{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f407e2da-a881-4f47-b9a9-02fa3055f30f",
   "metadata": {},
   "source": [
    "## objective detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13bf1693-0aae-4abb-9f92-63ec65e2018f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydicom in /opt/conda/lib/python3.9/site-packages (2.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5550719-4549-4285-a1a5-1f5c0771e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom as dicom\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "# from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "from retinanet import model\n",
    "from retinanet.dataloader import collater, Resizer, Augmenter, Normalizer, UnNormalizer\n",
    "\n",
    "# import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a2418c-cff2-4fc0-918e-929fb70f3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from retinanet.csv_eval import _compute_ap, compute_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abcaeeb5-54d2-4417-badf-787468c71fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30222</th>\n",
       "      <td>c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8</td>\n",
       "      <td>185.0</td>\n",
       "      <td>298.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30223</th>\n",
       "      <td>c1edf42b-5958-47ff-a1e7-4f23d99583ba</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30224</th>\n",
       "      <td>c1f6b555-2eb1-4231-98f6-50a963976431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30225</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>570.0</td>\n",
       "      <td>393.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30226</th>\n",
       "      <td>c1f7889a-9ea9-4acb-b64c-b737c929599a</td>\n",
       "      <td>233.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>356.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30227 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "0      0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN   \n",
       "1      00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN   \n",
       "2      00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN   \n",
       "3      003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN   \n",
       "4      00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0   \n",
       "...                                     ...    ...    ...    ...     ...   \n",
       "30222  c1ec14ff-f6d7-4b38-b0cb-fe07041cbdc8  185.0  298.0  228.0   379.0   \n",
       "30223  c1edf42b-5958-47ff-a1e7-4f23d99583ba    NaN    NaN    NaN     NaN   \n",
       "30224  c1f6b555-2eb1-4231-98f6-50a963976431    NaN    NaN    NaN     NaN   \n",
       "30225  c1f7889a-9ea9-4acb-b64c-b737c929599a  570.0  393.0  261.0   345.0   \n",
       "30226  c1f7889a-9ea9-4acb-b64c-b737c929599a  233.0  424.0  201.0   356.0   \n",
       "\n",
       "       Target  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           1  \n",
       "...       ...  \n",
       "30222       1  \n",
       "30223       0  \n",
       "30224       0  \n",
       "30225       1  \n",
       "30226       1  \n",
       "\n",
       "[30227 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_annot = pd.read_csv(\"../rsna-pneumonia-detection-challenge/stage_2_train_labels.csv\")\n",
    "# df_annot = df_annot[df_annot['Target']==1]\n",
    "df_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b341a3d-8d54-464b-9670-57e23582e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fmt(x):\n",
    "#     if np.isnan(x):\n",
    "#         return -1\n",
    "#     else:\n",
    "#         return x\n",
    "    \n",
    "# df_annot['x'] = df_annot['x'].apply(lambda x: fmt(x))\n",
    "# df_annot['y'] = df_annot['y'].apply(lambda x: fmt(x))\n",
    "# df_annot['width'] = df_annot['width'].apply(lambda x: fmt(x))\n",
    "# df_annot['height'] = df_annot['height'].apply(lambda x: fmt(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "075afc3a-2237-4a93-93b5-3a7fa832871c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:  30227\n",
      "Unique Images:  26684\n",
      "\n",
      "> Null Values in each column <\n",
      "patientId        0\n",
      "x            20672\n",
      "y            20672\n",
      "width        20672\n",
      "height       20672\n",
      "Target           0\n",
      "dtype: int64\n",
      "Total Target:  2\n",
      "\n",
      "> Target <\n",
      " [0 1]\n"
     ]
    }
   ],
   "source": [
    "unq_values = df_annot[\"patientId\"].unique()\n",
    "print(\"Total Records: \", len(df_annot))\n",
    "print(\"Unique Images: \",len(unq_values))\n",
    "\n",
    "null_values = df_annot.isnull().sum(axis = 0)\n",
    "print(\"\\n> Null Values in each column <\")\n",
    "print(null_values)\n",
    "\n",
    "sources = df_annot[\"Target\"].unique()\n",
    "print(\"Total Target: \",len(sources))\n",
    "print(\"\\n> Target <\\n\",sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b5b6f0-9259-4dca-b129-89dbdcdef6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../rsna-pneumonia-detection-challenge/stage_2_train_images/'\n",
    "train_data = []\n",
    "for fp in os.listdir(root_path):\n",
    "#     ds = dicom.dcmread(root_path+fp)\n",
    "    train_data.append([fp.split('.')[0], root_path+fp])\n",
    "    # plt.imshow(ds.pixel_array, cmap='gray')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "878b487c-a969-499f-9d67-98292739ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(train_data, columns=['patientId','filepath']).sort_values(by='patientId')\n",
    "# df_data = df_data.loc[df_data['patientId'].isin(df_annot['patientId'].unique())]\n",
    "msk = np.random.rand(len(df_data)) < 0.8\n",
    "df_train_data = df_data[msk]\n",
    "df_valid_data = df_data[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a253ec-3b05-47fa-855d-cd4d4104f5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8888</th>\n",
       "      <td>000924cf-0f8d-42bd-9158-1af53881a557</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23483</th>\n",
       "      <td>000db696-cf54-4385-b10b-6b16fbb3f985</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13569</th>\n",
       "      <td>001031d9-f904-4a23-b3e5-2c088acd19c6</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>0010f549-b242-4e94-87a8-57d79de215fc</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17775</th>\n",
       "      <td>001916b8-3d30-4935-a5d1-8eaddb1646cd</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21674</th>\n",
       "      <td>fffb2395-8edd-4954-8a89-ffe2fd329be3</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7729</th>\n",
       "      <td>fffba05a-1635-4545-9bbd-57ad4cfe8d27</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6091</th>\n",
       "      <td>fffc95b5-605b-4226-80ab-62caec682b22</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>fffcff11-d018-4414-971a-a7cefa327795</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24494</th>\n",
       "      <td>fffec09e-8a4a-48b1-b33e-ab4890ccd136</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21398 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId  \\\n",
       "8888   000924cf-0f8d-42bd-9158-1af53881a557   \n",
       "23483  000db696-cf54-4385-b10b-6b16fbb3f985   \n",
       "13569  001031d9-f904-4a23-b3e5-2c088acd19c6   \n",
       "8690   0010f549-b242-4e94-87a8-57d79de215fc   \n",
       "17775  001916b8-3d30-4935-a5d1-8eaddb1646cd   \n",
       "...                                     ...   \n",
       "21674  fffb2395-8edd-4954-8a89-ffe2fd329be3   \n",
       "7729   fffba05a-1635-4545-9bbd-57ad4cfe8d27   \n",
       "6091   fffc95b5-605b-4226-80ab-62caec682b22   \n",
       "14272  fffcff11-d018-4414-971a-a7cefa327795   \n",
       "24494  fffec09e-8a4a-48b1-b33e-ab4890ccd136   \n",
       "\n",
       "                                                filepath  \n",
       "8888   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "23483  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "13569  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "8690   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "17775  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "...                                                  ...  \n",
       "21674  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "7729   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "6091   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "14272  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "24494  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "\n",
       "[21398 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fddbc2c7-35d8-4e5c-9961-473dc8d1cef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>filepath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7634</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664</th>\n",
       "      <td>000fe35a-2649-43d4-b027-e67796d412e0</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>0022073f-cec8-42ec-ab5f-bc2314649235</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2539</th>\n",
       "      <td>0025d2de-bd78-4d36-9f72-e15a5e22ca82</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17216</th>\n",
       "      <td>00293de0-a530-41dc-9621-0b3def01d06d</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19331</th>\n",
       "      <td>ffc01e64-ba14-4620-8016-235fc1609767</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9675</th>\n",
       "      <td>ffcc35e8-6fe8-42df-9605-9fedf57240d1</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24111</th>\n",
       "      <td>ffd56560-6754-4a20-83c6-06ad5c4b30ab</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14690</th>\n",
       "      <td>ffd787b6-59ca-48cb-bd15-bcedd52cf37c</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18093</th>\n",
       "      <td>ffe9ab5c-9d39-4235-9ade-d725dcad6b76</td>\n",
       "      <td>../rsna-pneumonia-detection-challenge/stage_2_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5286 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId  \\\n",
       "7634   0004cfab-14fd-4e49-80ba-63a80b6bddd6   \n",
       "10664  000fe35a-2649-43d4-b027-e67796d412e0   \n",
       "2520   0022073f-cec8-42ec-ab5f-bc2314649235   \n",
       "2539   0025d2de-bd78-4d36-9f72-e15a5e22ca82   \n",
       "17216  00293de0-a530-41dc-9621-0b3def01d06d   \n",
       "...                                     ...   \n",
       "19331  ffc01e64-ba14-4620-8016-235fc1609767   \n",
       "9675   ffcc35e8-6fe8-42df-9605-9fedf57240d1   \n",
       "24111  ffd56560-6754-4a20-83c6-06ad5c4b30ab   \n",
       "14690  ffd787b6-59ca-48cb-bd15-bcedd52cf37c   \n",
       "18093  ffe9ab5c-9d39-4235-9ade-d725dcad6b76   \n",
       "\n",
       "                                                filepath  \n",
       "7634   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "10664  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "2520   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "2539   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "17216  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "...                                                  ...  \n",
       "19331  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "9675   ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "24111  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "14690  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "18093  ../rsna-pneumonia-detection-challenge/stage_2_...  \n",
       "\n",
       "[5286 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe969462-d75d-42da-a78e-9e39b712d106",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating targets for model using Dataset Class\n",
    "\n",
    "class mydataset(Dataset):\n",
    "\n",
    "    def __init__(self, df_data, df_annot, mode = \"train\", transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.pids = df_data['patientId'].unique()\n",
    "        self.df_annot = df_annot\n",
    "        self.df_data = df_data\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Retriving image id and records from df\n",
    "        pid = self.pids[idx]\n",
    "        annot = self.df_annot[self.df_annot['patientId'] == pid]\n",
    "\n",
    "        # Loading Image\n",
    "        fp = self.df_data[self.df_data['patientId'] == pid]['filepath'].item()\n",
    "        image = dicom.dcmread(fp)\n",
    "        image = image.pixel_array.astype(np.float32)\n",
    "        image = np.expand_dims(image, axis=0).transpose(1, 2, 0)\n",
    "        \n",
    "        # If mode is set to train, then only we create targets\n",
    "        if self.mode == \"train\" or self.mode == \"valid\":\n",
    "            \n",
    "            if annot['x'].isnull().values.any():\n",
    "                boxes = np.zeros((0,5))\n",
    "                sample = {'img':image, 'annot':boxes}\n",
    "            else:\n",
    "                # Converting xmin, ymin, w, h to x1, y1, x2, y2\n",
    "                boxes = np.zeros((annot.shape[0], 5))\n",
    "\n",
    "                boxes[:, 0:4] = annot[['x', 'y', 'width', 'height']].values\n",
    "                boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "                boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "                boxes[:, 4] = 1 # This is for label, as we have only 1 class, it is always 1\n",
    "\n",
    "            sample = {'img': image, 'annot': boxes}\n",
    "            if self.transforms:\n",
    "                sample = self.transforms(sample)\n",
    "\n",
    "            return sample\n",
    "        \n",
    "        elif self.mode == \"test\":\n",
    "            \n",
    "            sample = {'img' : image}\n",
    "            if self.transforms:\n",
    "                sample = self.transforms(sample)\n",
    "                \n",
    "            return sample\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.pids.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d312ee-df2d-412d-9afc-45b376a523ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = mydataset(df_train_data, df_annot, mode=\"train\", transforms=T.Compose([Resizer()]))\n",
    "# valid_dataset = mydataset(df_valid_data, df_annot, mode= \"valid\", transforms = T.Compose([Resizer()]))\n",
    "# torch.save(train_dataset, './train_128.dataset')\n",
    "# torch.save(valid_dataset, './valid_128.dataset')\n",
    "train_dataset = torch.load('./train_128.dataset')\n",
    "valid_dataset = torch.load('./valid_128.dataset')\n",
    "# train_dataset = mydataset(df_train_data, df_annot, mode=\"train\")\n",
    "# valid_dataset = mydataset(df_valid_data, df_annot, mode= \"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0680aa34-b19a-4c3e-94ed-9665d58aa7c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cd = 5\n",
    "# for each in train_dataset:\n",
    "#     print('img:\\n', each['img'].size(), '\\n\\t', each['img'])\n",
    "#     print('annot:\\n', each['annot'].size(), '\\n\\t', each['annot'])\n",
    "#     print('scale:', each['scale'])\n",
    "#     cd -= 1\n",
    "#     if cd == 0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f6e35c0-f517-4599-ae51-48fd876d153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 128,\n",
    "    shuffle = True,\n",
    "    collate_fn = collater\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 128,\n",
    "    shuffle = False,\n",
    "    collate_fn = collater\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcff81ac-c74b-4fb4-bf2d-0ad379ff4613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2812eed-eb89-4654-bfea-582ce8a1db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/final_proj/pytorch-retinanet/retinanet/dataloader.py:318: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_imgs[i, :int(img.shape[0]), :int(img.shape[1]), :] = torch.tensor(img)\n",
      "/home/jovyan/work/final_proj/pytorch-retinanet/retinanet/dataloader.py:330: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  annot_padded[idx, :annot.shape[0], :] = torch.tensor(annot)\n"
     ]
    }
   ],
   "source": [
    "for each in train_dataloader:\n",
    "    img = each['img']\n",
    "    annot = each['annot']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81807053-e9c6-4c47-a40f-f38465302efa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 1, 128, 128]), torch.Size([128, 2, 5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.size(), annot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8608d0ae-bacb-4cef-8df0-83b1cfebd48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_predict(retinanet, dataloader, confidence):\n",
    "\n",
    "#     # retinanet = torch.load('./retinanet_resnet50.pt')\n",
    "#     retinanet.eval()\n",
    "#     scores_list, labels_list, boxes_list = [], [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "        \n",
    "#         for data in tqdm(dataloader):\n",
    "#             img = data['img']\n",
    "#             annot = data['annot']\n",
    "#             # scale = data['scale']\n",
    "\n",
    "#             # run network\n",
    "#             if torch.cuda.is_available():\n",
    "#                 scores, labels, boxes = retinanet(img.cuda().float())\n",
    "#             else:\n",
    "#                 scores, labels, boxes = retinanet(img.float())\n",
    "\n",
    "#             scores_list.append(scores.cpu())\n",
    "#             labels_list.append(labels.cpu())\n",
    "#             boxes_list.append(boxes.cpu())\n",
    "\n",
    "#             # print(scores, \"\\n\", labels, \"\\n\", boxes, \"\\n\")\n",
    "\n",
    "#             # correct boxes for image scale\n",
    "#             # boxes /= scale\n",
    "        \n",
    "#         scores_list = torch.cat(scores_list, dim=0).numpy()\n",
    "#         labels_list = torch.cat(labels_list, dim=0).numpy()\n",
    "#         boxes_list = torch.cat(boxes_list, dim=0).numpy()\n",
    "            \n",
    "#         predict = {}\n",
    "#         for score_threshold in confidence:\n",
    "#             predict[score_threshold] = [[None, None] for j in range(len(valid_dataset))]\n",
    "\n",
    "#             for idx in range(len(scores_list)):\n",
    "#                 scores = scores_list[idx]\n",
    "#                 labels = labels_list[idx]\n",
    "#                 boxes = boxes_list[idx]\n",
    "\n",
    "#                 indices = np.where(scores > score_threshold)[0]\n",
    "#                 if indices.shape[0] > 0:\n",
    "#                     # select those scores\n",
    "#                     scores = scores[indices]\n",
    "\n",
    "#                     # find the order with which to sort the scores\n",
    "#                     scores_sort = np.argsort(-scores)[:4]\n",
    "\n",
    "#                     # select detections\n",
    "#                     image_boxes      = boxes[indices[scores_sort], :]\n",
    "#                     image_scores     = scores[scores_sort]\n",
    "#                     image_labels     = labels[indices[scores_sort]]\n",
    "#                     image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "\n",
    "#                     # copy detections to predict\n",
    "#                     for label in range(2):\n",
    "#                         predict[score_threshold][idx][label] = image_detections[image_detections[:, -1] == label, :-1]\n",
    "#                 else:\n",
    "#                     # copy detections to predict\n",
    "#                     for label in range(2):\n",
    "#                         predict[score_threshold][idx][label] = np.zeros((0, 5))\n",
    "                    \n",
    "#     return predict\n",
    "#             # print('{}/{}'.format(index + 1, len(dataset)), end='\\r')\n",
    "#             # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07b6d02c-f7ce-464b-bcb5-2809c9bab7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(retinanet, num, dataset, confidence):\n",
    "\n",
    "    # retinanet = torch.load('./retinanet_resnet50.pt')\n",
    "    retinanet.eval()\n",
    "    scores_list, labels_list, boxes_list = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for index in tqdm(range(num)):\n",
    "            data = dataset[index]\n",
    "            img = data['img'].permute(2, 0, 1).float()\n",
    "            img = np.repeat(img, 3, axis=0)\n",
    "            annot = data['annot']\n",
    "            scale = data['scale']\n",
    "\n",
    "            # run network\n",
    "            if torch.cuda.is_available():\n",
    "                scores, labels, boxes = retinanet(img.cuda().unsqueeze(dim=0))\n",
    "            else:\n",
    "                scores, labels, boxes = retinanet(img.unsqueeze(dim=0))\n",
    "\n",
    "            scores_list.append(scores.cpu().numpy())\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "            boxes_list.append(boxes.cpu().numpy())\n",
    "\n",
    "            # print(scores, \"\\n\", labels, \"\\n\", boxes, \"\\n\")\n",
    "\n",
    "            # correct boxes for image scale\n",
    "            # boxes /= scale\n",
    "\n",
    "            # select indices which have a score above the threshold\n",
    "            \n",
    "        predict = {}\n",
    "        for score_threshold in confidence:\n",
    "            predict[score_threshold] = [[None, None] for j in range(len(valid_dataset))]\n",
    "\n",
    "            for idx in range(len(scores_list)):\n",
    "                scores = scores_list[idx]\n",
    "                labels = labels_list[idx]\n",
    "                boxes = boxes_list[idx]\n",
    "\n",
    "                indices = np.where(scores > score_threshold)[0]\n",
    "                if indices.shape[0] > 0:\n",
    "                    # select those scores\n",
    "                    scores = scores[indices]\n",
    "\n",
    "                    # find the order with which to sort the scores\n",
    "                    scores_sort = np.argsort(-scores)[:4]\n",
    "\n",
    "                    # select detections\n",
    "                    image_boxes      = boxes[indices[scores_sort], :]\n",
    "                    image_scores     = scores[scores_sort]\n",
    "                    image_labels     = labels[indices[scores_sort]]\n",
    "                    image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "\n",
    "                    # copy detections to predict\n",
    "                    for label in range(2):\n",
    "                        predict[score_threshold][idx][label] = image_detections[image_detections[:, -1] == label, :-1]\n",
    "                else:\n",
    "                    # copy detections to predict\n",
    "                    for label in range(2):\n",
    "                        predict[score_threshold][idx][label] = np.zeros((0, 5))\n",
    "                    \n",
    "    return predict\n",
    "            # print('{}/{}'.format(index + 1, len(dataset)), end='\\r')\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0414f0d3-1a9d-4c92-90e5-074594436fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to ./resnet34-333f7ec4.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee791adc3264f46922ad36dd8f52bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "retinanet = model.resnet34(num_classes = 2, pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "207d057a-2f03-4f5c-81b9-059a4ff41186",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(retinanet.parameters(), lr = 0.0001)\n",
    "retinanet.to(device)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8ffb11a-1bd8-4521-ad7f-5082b1b79abe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(retinanet, epoch_num, train_data_loader):\n",
    "    \n",
    "    print(\"Epoch - {} Started\".format(epoch_num))\n",
    "    st = time.time()\n",
    "    \n",
    "    retinanet.train()\n",
    "    \n",
    "    epoch_loss = []\n",
    "\n",
    "    for iter_num, data in enumerate(train_data_loader):\n",
    "\n",
    "        # Reseting gradients after each iter\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward\n",
    "        img = data['img']\n",
    "        img = np.repeat(img, 3, axis=1)\n",
    "        classification_loss, regression_loss = retinanet([img.cuda().float(), data['annot'].cuda().float()])\n",
    "\n",
    "        # Calculating Loss\n",
    "        classification_loss = classification_loss.mean()\n",
    "        regression_loss = regression_loss.mean()\n",
    "\n",
    "        loss = classification_loss + regression_loss\n",
    "\n",
    "        if bool(loss == 0):\n",
    "            continue\n",
    "\n",
    "        # Calculating Gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient Clipping\n",
    "        torch.nn.utils.clip_grad_norm_(retinanet.parameters(), 0.1)\n",
    "                \n",
    "        # Updating Weights\n",
    "        optimizer.step()\n",
    "\n",
    "        #Epoch Loss\n",
    "        epoch_loss.append(float(loss))\n",
    "\n",
    "\n",
    "        print(\n",
    "            'Epoch: {} | Iteration: {} | Classification loss: {:1.5f} | Regression loss: {:1.5f} | Running loss: {:1.5f}'.format(\n",
    "                epoch_num, iter_num, float(classification_loss), float(regression_loss), np.mean(epoch_loss)))\n",
    "\n",
    "        del classification_loss\n",
    "        del regression_loss\n",
    "        \n",
    "    # Update the learning rate\n",
    "    #if lr_scheduler is not None:\n",
    "        #lr_scheduler.step()\n",
    "    \n",
    "    et = time.time()\n",
    "    print(\"\\n Total Time - {}\\n\".format(int(et - st)))\n",
    "    torch.save(retinanet, \"retinanet_resnet34_pretrained.pt\")\n",
    "    \n",
    "    ## validation\n",
    "    # retinanet = torch.load('./retinanet_resnet34.pt')\n",
    "    retinanet.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        results = []\n",
    "        scores_ = None; labels_=None; boxes_=None\n",
    "\n",
    "        print(\"get detections on train dataset...\")\n",
    "        train_detection_dict = get_predict(retinanet, 2000, train_dataset, confidence=[.05, .1, .15, .2, .25, .3, .35, .4, .45, .5])\n",
    "        print(\"get detections on valid dataset...\")\n",
    "        val_detection_dict = get_predict(retinanet, len(valid_dataset), valid_dataset, confidence=[.05, .1, .15, .2, .25, .3, .35, .4, .45, .5])\n",
    "\n",
    "        cd = 0; sz = 0\n",
    "        for each in [train_detection_dict, val_detection_dict]:\n",
    "\n",
    "            print()\n",
    "            print(\"=\"*100)\n",
    "            if cd == 0:\n",
    "                print(\"mAP on training dataset\")\n",
    "                sz = 2000\n",
    "            else:\n",
    "                print(\"mAP on validating dataset\")\n",
    "                sz = len(valid_dataset)\n",
    "            print(\"=\"*100)\n",
    "\n",
    "            for score_threshold in each:\n",
    "\n",
    "                print(\"\\npredicting with confidence value: {}\".format(score_threshold))\n",
    "                all_detections = each[score_threshold]\n",
    "                if cd == 0:\n",
    "                    all_annotations = torch.load('./ground_truth_annot_train.data')\n",
    "                else:\n",
    "                    all_annotations = torch.load('./ground_truth_annot_valid.data')\n",
    "\n",
    "                # print(all_annotations)\n",
    "\n",
    "                tmp = []\n",
    "\n",
    "                for iou_threshold in {0.3, 0.4, 0.5, 0.6, 0.7}:\n",
    "                    # print(\"in\")\n",
    "\n",
    "                    average_precisions = {}\n",
    "\n",
    "                    for label in range(1,2):\n",
    "                        # print(\"in label\")\n",
    "                        false_positives = np.zeros((0,))\n",
    "                        true_positives  = np.zeros((0,))\n",
    "                        scores          = np.zeros((0,))\n",
    "                        num_annotations = 0.0\n",
    "\n",
    "                        for i in range(sz):\n",
    "                            detections           = all_detections[i][label]\n",
    "                            annotations          = all_annotations[i][label]\n",
    "                            num_annotations     += annotations.shape[0]\n",
    "                            detected_annotations = []\n",
    "\n",
    "                            # print(detections)\n",
    "\n",
    "                            for d in detections:\n",
    "                                scores = np.append(scores, d[4])\n",
    "\n",
    "                                if annotations.shape[0] == 0:\n",
    "                                    false_positives = np.append(false_positives, 1)\n",
    "                                    true_positives  = np.append(true_positives, 0)\n",
    "                                    continue\n",
    "\n",
    "                                overlaps            = compute_overlap(np.expand_dims(d, axis=0), annotations)\n",
    "                                assigned_annotation = np.argmax(overlaps, axis=1)\n",
    "                                max_overlap         = overlaps[0, assigned_annotation]\n",
    "\n",
    "                                # print(assigned_annotation)\n",
    "                                # print(overlaps)\n",
    "                                # print(max_overlap)\n",
    "                                # print()\n",
    "\n",
    "                                # print(overlaps)\n",
    "\n",
    "                                if max_overlap >= iou_threshold and assigned_annotation not in detected_annotations:\n",
    "                                    false_positives = np.append(false_positives, 0)\n",
    "                                    true_positives  = np.append(true_positives, 1)\n",
    "                                    detected_annotations.append(assigned_annotation)\n",
    "                                else:\n",
    "                                    false_positives = np.append(false_positives, 1)\n",
    "                                    true_positives  = np.append(true_positives, 0)\n",
    "\n",
    "                        # print(false_positives)\n",
    "                        # print(true_positives)\n",
    "\n",
    "                        # print(num_annotations)\n",
    "\n",
    "                        # no annotations -> AP for this class is 0 (is this correct?)\n",
    "                        if num_annotations == 0:\n",
    "                            average_precisions[label] = 0, 0\n",
    "                            continue\n",
    "\n",
    "                        # sort by score\n",
    "                        indices         = np.argsort(-scores)\n",
    "                        false_positives = false_positives[indices]\n",
    "                        true_positives  = true_positives[indices]\n",
    "\n",
    "                        # compute false positives and true positives\n",
    "                        false_positives = np.cumsum(false_positives)\n",
    "                        true_positives  = np.cumsum(true_positives)\n",
    "\n",
    "                        # compute recall and precision\n",
    "                        recall    = true_positives / num_annotations\n",
    "                        precision = true_positives / np.maximum(true_positives + false_positives, np.finfo(np.float64).eps)\n",
    "\n",
    "                        # compute average precision\n",
    "                        average_precision  = _compute_ap(recall, precision)\n",
    "                        average_precisions[label] = average_precision, num_annotations\n",
    "\n",
    "                    # print(precision.shape[0])\n",
    "                    if precision.shape[0] == 0:\n",
    "                        print(\"AP@{}:0.0000,Precision:0.0000,Recall:0.0000\".format(iou_threshold))\n",
    "                        continue\n",
    "\n",
    "                    fmt = \"AP@{}:{:.4f},Precision:{:.4f},Recall:{:.4f}\"\n",
    "                    print(fmt.format(iou_threshold, average_precisions[1][0], precision[-1], recall[-1]))\n",
    "                \n",
    "                cd += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bee401-d15e-4da9-8126-c2001c67fbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch - 0 Started\n",
      "Epoch: 0 | Iteration: 0 | Classification loss: 0.24174 | Regression loss: 0.21143 | Running loss: 0.45317\n",
      "Epoch: 0 | Iteration: 1 | Classification loss: 0.17955 | Regression loss: 0.16965 | Running loss: 0.40119\n",
      "Epoch: 0 | Iteration: 2 | Classification loss: 0.22877 | Regression loss: 0.17179 | Running loss: 0.40098\n",
      "Epoch: 0 | Iteration: 3 | Classification loss: 0.17339 | Regression loss: 0.16184 | Running loss: 0.38454\n",
      "Epoch: 0 | Iteration: 4 | Classification loss: 0.13365 | Regression loss: 0.13851 | Running loss: 0.36207\n",
      "Epoch: 0 | Iteration: 5 | Classification loss: 0.11614 | Regression loss: 0.10427 | Running loss: 0.33846\n",
      "Epoch: 0 | Iteration: 6 | Classification loss: 0.20561 | Regression loss: 0.20520 | Running loss: 0.34879\n",
      "Epoch: 0 | Iteration: 7 | Classification loss: 0.16230 | Regression loss: 0.15903 | Running loss: 0.34536\n",
      "Epoch: 0 | Iteration: 8 | Classification loss: 0.15967 | Regression loss: 0.15447 | Running loss: 0.34189\n",
      "Epoch: 0 | Iteration: 9 | Classification loss: 0.15207 | Regression loss: 0.15451 | Running loss: 0.33836\n",
      "Epoch: 0 | Iteration: 10 | Classification loss: 0.13125 | Regression loss: 0.13484 | Running loss: 0.33179\n",
      "Epoch: 0 | Iteration: 11 | Classification loss: 0.16478 | Regression loss: 0.16238 | Running loss: 0.33140\n",
      "Epoch: 0 | Iteration: 12 | Classification loss: 0.12205 | Regression loss: 0.13624 | Running loss: 0.32578\n",
      "Epoch: 0 | Iteration: 13 | Classification loss: 0.14384 | Regression loss: 0.14586 | Running loss: 0.32320\n",
      "Epoch: 0 | Iteration: 14 | Classification loss: 0.11950 | Regression loss: 0.11897 | Running loss: 0.31756\n",
      "Epoch: 0 | Iteration: 15 | Classification loss: 0.16668 | Regression loss: 0.16860 | Running loss: 0.31866\n",
      "Epoch: 0 | Iteration: 16 | Classification loss: 0.14680 | Regression loss: 0.14910 | Running loss: 0.31732\n",
      "Epoch: 0 | Iteration: 17 | Classification loss: 0.17238 | Regression loss: 0.20090 | Running loss: 0.32043\n",
      "Epoch: 0 | Iteration: 18 | Classification loss: 0.13939 | Regression loss: 0.16520 | Running loss: 0.31960\n",
      "Epoch: 0 | Iteration: 19 | Classification loss: 0.11845 | Regression loss: 0.10274 | Running loss: 0.31468\n",
      "Epoch: 0 | Iteration: 20 | Classification loss: 0.19343 | Regression loss: 0.21314 | Running loss: 0.31905\n",
      "Epoch: 0 | Iteration: 21 | Classification loss: 0.21474 | Regression loss: 0.24342 | Running loss: 0.32538\n",
      "Epoch: 0 | Iteration: 22 | Classification loss: 0.16234 | Regression loss: 0.15509 | Running loss: 0.32503\n",
      "Epoch: 0 | Iteration: 23 | Classification loss: 0.15450 | Regression loss: 0.15240 | Running loss: 0.32428\n",
      "Epoch: 0 | Iteration: 24 | Classification loss: 0.14651 | Regression loss: 0.15524 | Running loss: 0.32337\n",
      "Epoch: 0 | Iteration: 25 | Classification loss: 0.15821 | Regression loss: 0.17992 | Running loss: 0.32394\n",
      "Epoch: 0 | Iteration: 26 | Classification loss: 0.21674 | Regression loss: 0.24284 | Running loss: 0.32897\n",
      "Epoch: 0 | Iteration: 27 | Classification loss: 0.14713 | Regression loss: 0.14347 | Running loss: 0.32760\n",
      "Epoch: 0 | Iteration: 28 | Classification loss: 0.19963 | Regression loss: 0.21343 | Running loss: 0.33054\n",
      "Epoch: 0 | Iteration: 29 | Classification loss: 0.11599 | Regression loss: 0.11243 | Running loss: 0.32714\n",
      "Epoch: 0 | Iteration: 30 | Classification loss: 0.18235 | Regression loss: 0.19470 | Running loss: 0.32875\n",
      "Epoch: 0 | Iteration: 31 | Classification loss: 0.14336 | Regression loss: 0.16981 | Running loss: 0.32826\n",
      "Epoch: 0 | Iteration: 32 | Classification loss: 0.11789 | Regression loss: 0.11735 | Running loss: 0.32544\n",
      "Epoch: 0 | Iteration: 33 | Classification loss: 0.17031 | Regression loss: 0.18822 | Running loss: 0.32642\n",
      "Epoch: 0 | Iteration: 34 | Classification loss: 0.11525 | Regression loss: 0.12914 | Running loss: 0.32407\n",
      "Epoch: 0 | Iteration: 35 | Classification loss: 0.11207 | Regression loss: 0.13036 | Running loss: 0.32180\n",
      "Epoch: 0 | Iteration: 36 | Classification loss: 0.18203 | Regression loss: 0.20653 | Running loss: 0.32361\n",
      "Epoch: 0 | Iteration: 37 | Classification loss: 0.13358 | Regression loss: 0.14725 | Running loss: 0.32248\n",
      "Epoch: 0 | Iteration: 38 | Classification loss: 0.12933 | Regression loss: 0.15416 | Running loss: 0.32148\n",
      "Epoch: 0 | Iteration: 39 | Classification loss: 0.15845 | Regression loss: 0.14628 | Running loss: 0.32106\n",
      "Epoch: 0 | Iteration: 40 | Classification loss: 0.13891 | Regression loss: 0.17082 | Running loss: 0.32079\n",
      "Epoch: 0 | Iteration: 41 | Classification loss: 0.17439 | Regression loss: 0.18612 | Running loss: 0.32173\n",
      "Epoch: 0 | Iteration: 42 | Classification loss: 0.16156 | Regression loss: 0.17737 | Running loss: 0.32213\n",
      "Epoch: 0 | Iteration: 43 | Classification loss: 0.11264 | Regression loss: 0.13932 | Running loss: 0.32054\n",
      "Epoch: 0 | Iteration: 44 | Classification loss: 0.12478 | Regression loss: 0.12665 | Running loss: 0.31900\n",
      "Epoch: 0 | Iteration: 45 | Classification loss: 0.11438 | Regression loss: 0.11778 | Running loss: 0.31712\n",
      "Epoch: 0 | Iteration: 46 | Classification loss: 0.12838 | Regression loss: 0.14546 | Running loss: 0.31619\n",
      "Epoch: 0 | Iteration: 47 | Classification loss: 0.13651 | Regression loss: 0.14136 | Running loss: 0.31540\n",
      "Epoch: 0 | Iteration: 48 | Classification loss: 0.14634 | Regression loss: 0.15850 | Running loss: 0.31518\n",
      "Epoch: 0 | Iteration: 49 | Classification loss: 0.14398 | Regression loss: 0.15081 | Running loss: 0.31477\n",
      "Epoch: 0 | Iteration: 50 | Classification loss: 0.18997 | Regression loss: 0.23126 | Running loss: 0.31686\n",
      "Epoch: 0 | Iteration: 51 | Classification loss: 0.15561 | Regression loss: 0.18328 | Running loss: 0.31728\n",
      "Epoch: 0 | Iteration: 52 | Classification loss: 0.12044 | Regression loss: 0.13450 | Running loss: 0.31611\n",
      "Epoch: 0 | Iteration: 53 | Classification loss: 0.09207 | Regression loss: 0.09295 | Running loss: 0.31368\n",
      "Epoch: 0 | Iteration: 54 | Classification loss: 0.14620 | Regression loss: 0.16713 | Running loss: 0.31367\n",
      "Epoch: 0 | Iteration: 55 | Classification loss: 0.13914 | Regression loss: 0.15466 | Running loss: 0.31332\n",
      "Epoch: 0 | Iteration: 56 | Classification loss: 0.13818 | Regression loss: 0.15770 | Running loss: 0.31301\n",
      "Epoch: 0 | Iteration: 57 | Classification loss: 0.09650 | Regression loss: 0.09842 | Running loss: 0.31098\n",
      "Epoch: 0 | Iteration: 58 | Classification loss: 0.14960 | Regression loss: 0.15101 | Running loss: 0.31080\n",
      "Epoch: 0 | Iteration: 59 | Classification loss: 0.14565 | Regression loss: 0.14185 | Running loss: 0.31041\n",
      "Epoch: 0 | Iteration: 60 | Classification loss: 0.12383 | Regression loss: 0.13963 | Running loss: 0.30964\n",
      "Epoch: 0 | Iteration: 61 | Classification loss: 0.12308 | Regression loss: 0.13610 | Running loss: 0.30883\n",
      "Epoch: 0 | Iteration: 62 | Classification loss: 0.12348 | Regression loss: 0.12040 | Running loss: 0.30780\n",
      "Epoch: 0 | Iteration: 63 | Classification loss: 0.10235 | Regression loss: 0.09672 | Running loss: 0.30610\n",
      "Epoch: 0 | Iteration: 64 | Classification loss: 0.15170 | Regression loss: 0.15796 | Running loss: 0.30615\n",
      "Epoch: 0 | Iteration: 65 | Classification loss: 0.11820 | Regression loss: 0.12944 | Running loss: 0.30527\n",
      "Epoch: 0 | Iteration: 66 | Classification loss: 0.11557 | Regression loss: 0.13533 | Running loss: 0.30446\n",
      "Epoch: 0 | Iteration: 67 | Classification loss: 0.14386 | Regression loss: 0.15091 | Running loss: 0.30431\n",
      "Epoch: 0 | Iteration: 68 | Classification loss: 0.13117 | Regression loss: 0.12454 | Running loss: 0.30361\n",
      "Epoch: 0 | Iteration: 69 | Classification loss: 0.12162 | Regression loss: 0.13199 | Running loss: 0.30290\n",
      "Epoch: 0 | Iteration: 70 | Classification loss: 0.11880 | Regression loss: 0.12755 | Running loss: 0.30210\n",
      "Epoch: 0 | Iteration: 71 | Classification loss: 0.11203 | Regression loss: 0.11611 | Running loss: 0.30107\n",
      "Epoch: 0 | Iteration: 72 | Classification loss: 0.15383 | Regression loss: 0.16211 | Running loss: 0.30128\n",
      "Epoch: 0 | Iteration: 73 | Classification loss: 0.13956 | Regression loss: 0.13145 | Running loss: 0.30087\n",
      "Epoch: 0 | Iteration: 74 | Classification loss: 0.15241 | Regression loss: 0.16721 | Running loss: 0.30112\n",
      "Epoch: 0 | Iteration: 75 | Classification loss: 0.11407 | Regression loss: 0.13774 | Running loss: 0.30047\n",
      "Epoch: 0 | Iteration: 76 | Classification loss: 0.10217 | Regression loss: 0.11310 | Running loss: 0.29936\n",
      "Epoch: 0 | Iteration: 77 | Classification loss: 0.13936 | Regression loss: 0.16792 | Running loss: 0.29946\n",
      "Epoch: 0 | Iteration: 78 | Classification loss: 0.15540 | Regression loss: 0.17534 | Running loss: 0.29986\n",
      "Epoch: 0 | Iteration: 79 | Classification loss: 0.12639 | Regression loss: 0.14481 | Running loss: 0.29950\n",
      "Epoch: 0 | Iteration: 80 | Classification loss: 0.12620 | Regression loss: 0.12627 | Running loss: 0.29892\n",
      "Epoch: 0 | Iteration: 81 | Classification loss: 0.13584 | Regression loss: 0.16121 | Running loss: 0.29890\n",
      "Epoch: 0 | Iteration: 82 | Classification loss: 0.10044 | Regression loss: 0.09087 | Running loss: 0.29760\n",
      "Epoch: 0 | Iteration: 83 | Classification loss: 0.14330 | Regression loss: 0.15588 | Running loss: 0.29762\n",
      "Epoch: 0 | Iteration: 84 | Classification loss: 0.11872 | Regression loss: 0.13264 | Running loss: 0.29708\n",
      "Epoch: 0 | Iteration: 85 | Classification loss: 0.12387 | Regression loss: 0.12721 | Running loss: 0.29654\n",
      "Epoch: 0 | Iteration: 86 | Classification loss: 0.09615 | Regression loss: 0.11226 | Running loss: 0.29553\n",
      "Epoch: 0 | Iteration: 87 | Classification loss: 0.12697 | Regression loss: 0.14958 | Running loss: 0.29531\n",
      "Epoch: 0 | Iteration: 88 | Classification loss: 0.16634 | Regression loss: 0.19024 | Running loss: 0.29600\n",
      "Epoch: 0 | Iteration: 89 | Classification loss: 0.13722 | Regression loss: 0.16006 | Running loss: 0.29601\n",
      "Epoch: 0 | Iteration: 90 | Classification loss: 0.09285 | Regression loss: 0.10720 | Running loss: 0.29496\n",
      "Epoch: 0 | Iteration: 91 | Classification loss: 0.09750 | Regression loss: 0.10095 | Running loss: 0.29391\n",
      "Epoch: 0 | Iteration: 92 | Classification loss: 0.11846 | Regression loss: 0.12909 | Running loss: 0.29341\n",
      "Epoch: 0 | Iteration: 93 | Classification loss: 0.15878 | Regression loss: 0.16377 | Running loss: 0.29372\n",
      "Epoch: 0 | Iteration: 94 | Classification loss: 0.14528 | Regression loss: 0.15620 | Running loss: 0.29380\n",
      "Epoch: 0 | Iteration: 95 | Classification loss: 0.11517 | Regression loss: 0.10854 | Running loss: 0.29307\n",
      "Epoch: 0 | Iteration: 96 | Classification loss: 0.13896 | Regression loss: 0.13746 | Running loss: 0.29290\n",
      "Epoch: 0 | Iteration: 97 | Classification loss: 0.07178 | Regression loss: 0.06827 | Running loss: 0.29134\n",
      "Epoch: 0 | Iteration: 98 | Classification loss: 0.13153 | Regression loss: 0.13603 | Running loss: 0.29110\n",
      "Epoch: 0 | Iteration: 99 | Classification loss: 0.12213 | Regression loss: 0.13058 | Running loss: 0.29072\n",
      "Epoch: 0 | Iteration: 100 | Classification loss: 0.13586 | Regression loss: 0.14192 | Running loss: 0.29059\n",
      "Epoch: 0 | Iteration: 101 | Classification loss: 0.11622 | Regression loss: 0.12781 | Running loss: 0.29013\n",
      "Epoch: 0 | Iteration: 102 | Classification loss: 0.14129 | Regression loss: 0.16321 | Running loss: 0.29027\n",
      "Epoch: 0 | Iteration: 103 | Classification loss: 0.12012 | Regression loss: 0.13105 | Running loss: 0.28990\n",
      "Epoch: 0 | Iteration: 104 | Classification loss: 0.11618 | Regression loss: 0.13094 | Running loss: 0.28949\n",
      "Epoch: 0 | Iteration: 105 | Classification loss: 0.12466 | Regression loss: 0.13605 | Running loss: 0.28922\n",
      "Epoch: 0 | Iteration: 106 | Classification loss: 0.11716 | Regression loss: 0.12599 | Running loss: 0.28879\n",
      "Epoch: 0 | Iteration: 107 | Classification loss: 0.14403 | Regression loss: 0.16813 | Running loss: 0.28900\n",
      "Epoch: 0 | Iteration: 108 | Classification loss: 0.10576 | Regression loss: 0.10468 | Running loss: 0.28828\n",
      "Epoch: 0 | Iteration: 109 | Classification loss: 0.14308 | Regression loss: 0.13313 | Running loss: 0.28817\n",
      "Epoch: 0 | Iteration: 110 | Classification loss: 0.11871 | Regression loss: 0.14590 | Running loss: 0.28796\n",
      "Epoch: 0 | Iteration: 111 | Classification loss: 0.10850 | Regression loss: 0.14036 | Running loss: 0.28761\n",
      "Epoch: 0 | Iteration: 112 | Classification loss: 0.10930 | Regression loss: 0.13066 | Running loss: 0.28719\n",
      "Epoch: 0 | Iteration: 113 | Classification loss: 0.13547 | Regression loss: 0.15365 | Running loss: 0.28721\n",
      "Epoch: 0 | Iteration: 114 | Classification loss: 0.09808 | Regression loss: 0.12700 | Running loss: 0.28667\n",
      "Epoch: 0 | Iteration: 115 | Classification loss: 0.11616 | Regression loss: 0.11618 | Running loss: 0.28620\n",
      "Epoch: 0 | Iteration: 116 | Classification loss: 0.11488 | Regression loss: 0.14632 | Running loss: 0.28599\n",
      "Epoch: 0 | Iteration: 117 | Classification loss: 0.10586 | Regression loss: 0.12001 | Running loss: 0.28548\n",
      "Epoch: 0 | Iteration: 118 | Classification loss: 0.10952 | Regression loss: 0.13401 | Running loss: 0.28512\n",
      "Epoch: 0 | Iteration: 119 | Classification loss: 0.12419 | Regression loss: 0.12103 | Running loss: 0.28479\n",
      "Epoch: 0 | Iteration: 120 | Classification loss: 0.06231 | Regression loss: 0.06234 | Running loss: 0.28347\n",
      "Epoch: 0 | Iteration: 121 | Classification loss: 0.15465 | Regression loss: 0.15140 | Running loss: 0.28365\n",
      "Epoch: 0 | Iteration: 122 | Classification loss: 0.14392 | Regression loss: 0.15557 | Running loss: 0.28378\n",
      "Epoch: 0 | Iteration: 123 | Classification loss: 0.12916 | Regression loss: 0.13504 | Running loss: 0.28362\n",
      "Epoch: 0 | Iteration: 124 | Classification loss: 0.15531 | Regression loss: 0.16326 | Running loss: 0.28390\n",
      "Epoch: 0 | Iteration: 125 | Classification loss: 0.13662 | Regression loss: 0.18165 | Running loss: 0.28418\n",
      "Epoch: 0 | Iteration: 126 | Classification loss: 0.22066 | Regression loss: 0.15691 | Running loss: 0.28491\n",
      "Epoch: 0 | Iteration: 127 | Classification loss: 0.38318 | Regression loss: 0.08150 | Running loss: 0.28632\n",
      "Epoch: 0 | Iteration: 128 | Classification loss: 0.15811 | Regression loss: 0.14860 | Running loss: 0.28647\n",
      "Epoch: 0 | Iteration: 129 | Classification loss: 0.13581 | Regression loss: 0.12687 | Running loss: 0.28629\n",
      "Epoch: 0 | Iteration: 130 | Classification loss: 0.13110 | Regression loss: 0.14058 | Running loss: 0.28618\n",
      "Epoch: 0 | Iteration: 131 | Classification loss: 0.08434 | Regression loss: 0.08607 | Running loss: 0.28530\n",
      "Epoch: 0 | Iteration: 132 | Classification loss: 0.16255 | Regression loss: 0.15385 | Running loss: 0.28554\n",
      "Epoch: 0 | Iteration: 133 | Classification loss: 0.15213 | Regression loss: 0.14016 | Running loss: 0.28559\n",
      "Epoch: 0 | Iteration: 134 | Classification loss: 0.13748 | Regression loss: 0.13452 | Running loss: 0.28549\n",
      "Epoch: 0 | Iteration: 135 | Classification loss: 0.11156 | Regression loss: 0.11498 | Running loss: 0.28505\n",
      "Epoch: 0 | Iteration: 136 | Classification loss: 0.12546 | Regression loss: 0.13791 | Running loss: 0.28489\n",
      "Epoch: 0 | Iteration: 137 | Classification loss: 0.13197 | Regression loss: 0.15055 | Running loss: 0.28488\n",
      "Epoch: 0 | Iteration: 138 | Classification loss: 0.09853 | Regression loss: 0.10877 | Running loss: 0.28432\n",
      "Epoch: 0 | Iteration: 139 | Classification loss: 0.13078 | Regression loss: 0.10831 | Running loss: 0.28400\n",
      "Epoch: 0 | Iteration: 140 | Classification loss: 0.09212 | Regression loss: 0.10010 | Running loss: 0.28334\n",
      "Epoch: 0 | Iteration: 141 | Classification loss: 0.10633 | Regression loss: 0.11820 | Running loss: 0.28293\n",
      "Epoch: 0 | Iteration: 142 | Classification loss: 0.12870 | Regression loss: 0.12902 | Running loss: 0.28275\n",
      "Epoch: 0 | Iteration: 143 | Classification loss: 0.11959 | Regression loss: 0.11922 | Running loss: 0.28245\n",
      "Epoch: 0 | Iteration: 144 | Classification loss: 0.12770 | Regression loss: 0.15178 | Running loss: 0.28243\n",
      "Epoch: 0 | Iteration: 145 | Classification loss: 0.11799 | Regression loss: 0.10827 | Running loss: 0.28204\n",
      "Epoch: 0 | Iteration: 146 | Classification loss: 0.14010 | Regression loss: 0.10267 | Running loss: 0.28178\n",
      "Epoch: 0 | Iteration: 147 | Classification loss: 0.13742 | Regression loss: 0.18168 | Running loss: 0.28203\n",
      "Epoch: 0 | Iteration: 148 | Classification loss: 0.08269 | Regression loss: 0.08881 | Running loss: 0.28129\n",
      "Epoch: 0 | Iteration: 149 | Classification loss: 0.10792 | Regression loss: 0.10989 | Running loss: 0.28086\n",
      "Epoch: 0 | Iteration: 150 | Classification loss: 0.11628 | Regression loss: 0.11563 | Running loss: 0.28054\n",
      "Epoch: 0 | Iteration: 151 | Classification loss: 0.11096 | Regression loss: 0.11963 | Running loss: 0.28021\n",
      "Epoch: 0 | Iteration: 152 | Classification loss: 0.12468 | Regression loss: 0.14258 | Running loss: 0.28013\n",
      "Epoch: 0 | Iteration: 153 | Classification loss: 0.11730 | Regression loss: 0.11995 | Running loss: 0.27985\n",
      "Epoch: 0 | Iteration: 154 | Classification loss: 0.11287 | Regression loss: 0.11637 | Running loss: 0.27952\n",
      "Epoch: 0 | Iteration: 155 | Classification loss: 0.09526 | Regression loss: 0.08798 | Running loss: 0.27890\n",
      "Epoch: 0 | Iteration: 156 | Classification loss: 0.12037 | Regression loss: 0.13087 | Running loss: 0.27873\n",
      "Epoch: 0 | Iteration: 157 | Classification loss: 0.13109 | Regression loss: 0.14169 | Running loss: 0.27869\n",
      "Epoch: 0 | Iteration: 158 | Classification loss: 0.13404 | Regression loss: 0.14592 | Running loss: 0.27870\n",
      "Epoch: 0 | Iteration: 159 | Classification loss: 0.07191 | Regression loss: 0.08020 | Running loss: 0.27791\n",
      "Epoch: 0 | Iteration: 160 | Classification loss: 0.15622 | Regression loss: 0.18067 | Running loss: 0.27827\n",
      "Epoch: 0 | Iteration: 161 | Classification loss: 0.12166 | Regression loss: 0.13584 | Running loss: 0.27815\n",
      "Epoch: 0 | Iteration: 162 | Classification loss: 0.12060 | Regression loss: 0.12890 | Running loss: 0.27797\n",
      "Epoch: 0 | Iteration: 163 | Classification loss: 0.11597 | Regression loss: 0.10400 | Running loss: 0.27762\n",
      "Epoch: 0 | Iteration: 164 | Classification loss: 0.12130 | Regression loss: 0.12925 | Running loss: 0.27745\n",
      "Epoch: 0 | Iteration: 165 | Classification loss: 0.15972 | Regression loss: 0.17201 | Running loss: 0.27778\n",
      "Epoch: 0 | Iteration: 166 | Classification loss: 0.64840 | Regression loss: 0.84263 | Running loss: 0.28504\n",
      "\n",
      " Total Time - 1526\n",
      "\n",
      "get detections on train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4798a6b575204bc89a661feabb7908ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get detections on valid dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09b2bff91cb43cb9da9859bb87ae688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "mAP on training dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4696,Precision:0.1247,Recall:0.8076\n",
      "AP@0.4:0.3385,Precision:0.1037,Recall:0.6716\n",
      "AP@0.6:0.0855,Precision:0.0580,Recall:0.3756\n",
      "AP@0.5:0.1941,Precision:0.0836,Recall:0.5412\n",
      "AP@0.7:0.0150,Precision:0.0241,Recall:0.1563\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.0106,Precision:0.0427,Recall:0.1695\n",
      "AP@0.4:0.0056,Precision:0.0303,Recall:0.1199\n",
      "AP@0.6:0.0004,Precision:0.0069,Recall:0.0274\n",
      "AP@0.5:0.0014,Precision:0.0151,Recall:0.0600\n",
      "AP@0.7:0.0000,Precision:0.0020,Recall:0.0078\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.0073,Precision:0.0487,Recall:0.0965\n",
      "AP@0.4:0.0038,Precision:0.0336,Recall:0.0665\n",
      "AP@0.6:0.0003,Precision:0.0086,Recall:0.0169\n",
      "AP@0.5:0.0010,Precision:0.0171,Recall:0.0339\n",
      "AP@0.7:0.0000,Precision:0.0026,Recall:0.0052\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.0054,Precision:0.0577,Recall:0.0626\n",
      "AP@0.4:0.0031,Precision:0.0433,Recall:0.0469\n",
      "AP@0.6:0.0002,Precision:0.0096,Recall:0.0104\n",
      "AP@0.5:0.0008,Precision:0.0228,Recall:0.0248\n",
      "AP@0.7:0.0000,Precision:0.0024,Recall:0.0026\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.0041,Precision:0.0688,Recall:0.0417\n",
      "AP@0.4:0.0024,Precision:0.0538,Recall:0.0326\n",
      "AP@0.6:0.0002,Precision:0.0151,Recall:0.0091\n",
      "AP@0.5:0.0006,Precision:0.0258,Recall:0.0156\n",
      "AP@0.7:0.0000,Precision:0.0022,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.0031,Precision:0.0950,Recall:0.0300\n",
      "AP@0.4:0.0017,Precision:0.0702,Recall:0.0222\n",
      "AP@0.6:0.0002,Precision:0.0165,Recall:0.0052\n",
      "AP@0.5:0.0004,Precision:0.0331,Recall:0.0104\n",
      "AP@0.7:0.0000,Precision:0.0041,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0010,Precision:0.0841,Recall:0.0117\n",
      "AP@0.4:0.0006,Precision:0.0654,Recall:0.0091\n",
      "AP@0.6:0.0001,Precision:0.0280,Recall:0.0039\n",
      "AP@0.5:0.0001,Precision:0.0280,Recall:0.0039\n",
      "AP@0.7:0.0000,Precision:0.0093,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0001,Precision:0.0270,Recall:0.0013\n",
      "AP@0.4:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.6:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.5:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.4:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.6:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.5:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.4:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.6:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.5:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "====================================================================================================\n",
      "mAP on validating dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4182,Precision:0.0857,Recall:0.8438\n",
      "AP@0.4:0.3254,Precision:0.0766,Recall:0.7539\n",
      "AP@0.6:0.0786,Precision:0.0408,Recall:0.4013\n",
      "AP@0.5:0.1861,Precision:0.0611,Recall:0.6014\n",
      "AP@0.7:0.0164,Precision:0.0181,Recall:0.1782\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.4088,Precision:0.1849,Recall:0.7774\n",
      "AP@0.4:0.3175,Precision:0.1645,Recall:0.6917\n",
      "AP@0.6:0.0761,Precision:0.0866,Recall:0.3642\n",
      "AP@0.5:0.1806,Precision:0.1302,Recall:0.5475\n",
      "AP@0.7:0.0159,Precision:0.0381,Recall:0.1604\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.3715,Precision:0.3089,Recall:0.6280\n",
      "AP@0.4:0.2886,Precision:0.2765,Recall:0.5622\n",
      "AP@0.6:0.0674,Precision:0.1424,Recall:0.2894\n",
      "AP@0.5:0.1620,Precision:0.2167,Recall:0.4404\n",
      "AP@0.7:0.0144,Precision:0.0650,Recall:0.1322\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.3142,Precision:0.4365,Recall:0.4754\n",
      "AP@0.4:0.2409,Precision:0.3851,Recall:0.4195\n",
      "AP@0.6:0.0535,Precision:0.1918,Recall:0.2090\n",
      "AP@0.5:0.1311,Precision:0.2940,Recall:0.3203\n",
      "AP@0.7:0.0116,Precision:0.0882,Recall:0.0961\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.2438,Precision:0.5458,Recall:0.3328\n",
      "AP@0.4:0.1842,Precision:0.4739,Recall:0.2889\n",
      "AP@0.6:0.0389,Precision:0.2296,Recall:0.1400\n",
      "AP@0.5:0.0970,Precision:0.3556,Recall:0.2168\n",
      "AP@0.7:0.0085,Precision:0.1063,Recall:0.0648\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.1681,Precision:0.6837,Recall:0.2100\n",
      "AP@0.4:0.1262,Precision:0.5884,Recall:0.1808\n",
      "AP@0.6:0.0235,Precision:0.2534,Recall:0.0778\n",
      "AP@0.5:0.0612,Precision:0.4133,Recall:0.1270\n",
      "AP@0.7:0.0053,Precision:0.1207,Recall:0.0371\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0941,Precision:0.7992,Recall:0.1102\n",
      "AP@0.4:0.0714,Precision:0.7045,Recall:0.0972\n",
      "AP@0.6:0.0129,Precision:0.2955,Recall:0.0408\n",
      "AP@0.5:0.0340,Precision:0.4848,Recall:0.0669\n",
      "AP@0.7:0.0028,Precision:0.1402,Recall:0.0193\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0457,Precision:0.8235,Recall:0.0512\n",
      "AP@0.4:0.0323,Precision:0.6891,Recall:0.0428\n",
      "AP@0.6:0.0050,Precision:0.2353,Recall:0.0146\n",
      "AP@0.5:0.0146,Precision:0.4538,Recall:0.0282\n",
      "AP@0.7:0.0009,Precision:0.1008,Recall:0.0063\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0177,Precision:0.9000,Recall:0.0188\n",
      "AP@0.4:0.0127,Precision:0.7500,Recall:0.0157\n",
      "AP@0.6:0.0021,Precision:0.2250,Recall:0.0047\n",
      "AP@0.5:0.0058,Precision:0.4750,Recall:0.0099\n",
      "AP@0.7:0.0001,Precision:0.0500,Recall:0.0010\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0052,Precision:1.0000,Recall:0.0052\n",
      "AP@0.4:0.0035,Precision:0.7000,Recall:0.0037\n",
      "AP@0.6:0.0013,Precision:0.3000,Recall:0.0016\n",
      "AP@0.5:0.0019,Precision:0.5000,Recall:0.0026\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "Epoch - 1 Started\n",
      "Epoch: 1 | Iteration: 0 | Classification loss: 0.10332 | Regression loss: 0.11112 | Running loss: 0.21444\n",
      "Epoch: 1 | Iteration: 1 | Classification loss: 0.12170 | Regression loss: 0.13749 | Running loss: 0.23682\n",
      "Epoch: 1 | Iteration: 2 | Classification loss: 0.11941 | Regression loss: 0.12520 | Running loss: 0.23942\n",
      "Epoch: 1 | Iteration: 3 | Classification loss: 0.10197 | Regression loss: 0.11744 | Running loss: 0.23441\n",
      "Epoch: 1 | Iteration: 4 | Classification loss: 0.11872 | Regression loss: 0.14038 | Running loss: 0.23935\n",
      "Epoch: 1 | Iteration: 5 | Classification loss: 0.10664 | Regression loss: 0.11107 | Running loss: 0.23574\n",
      "Epoch: 1 | Iteration: 6 | Classification loss: 0.10024 | Regression loss: 0.10521 | Running loss: 0.23142\n",
      "Epoch: 1 | Iteration: 7 | Classification loss: 0.07541 | Regression loss: 0.08992 | Running loss: 0.22316\n",
      "Epoch: 1 | Iteration: 8 | Classification loss: 0.11154 | Regression loss: 0.10425 | Running loss: 0.22234\n",
      "Epoch: 1 | Iteration: 9 | Classification loss: 0.10699 | Regression loss: 0.12476 | Running loss: 0.22328\n",
      "Epoch: 1 | Iteration: 10 | Classification loss: 0.11630 | Regression loss: 0.14632 | Running loss: 0.22686\n",
      "Epoch: 1 | Iteration: 11 | Classification loss: 0.08186 | Regression loss: 0.09274 | Running loss: 0.22250\n",
      "Epoch: 1 | Iteration: 12 | Classification loss: 0.10268 | Regression loss: 0.11726 | Running loss: 0.22230\n",
      "Epoch: 1 | Iteration: 13 | Classification loss: 0.14056 | Regression loss: 0.17235 | Running loss: 0.22878\n",
      "Epoch: 1 | Iteration: 14 | Classification loss: 0.10402 | Regression loss: 0.10726 | Running loss: 0.22761\n",
      "Epoch: 1 | Iteration: 15 | Classification loss: 0.09912 | Regression loss: 0.11044 | Running loss: 0.22648\n",
      "Epoch: 1 | Iteration: 16 | Classification loss: 0.13499 | Regression loss: 0.13185 | Running loss: 0.22886\n",
      "Epoch: 1 | Iteration: 17 | Classification loss: 0.07398 | Regression loss: 0.06793 | Running loss: 0.22403\n",
      "Epoch: 1 | Iteration: 18 | Classification loss: 0.10398 | Regression loss: 0.11174 | Running loss: 0.22359\n",
      "Epoch: 1 | Iteration: 19 | Classification loss: 0.12122 | Regression loss: 0.13426 | Running loss: 0.22518\n",
      "Epoch: 1 | Iteration: 20 | Classification loss: 0.08116 | Regression loss: 0.10025 | Running loss: 0.22310\n",
      "Epoch: 1 | Iteration: 21 | Classification loss: 0.10228 | Regression loss: 0.12690 | Running loss: 0.22338\n",
      "Epoch: 1 | Iteration: 22 | Classification loss: 0.09158 | Regression loss: 0.07413 | Running loss: 0.22087\n",
      "Epoch: 1 | Iteration: 23 | Classification loss: 0.11547 | Regression loss: 0.13892 | Running loss: 0.22227\n",
      "Epoch: 1 | Iteration: 24 | Classification loss: 0.12163 | Regression loss: 0.14279 | Running loss: 0.22395\n",
      "Epoch: 1 | Iteration: 25 | Classification loss: 0.12971 | Regression loss: 0.13112 | Running loss: 0.22537\n",
      "Epoch: 1 | Iteration: 26 | Classification loss: 0.06255 | Regression loss: 0.07402 | Running loss: 0.22208\n",
      "Epoch: 1 | Iteration: 27 | Classification loss: 0.12216 | Regression loss: 0.12934 | Running loss: 0.22313\n",
      "Epoch: 1 | Iteration: 28 | Classification loss: 0.10217 | Regression loss: 0.10402 | Running loss: 0.22255\n",
      "Epoch: 1 | Iteration: 29 | Classification loss: 0.12353 | Regression loss: 0.12896 | Running loss: 0.22355\n",
      "Epoch: 1 | Iteration: 30 | Classification loss: 0.08221 | Regression loss: 0.10343 | Running loss: 0.22232\n",
      "Epoch: 1 | Iteration: 31 | Classification loss: 0.13240 | Regression loss: 0.13746 | Running loss: 0.22381\n",
      "Epoch: 1 | Iteration: 32 | Classification loss: 0.08887 | Regression loss: 0.08497 | Running loss: 0.22229\n",
      "Epoch: 1 | Iteration: 33 | Classification loss: 0.07569 | Regression loss: 0.08349 | Running loss: 0.22044\n",
      "Epoch: 1 | Iteration: 34 | Classification loss: 0.12768 | Regression loss: 0.11952 | Running loss: 0.22120\n",
      "Epoch: 1 | Iteration: 35 | Classification loss: 0.10873 | Regression loss: 0.13734 | Running loss: 0.22189\n",
      "Epoch: 1 | Iteration: 36 | Classification loss: 0.12913 | Regression loss: 0.13493 | Running loss: 0.22303\n",
      "Epoch: 1 | Iteration: 37 | Classification loss: 0.12361 | Regression loss: 0.13126 | Running loss: 0.22387\n",
      "Epoch: 1 | Iteration: 38 | Classification loss: 0.09172 | Regression loss: 0.10999 | Running loss: 0.22330\n",
      "Epoch: 1 | Iteration: 39 | Classification loss: 0.12637 | Regression loss: 0.12633 | Running loss: 0.22404\n",
      "Epoch: 1 | Iteration: 40 | Classification loss: 0.10837 | Regression loss: 0.11915 | Running loss: 0.22412\n",
      "Epoch: 1 | Iteration: 41 | Classification loss: 0.11199 | Regression loss: 0.12107 | Running loss: 0.22434\n",
      "Epoch: 1 | Iteration: 42 | Classification loss: 0.10591 | Regression loss: 0.10947 | Running loss: 0.22413\n",
      "Epoch: 1 | Iteration: 43 | Classification loss: 0.12253 | Regression loss: 0.13757 | Running loss: 0.22495\n",
      "Epoch: 1 | Iteration: 44 | Classification loss: 0.13603 | Regression loss: 0.15292 | Running loss: 0.22637\n",
      "Epoch: 1 | Iteration: 45 | Classification loss: 0.14153 | Regression loss: 0.16098 | Running loss: 0.22802\n",
      "Epoch: 1 | Iteration: 46 | Classification loss: 0.09790 | Regression loss: 0.08858 | Running loss: 0.22714\n",
      "Epoch: 1 | Iteration: 47 | Classification loss: 0.10316 | Regression loss: 0.08385 | Running loss: 0.22630\n",
      "Epoch: 1 | Iteration: 48 | Classification loss: 0.11937 | Regression loss: 0.11454 | Running loss: 0.22646\n",
      "Epoch: 1 | Iteration: 49 | Classification loss: 0.14520 | Regression loss: 0.17903 | Running loss: 0.22841\n",
      "Epoch: 1 | Iteration: 50 | Classification loss: 0.07406 | Regression loss: 0.07588 | Running loss: 0.22688\n",
      "Epoch: 1 | Iteration: 51 | Classification loss: 0.10848 | Regression loss: 0.12878 | Running loss: 0.22707\n",
      "Epoch: 1 | Iteration: 52 | Classification loss: 0.13019 | Regression loss: 0.14853 | Running loss: 0.22805\n",
      "Epoch: 1 | Iteration: 53 | Classification loss: 0.10698 | Regression loss: 0.12630 | Running loss: 0.22815\n",
      "Epoch: 1 | Iteration: 54 | Classification loss: 0.09652 | Regression loss: 0.11918 | Running loss: 0.22792\n",
      "Epoch: 1 | Iteration: 55 | Classification loss: 0.10782 | Regression loss: 0.13362 | Running loss: 0.22816\n",
      "Epoch: 1 | Iteration: 56 | Classification loss: 0.12714 | Regression loss: 0.10517 | Running loss: 0.22823\n",
      "Epoch: 1 | Iteration: 57 | Classification loss: 0.13935 | Regression loss: 0.09816 | Running loss: 0.22839\n",
      "Epoch: 1 | Iteration: 58 | Classification loss: 0.11521 | Regression loss: 0.12493 | Running loss: 0.22859\n",
      "Epoch: 1 | Iteration: 59 | Classification loss: 0.09008 | Regression loss: 0.10564 | Running loss: 0.22804\n",
      "Epoch: 1 | Iteration: 60 | Classification loss: 0.10236 | Regression loss: 0.10728 | Running loss: 0.22774\n",
      "Epoch: 1 | Iteration: 61 | Classification loss: 0.09287 | Regression loss: 0.10464 | Running loss: 0.22726\n",
      "Epoch: 1 | Iteration: 62 | Classification loss: 0.10609 | Regression loss: 0.12689 | Running loss: 0.22735\n",
      "Epoch: 1 | Iteration: 63 | Classification loss: 0.12119 | Regression loss: 0.13979 | Running loss: 0.22787\n",
      "Epoch: 1 | Iteration: 64 | Classification loss: 0.10828 | Regression loss: 0.11477 | Running loss: 0.22780\n",
      "Epoch: 1 | Iteration: 65 | Classification loss: 0.13262 | Regression loss: 0.12042 | Running loss: 0.22818\n",
      "Epoch: 1 | Iteration: 66 | Classification loss: 0.13046 | Regression loss: 0.11352 | Running loss: 0.22842\n",
      "Epoch: 1 | Iteration: 67 | Classification loss: 0.14294 | Regression loss: 0.15561 | Running loss: 0.22945\n",
      "Epoch: 1 | Iteration: 68 | Classification loss: 0.11594 | Regression loss: 0.14018 | Running loss: 0.22983\n",
      "Epoch: 1 | Iteration: 69 | Classification loss: 0.08910 | Regression loss: 0.10256 | Running loss: 0.22929\n",
      "Epoch: 1 | Iteration: 70 | Classification loss: 0.10611 | Regression loss: 0.11252 | Running loss: 0.22914\n",
      "Epoch: 1 | Iteration: 71 | Classification loss: 0.09918 | Regression loss: 0.09399 | Running loss: 0.22864\n",
      "Epoch: 1 | Iteration: 72 | Classification loss: 0.12537 | Regression loss: 0.15038 | Running loss: 0.22928\n",
      "Epoch: 1 | Iteration: 73 | Classification loss: 0.11003 | Regression loss: 0.10896 | Running loss: 0.22915\n",
      "Epoch: 1 | Iteration: 74 | Classification loss: 0.15872 | Regression loss: 0.09913 | Running loss: 0.22953\n",
      "Epoch: 1 | Iteration: 75 | Classification loss: 0.12583 | Regression loss: 0.14955 | Running loss: 0.23013\n",
      "Epoch: 1 | Iteration: 76 | Classification loss: 0.15604 | Regression loss: 0.12391 | Running loss: 0.23078\n",
      "Epoch: 1 | Iteration: 77 | Classification loss: 0.14552 | Regression loss: 0.15606 | Running loss: 0.23169\n",
      "Epoch: 1 | Iteration: 78 | Classification loss: 0.10999 | Regression loss: 0.11521 | Running loss: 0.23160\n",
      "Epoch: 1 | Iteration: 79 | Classification loss: 0.08448 | Regression loss: 0.08368 | Running loss: 0.23081\n",
      "Epoch: 1 | Iteration: 80 | Classification loss: 0.10744 | Regression loss: 0.11548 | Running loss: 0.23071\n",
      "Epoch: 1 | Iteration: 81 | Classification loss: 0.11054 | Regression loss: 0.12063 | Running loss: 0.23072\n",
      "Epoch: 1 | Iteration: 82 | Classification loss: 0.12823 | Regression loss: 0.13659 | Running loss: 0.23113\n",
      "Epoch: 1 | Iteration: 83 | Classification loss: 0.11794 | Regression loss: 0.14222 | Running loss: 0.23148\n",
      "Epoch: 1 | Iteration: 84 | Classification loss: 0.13736 | Regression loss: 0.13827 | Running loss: 0.23200\n",
      "Epoch: 1 | Iteration: 85 | Classification loss: 0.11847 | Regression loss: 0.13178 | Running loss: 0.23221\n",
      "Epoch: 1 | Iteration: 86 | Classification loss: 0.10795 | Regression loss: 0.11661 | Running loss: 0.23212\n",
      "Epoch: 1 | Iteration: 87 | Classification loss: 0.11765 | Regression loss: 0.11715 | Running loss: 0.23215\n",
      "Epoch: 1 | Iteration: 88 | Classification loss: 0.08619 | Regression loss: 0.09447 | Running loss: 0.23157\n",
      "Epoch: 1 | Iteration: 89 | Classification loss: 0.09695 | Regression loss: 0.10801 | Running loss: 0.23128\n",
      "Epoch: 1 | Iteration: 90 | Classification loss: 0.10890 | Regression loss: 0.11926 | Running loss: 0.23124\n",
      "Epoch: 1 | Iteration: 91 | Classification loss: 0.11842 | Regression loss: 0.14025 | Running loss: 0.23154\n",
      "Epoch: 1 | Iteration: 92 | Classification loss: 0.10945 | Regression loss: 0.10825 | Running loss: 0.23139\n",
      "Epoch: 1 | Iteration: 93 | Classification loss: 0.10453 | Regression loss: 0.15003 | Running loss: 0.23164\n",
      "Epoch: 1 | Iteration: 94 | Classification loss: 0.11293 | Regression loss: 0.11968 | Running loss: 0.23165\n",
      "Epoch: 1 | Iteration: 95 | Classification loss: 0.13793 | Regression loss: 0.11090 | Running loss: 0.23183\n",
      "Epoch: 1 | Iteration: 96 | Classification loss: 0.10641 | Regression loss: 0.11326 | Running loss: 0.23170\n",
      "Epoch: 1 | Iteration: 97 | Classification loss: 0.11003 | Regression loss: 0.11747 | Running loss: 0.23166\n",
      "Epoch: 1 | Iteration: 98 | Classification loss: 0.11214 | Regression loss: 0.12839 | Running loss: 0.23175\n",
      "Epoch: 1 | Iteration: 99 | Classification loss: 0.10585 | Regression loss: 0.12283 | Running loss: 0.23172\n",
      "Epoch: 1 | Iteration: 100 | Classification loss: 0.14694 | Regression loss: 0.14698 | Running loss: 0.23233\n",
      "Epoch: 1 | Iteration: 101 | Classification loss: 0.11826 | Regression loss: 0.11165 | Running loss: 0.23231\n",
      "Epoch: 1 | Iteration: 102 | Classification loss: 0.12916 | Regression loss: 0.07815 | Running loss: 0.23207\n",
      "Epoch: 1 | Iteration: 103 | Classification loss: 0.16261 | Regression loss: 0.11875 | Running loss: 0.23254\n",
      "Epoch: 1 | Iteration: 104 | Classification loss: 0.09986 | Regression loss: 0.12055 | Running loss: 0.23243\n",
      "Epoch: 1 | Iteration: 105 | Classification loss: 0.11009 | Regression loss: 0.11456 | Running loss: 0.23235\n",
      "Epoch: 1 | Iteration: 106 | Classification loss: 0.11178 | Regression loss: 0.12332 | Running loss: 0.23238\n",
      "Epoch: 1 | Iteration: 107 | Classification loss: 0.13762 | Regression loss: 0.14261 | Running loss: 0.23282\n",
      "Epoch: 1 | Iteration: 108 | Classification loss: 0.07787 | Regression loss: 0.07905 | Running loss: 0.23212\n",
      "Epoch: 1 | Iteration: 109 | Classification loss: 0.12786 | Regression loss: 0.13052 | Running loss: 0.23236\n",
      "Epoch: 1 | Iteration: 110 | Classification loss: 0.12202 | Regression loss: 0.13268 | Running loss: 0.23256\n",
      "Epoch: 1 | Iteration: 111 | Classification loss: 0.12400 | Regression loss: 0.12822 | Running loss: 0.23274\n",
      "Epoch: 1 | Iteration: 112 | Classification loss: 0.10334 | Regression loss: 0.11492 | Running loss: 0.23261\n",
      "Epoch: 1 | Iteration: 113 | Classification loss: 0.14049 | Regression loss: 0.13107 | Running loss: 0.23295\n",
      "Epoch: 1 | Iteration: 114 | Classification loss: 0.11721 | Regression loss: 0.14143 | Running loss: 0.23318\n",
      "Epoch: 1 | Iteration: 115 | Classification loss: 0.13508 | Regression loss: 0.16468 | Running loss: 0.23375\n",
      "Epoch: 1 | Iteration: 116 | Classification loss: 0.09144 | Regression loss: 0.10887 | Running loss: 0.23346\n",
      "Epoch: 1 | Iteration: 117 | Classification loss: 0.08630 | Regression loss: 0.09211 | Running loss: 0.23300\n",
      "Epoch: 1 | Iteration: 118 | Classification loss: 0.11755 | Regression loss: 0.12732 | Running loss: 0.23310\n",
      "Epoch: 1 | Iteration: 119 | Classification loss: 0.09311 | Regression loss: 0.10271 | Running loss: 0.23279\n",
      "Epoch: 1 | Iteration: 120 | Classification loss: 0.09360 | Regression loss: 0.10971 | Running loss: 0.23254\n",
      "Epoch: 1 | Iteration: 121 | Classification loss: 0.11925 | Regression loss: 0.13922 | Running loss: 0.23276\n",
      "Epoch: 1 | Iteration: 122 | Classification loss: 0.11366 | Regression loss: 0.13415 | Running loss: 0.23288\n",
      "Epoch: 1 | Iteration: 123 | Classification loss: 0.11245 | Regression loss: 0.10823 | Running loss: 0.23278\n",
      "Epoch: 1 | Iteration: 124 | Classification loss: 0.13182 | Regression loss: 0.09684 | Running loss: 0.23275\n",
      "Epoch: 1 | Iteration: 125 | Classification loss: 0.09043 | Regression loss: 0.12649 | Running loss: 0.23262\n",
      "Epoch: 1 | Iteration: 126 | Classification loss: 0.09643 | Regression loss: 0.10512 | Running loss: 0.23238\n",
      "Epoch: 1 | Iteration: 127 | Classification loss: 0.11843 | Regression loss: 0.12594 | Running loss: 0.23247\n",
      "Epoch: 1 | Iteration: 128 | Classification loss: 0.14216 | Regression loss: 0.15637 | Running loss: 0.23298\n",
      "Epoch: 1 | Iteration: 129 | Classification loss: 0.11233 | Regression loss: 0.11735 | Running loss: 0.23296\n",
      "Epoch: 1 | Iteration: 130 | Classification loss: 0.10432 | Regression loss: 0.12196 | Running loss: 0.23291\n",
      "Epoch: 1 | Iteration: 131 | Classification loss: 0.11216 | Regression loss: 0.11301 | Running loss: 0.23285\n",
      "Epoch: 1 | Iteration: 132 | Classification loss: 0.11722 | Regression loss: 0.11545 | Running loss: 0.23285\n",
      "Epoch: 1 | Iteration: 133 | Classification loss: 0.11413 | Regression loss: 0.11485 | Running loss: 0.23282\n",
      "Epoch: 1 | Iteration: 134 | Classification loss: 0.09511 | Regression loss: 0.09879 | Running loss: 0.23253\n",
      "Epoch: 1 | Iteration: 135 | Classification loss: 0.10239 | Regression loss: 0.12437 | Running loss: 0.23249\n",
      "Epoch: 1 | Iteration: 136 | Classification loss: 0.14769 | Regression loss: 0.14400 | Running loss: 0.23292\n",
      "Epoch: 1 | Iteration: 137 | Classification loss: 0.13568 | Regression loss: 0.15167 | Running loss: 0.23331\n",
      "Epoch: 1 | Iteration: 138 | Classification loss: 0.08711 | Regression loss: 0.09315 | Running loss: 0.23293\n",
      "Epoch: 1 | Iteration: 139 | Classification loss: 0.14703 | Regression loss: 0.16398 | Running loss: 0.23349\n",
      "Epoch: 1 | Iteration: 140 | Classification loss: 0.09852 | Regression loss: 0.09809 | Running loss: 0.23323\n",
      "Epoch: 1 | Iteration: 141 | Classification loss: 0.12672 | Regression loss: 0.14551 | Running loss: 0.23350\n",
      "Epoch: 1 | Iteration: 142 | Classification loss: 0.13418 | Regression loss: 0.11092 | Running loss: 0.23358\n",
      "Epoch: 1 | Iteration: 143 | Classification loss: 0.08569 | Regression loss: 0.08918 | Running loss: 0.23318\n",
      "Epoch: 1 | Iteration: 144 | Classification loss: 0.13082 | Regression loss: 0.12249 | Running loss: 0.23331\n",
      "Epoch: 1 | Iteration: 145 | Classification loss: 0.13402 | Regression loss: 0.12433 | Running loss: 0.23349\n",
      "Epoch: 1 | Iteration: 146 | Classification loss: 0.13324 | Regression loss: 0.12894 | Running loss: 0.23368\n",
      "Epoch: 1 | Iteration: 147 | Classification loss: 0.15151 | Regression loss: 0.14564 | Running loss: 0.23411\n",
      "Epoch: 1 | Iteration: 148 | Classification loss: 0.11528 | Regression loss: 0.11484 | Running loss: 0.23408\n",
      "Epoch: 1 | Iteration: 149 | Classification loss: 0.08287 | Regression loss: 0.08920 | Running loss: 0.23367\n",
      "Epoch: 1 | Iteration: 150 | Classification loss: 0.08775 | Regression loss: 0.10290 | Running loss: 0.23339\n",
      "Epoch: 1 | Iteration: 151 | Classification loss: 0.08723 | Regression loss: 0.10633 | Running loss: 0.23312\n",
      "Epoch: 1 | Iteration: 152 | Classification loss: 0.09474 | Regression loss: 0.10321 | Running loss: 0.23289\n",
      "Epoch: 1 | Iteration: 153 | Classification loss: 0.10095 | Regression loss: 0.12390 | Running loss: 0.23284\n",
      "Epoch: 1 | Iteration: 154 | Classification loss: 0.09040 | Regression loss: 0.12096 | Running loss: 0.23270\n",
      "Epoch: 1 | Iteration: 155 | Classification loss: 0.11470 | Regression loss: 0.13392 | Running loss: 0.23280\n",
      "Epoch: 1 | Iteration: 156 | Classification loss: 0.11264 | Regression loss: 0.11908 | Running loss: 0.23280\n",
      "Epoch: 1 | Iteration: 157 | Classification loss: 0.13958 | Regression loss: 0.13433 | Running loss: 0.23306\n",
      "Epoch: 1 | Iteration: 158 | Classification loss: 0.08219 | Regression loss: 0.07003 | Running loss: 0.23255\n",
      "Epoch: 1 | Iteration: 159 | Classification loss: 0.08199 | Regression loss: 0.08346 | Running loss: 0.23213\n",
      "Epoch: 1 | Iteration: 160 | Classification loss: 0.09770 | Regression loss: 0.09588 | Running loss: 0.23189\n",
      "Epoch: 1 | Iteration: 161 | Classification loss: 0.09915 | Regression loss: 0.10049 | Running loss: 0.23169\n",
      "Epoch: 1 | Iteration: 162 | Classification loss: 0.11602 | Regression loss: 0.11181 | Running loss: 0.23167\n",
      "Epoch: 1 | Iteration: 163 | Classification loss: 0.15360 | Regression loss: 0.14842 | Running loss: 0.23210\n",
      "Epoch: 1 | Iteration: 164 | Classification loss: 0.12769 | Regression loss: 0.14328 | Running loss: 0.23233\n",
      "Epoch: 1 | Iteration: 165 | Classification loss: 0.13762 | Regression loss: 0.11749 | Running loss: 0.23247\n",
      "Epoch: 1 | Iteration: 166 | Classification loss: 0.27503 | Regression loss: 0.00000 | Running loss: 0.23272\n",
      "\n",
      " Total Time - 1449\n",
      "\n",
      "get detections on train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1b563aaed84843a0b9cd4920c30f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get detections on valid dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c74c33907447f7963e08540d7bce00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "mAP on training dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4928,Precision:0.1762,Recall:0.8353\n",
      "AP@0.4:0.4051,Precision:0.1534,Recall:0.7271\n",
      "AP@0.6:0.1695,Precision:0.1038,Recall:0.4921\n",
      "AP@0.5:0.3029,Precision:0.1335,Recall:0.6327\n",
      "AP@0.7:0.0482,Precision:0.0507,Recall:0.2405\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.0123,Precision:0.0458,Recall:0.1917\n",
      "AP@0.4:0.0057,Precision:0.0302,Recall:0.1265\n",
      "AP@0.6:0.0005,Precision:0.0078,Recall:0.0326\n",
      "AP@0.5:0.0020,Precision:0.0187,Recall:0.0782\n",
      "AP@0.7:0.0001,Precision:0.0028,Recall:0.0117\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.0095,Precision:0.0483,Recall:0.1330\n",
      "AP@0.4:0.0044,Precision:0.0313,Recall:0.0860\n",
      "AP@0.6:0.0004,Precision:0.0090,Recall:0.0248\n",
      "AP@0.5:0.0016,Precision:0.0209,Recall:0.0574\n",
      "AP@0.7:0.0001,Precision:0.0038,Recall:0.0104\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.0082,Precision:0.0559,Recall:0.1082\n",
      "AP@0.4:0.0039,Precision:0.0370,Recall:0.0717\n",
      "AP@0.6:0.0003,Precision:0.0094,Recall:0.0183\n",
      "AP@0.5:0.0013,Precision:0.0222,Recall:0.0430\n",
      "AP@0.7:0.0001,Precision:0.0047,Recall:0.0091\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.0066,Precision:0.0600,Recall:0.0808\n",
      "AP@0.4:0.0030,Precision:0.0348,Recall:0.0469\n",
      "AP@0.6:0.0003,Precision:0.0097,Recall:0.0130\n",
      "AP@0.5:0.0009,Precision:0.0194,Recall:0.0261\n",
      "AP@0.7:0.0001,Precision:0.0058,Recall:0.0078\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.0056,Precision:0.0680,Recall:0.0639\n",
      "AP@0.4:0.0027,Precision:0.0402,Recall:0.0378\n",
      "AP@0.6:0.0003,Precision:0.0125,Recall:0.0117\n",
      "AP@0.5:0.0008,Precision:0.0222,Recall:0.0209\n",
      "AP@0.7:0.0001,Precision:0.0069,Recall:0.0065\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0045,Precision:0.0754,Recall:0.0495\n",
      "AP@0.4:0.0025,Precision:0.0516,Recall:0.0339\n",
      "AP@0.6:0.0003,Precision:0.0179,Recall:0.0117\n",
      "AP@0.5:0.0008,Precision:0.0317,Recall:0.0209\n",
      "AP@0.7:0.0001,Precision:0.0099,Recall:0.0065\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0031,Precision:0.0690,Recall:0.0313\n",
      "AP@0.4:0.0019,Precision:0.0517,Recall:0.0235\n",
      "AP@0.6:0.0002,Precision:0.0201,Recall:0.0091\n",
      "AP@0.5:0.0006,Precision:0.0345,Recall:0.0156\n",
      "AP@0.7:0.0001,Precision:0.0115,Recall:0.0052\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0023,Precision:0.0672,Recall:0.0209\n",
      "AP@0.4:0.0013,Precision:0.0462,Recall:0.0143\n",
      "AP@0.6:0.0001,Precision:0.0168,Recall:0.0052\n",
      "AP@0.5:0.0002,Precision:0.0252,Recall:0.0078\n",
      "AP@0.7:0.0000,Precision:0.0084,Recall:0.0026\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0020,Precision:0.0807,Recall:0.0169\n",
      "AP@0.4:0.0010,Precision:0.0435,Recall:0.0091\n",
      "AP@0.6:0.0000,Precision:0.0124,Recall:0.0026\n",
      "AP@0.5:0.0001,Precision:0.0248,Recall:0.0052\n",
      "AP@0.7:0.0000,Precision:0.0062,Recall:0.0013\n",
      "\n",
      "====================================================================================================\n",
      "mAP on validating dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.3816,Precision:0.1194,Recall:0.8563\n",
      "AP@0.4:0.3247,Precision:0.1082,Recall:0.7759\n",
      "AP@0.6:0.1466,Precision:0.0686,Recall:0.4922\n",
      "AP@0.5:0.2519,Precision:0.0928,Recall:0.6656\n",
      "AP@0.7:0.0471,Precision:0.0354,Recall:0.2539\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.3728,Precision:0.1776,Recall:0.7989\n",
      "AP@0.4:0.3175,Precision:0.1610,Recall:0.7241\n",
      "AP@0.6:0.1443,Precision:0.1039,Recall:0.4671\n",
      "AP@0.5:0.2477,Precision:0.1404,Recall:0.6311\n",
      "AP@0.7:0.0464,Precision:0.0536,Recall:0.2409\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.3549,Precision:0.2503,Recall:0.7158\n",
      "AP@0.4:0.3026,Precision:0.2266,Recall:0.6479\n",
      "AP@0.6:0.1376,Precision:0.1449,Recall:0.4143\n",
      "AP@0.5:0.2358,Precision:0.1962,Recall:0.5611\n",
      "AP@0.7:0.0448,Precision:0.0756,Recall:0.2163\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.3264,Precision:0.3224,Recall:0.6181\n",
      "AP@0.4:0.2790,Precision:0.2911,Recall:0.5580\n",
      "AP@0.6:0.1276,Precision:0.1848,Recall:0.3542\n",
      "AP@0.5:0.2179,Precision:0.2516,Recall:0.4822\n",
      "AP@0.7:0.0424,Precision:0.0984,Recall:0.1886\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.2880,Precision:0.3962,Recall:0.5104\n",
      "AP@0.4:0.2494,Precision:0.3617,Recall:0.4660\n",
      "AP@0.6:0.1159,Precision:0.2307,Recall:0.2973\n",
      "AP@0.5:0.1961,Precision:0.3135,Recall:0.4039\n",
      "AP@0.7:0.0390,Precision:0.1221,Recall:0.1573\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.2449,Precision:0.4601,Recall:0.4096\n",
      "AP@0.4:0.2146,Precision:0.4243,Recall:0.3777\n",
      "AP@0.6:0.1030,Precision:0.2764,Recall:0.2461\n",
      "AP@0.5:0.1709,Precision:0.3715,Recall:0.3307\n",
      "AP@0.7:0.0354,Precision:0.1473,Recall:0.1311\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.2065,Precision:0.5235,Recall:0.3318\n",
      "AP@0.4:0.1825,Precision:0.4847,Recall:0.3072\n",
      "AP@0.6:0.0899,Precision:0.3190,Recall:0.2022\n",
      "AP@0.5:0.1477,Precision:0.4303,Recall:0.2727\n",
      "AP@0.7:0.0320,Precision:0.1731,Recall:0.1097\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.1650,Precision:0.5729,Recall:0.2565\n",
      "AP@0.4:0.1475,Precision:0.5344,Recall:0.2393\n",
      "AP@0.6:0.0756,Precision:0.3594,Recall:0.1609\n",
      "AP@0.5:0.1208,Precision:0.4796,Recall:0.2147\n",
      "AP@0.7:0.0281,Precision:0.1995,Recall:0.0893\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.1258,Precision:0.5990,Recall:0.1897\n",
      "AP@0.4:0.1126,Precision:0.5545,Recall:0.1755\n",
      "AP@0.6:0.0599,Precision:0.3746,Recall:0.1186\n",
      "AP@0.5:0.0930,Precision:0.4983,Recall:0.1578\n",
      "AP@0.7:0.0233,Precision:0.2096,Recall:0.0664\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0924,Precision:0.6196,Recall:0.1353\n",
      "AP@0.4:0.0852,Precision:0.5837,Recall:0.1275\n",
      "AP@0.6:0.0476,Precision:0.3971,Recall:0.0867\n",
      "AP@0.5:0.0708,Precision:0.5263,Recall:0.1149\n",
      "AP@0.7:0.0195,Precision:0.2249,Recall:0.0491\n",
      "Epoch - 2 Started\n",
      "Epoch: 2 | Iteration: 0 | Classification loss: 0.14693 | Regression loss: 0.10447 | Running loss: 0.25139\n",
      "Epoch: 2 | Iteration: 1 | Classification loss: 0.11884 | Regression loss: 0.14088 | Running loss: 0.25556\n",
      "Epoch: 2 | Iteration: 2 | Classification loss: 0.10975 | Regression loss: 0.12330 | Running loss: 0.24805\n",
      "Epoch: 2 | Iteration: 3 | Classification loss: 0.10740 | Regression loss: 0.12009 | Running loss: 0.24291\n",
      "Epoch: 2 | Iteration: 4 | Classification loss: 0.11903 | Regression loss: 0.12343 | Running loss: 0.24282\n",
      "Epoch: 2 | Iteration: 5 | Classification loss: 0.11667 | Regression loss: 0.10314 | Running loss: 0.23899\n",
      "Epoch: 2 | Iteration: 6 | Classification loss: 0.09629 | Regression loss: 0.10520 | Running loss: 0.23363\n",
      "Epoch: 2 | Iteration: 7 | Classification loss: 0.12102 | Regression loss: 0.13908 | Running loss: 0.23694\n",
      "Epoch: 2 | Iteration: 8 | Classification loss: 0.12776 | Regression loss: 0.13770 | Running loss: 0.24011\n",
      "Epoch: 2 | Iteration: 9 | Classification loss: 0.08732 | Regression loss: 0.08203 | Running loss: 0.23303\n",
      "Epoch: 2 | Iteration: 10 | Classification loss: 0.07468 | Regression loss: 0.08197 | Running loss: 0.22609\n",
      "Epoch: 2 | Iteration: 11 | Classification loss: 0.08085 | Regression loss: 0.09478 | Running loss: 0.22188\n",
      "Epoch: 2 | Iteration: 12 | Classification loss: 0.14160 | Regression loss: 0.12727 | Running loss: 0.22550\n",
      "Epoch: 2 | Iteration: 13 | Classification loss: 0.11122 | Regression loss: 0.12148 | Running loss: 0.22601\n",
      "Epoch: 2 | Iteration: 14 | Classification loss: 0.12247 | Regression loss: 0.13334 | Running loss: 0.22800\n",
      "Epoch: 2 | Iteration: 15 | Classification loss: 0.09192 | Regression loss: 0.10756 | Running loss: 0.22622\n",
      "Epoch: 2 | Iteration: 16 | Classification loss: 0.09247 | Regression loss: 0.10853 | Running loss: 0.22473\n",
      "Epoch: 2 | Iteration: 17 | Classification loss: 0.09077 | Regression loss: 0.09589 | Running loss: 0.22262\n",
      "Epoch: 2 | Iteration: 18 | Classification loss: 0.07411 | Regression loss: 0.08245 | Running loss: 0.21914\n",
      "Epoch: 2 | Iteration: 19 | Classification loss: 0.10296 | Regression loss: 0.10898 | Running loss: 0.21878\n",
      "Epoch: 2 | Iteration: 20 | Classification loss: 0.07994 | Regression loss: 0.09797 | Running loss: 0.21684\n",
      "Epoch: 2 | Iteration: 21 | Classification loss: 0.10337 | Regression loss: 0.12371 | Running loss: 0.21730\n",
      "Epoch: 2 | Iteration: 22 | Classification loss: 0.12115 | Regression loss: 0.12387 | Running loss: 0.21851\n",
      "Epoch: 2 | Iteration: 23 | Classification loss: 0.10168 | Regression loss: 0.11686 | Running loss: 0.21851\n",
      "Epoch: 2 | Iteration: 24 | Classification loss: 0.08696 | Regression loss: 0.08849 | Running loss: 0.21679\n",
      "Epoch: 2 | Iteration: 25 | Classification loss: 0.08598 | Regression loss: 0.10029 | Running loss: 0.21561\n",
      "Epoch: 2 | Iteration: 26 | Classification loss: 0.13518 | Regression loss: 0.15336 | Running loss: 0.21831\n",
      "Epoch: 2 | Iteration: 27 | Classification loss: 0.11898 | Regression loss: 0.13404 | Running loss: 0.21955\n",
      "Epoch: 2 | Iteration: 28 | Classification loss: 0.09175 | Regression loss: 0.11349 | Running loss: 0.21906\n",
      "Epoch: 2 | Iteration: 29 | Classification loss: 0.10360 | Regression loss: 0.08540 | Running loss: 0.21806\n",
      "Epoch: 2 | Iteration: 30 | Classification loss: 0.11812 | Regression loss: 0.12279 | Running loss: 0.21879\n",
      "Epoch: 2 | Iteration: 31 | Classification loss: 0.11093 | Regression loss: 0.13141 | Running loss: 0.21953\n",
      "Epoch: 2 | Iteration: 32 | Classification loss: 0.09253 | Regression loss: 0.09904 | Running loss: 0.21868\n",
      "Epoch: 2 | Iteration: 33 | Classification loss: 0.10699 | Regression loss: 0.11721 | Running loss: 0.21885\n",
      "Epoch: 2 | Iteration: 34 | Classification loss: 0.06301 | Regression loss: 0.07107 | Running loss: 0.21642\n",
      "Epoch: 2 | Iteration: 35 | Classification loss: 0.10997 | Regression loss: 0.11028 | Running loss: 0.21653\n",
      "Epoch: 2 | Iteration: 36 | Classification loss: 0.07481 | Regression loss: 0.07979 | Running loss: 0.21486\n",
      "Epoch: 2 | Iteration: 37 | Classification loss: 0.07369 | Regression loss: 0.08543 | Running loss: 0.21339\n",
      "Epoch: 2 | Iteration: 38 | Classification loss: 0.10414 | Regression loss: 0.13285 | Running loss: 0.21399\n",
      "Epoch: 2 | Iteration: 39 | Classification loss: 0.11842 | Regression loss: 0.10157 | Running loss: 0.21414\n",
      "Epoch: 2 | Iteration: 40 | Classification loss: 0.12380 | Regression loss: 0.12608 | Running loss: 0.21502\n",
      "Epoch: 2 | Iteration: 41 | Classification loss: 0.09081 | Regression loss: 0.11137 | Running loss: 0.21471\n",
      "Epoch: 2 | Iteration: 42 | Classification loss: 0.10725 | Regression loss: 0.13253 | Running loss: 0.21529\n",
      "Epoch: 2 | Iteration: 43 | Classification loss: 0.09325 | Regression loss: 0.10520 | Running loss: 0.21491\n",
      "Epoch: 2 | Iteration: 44 | Classification loss: 0.09871 | Regression loss: 0.10564 | Running loss: 0.21468\n",
      "Epoch: 2 | Iteration: 45 | Classification loss: 0.09964 | Regression loss: 0.11455 | Running loss: 0.21467\n",
      "Epoch: 2 | Iteration: 46 | Classification loss: 0.10182 | Regression loss: 0.11621 | Running loss: 0.21474\n",
      "Epoch: 2 | Iteration: 47 | Classification loss: 0.09059 | Regression loss: 0.10719 | Running loss: 0.21438\n",
      "Epoch: 2 | Iteration: 48 | Classification loss: 0.11680 | Regression loss: 0.14338 | Running loss: 0.21532\n",
      "Epoch: 2 | Iteration: 49 | Classification loss: 0.16341 | Regression loss: 0.10423 | Running loss: 0.21636\n",
      "Epoch: 2 | Iteration: 50 | Classification loss: 0.13525 | Regression loss: 0.11716 | Running loss: 0.21707\n",
      "Epoch: 2 | Iteration: 51 | Classification loss: 0.16786 | Regression loss: 0.09341 | Running loss: 0.21792\n",
      "Epoch: 2 | Iteration: 52 | Classification loss: 0.09159 | Regression loss: 0.08545 | Running loss: 0.21715\n",
      "Epoch: 2 | Iteration: 53 | Classification loss: 0.11531 | Regression loss: 0.13233 | Running loss: 0.21771\n",
      "Epoch: 2 | Iteration: 54 | Classification loss: 0.11568 | Regression loss: 0.14086 | Running loss: 0.21842\n",
      "Epoch: 2 | Iteration: 55 | Classification loss: 0.12115 | Regression loss: 0.11764 | Running loss: 0.21878\n",
      "Epoch: 2 | Iteration: 56 | Classification loss: 0.09714 | Regression loss: 0.10484 | Running loss: 0.21849\n",
      "Epoch: 2 | Iteration: 57 | Classification loss: 0.10555 | Regression loss: 0.11297 | Running loss: 0.21849\n",
      "Epoch: 2 | Iteration: 58 | Classification loss: 0.12299 | Regression loss: 0.14085 | Running loss: 0.21926\n",
      "Epoch: 2 | Iteration: 59 | Classification loss: 0.10474 | Regression loss: 0.12398 | Running loss: 0.21942\n",
      "Epoch: 2 | Iteration: 60 | Classification loss: 0.12161 | Regression loss: 0.10315 | Running loss: 0.21950\n",
      "Epoch: 2 | Iteration: 61 | Classification loss: 0.18176 | Regression loss: 0.06848 | Running loss: 0.22000\n",
      "Epoch: 2 | Iteration: 62 | Classification loss: 0.08940 | Regression loss: 0.11611 | Running loss: 0.21977\n",
      "Epoch: 2 | Iteration: 63 | Classification loss: 0.12028 | Regression loss: 0.12719 | Running loss: 0.22020\n",
      "Epoch: 2 | Iteration: 64 | Classification loss: 0.08084 | Regression loss: 0.08866 | Running loss: 0.21942\n",
      "Epoch: 2 | Iteration: 65 | Classification loss: 0.07903 | Regression loss: 0.07969 | Running loss: 0.21850\n",
      "Epoch: 2 | Iteration: 66 | Classification loss: 0.12905 | Regression loss: 0.13142 | Running loss: 0.21913\n",
      "Epoch: 2 | Iteration: 67 | Classification loss: 0.12264 | Regression loss: 0.12586 | Running loss: 0.21956\n",
      "Epoch: 2 | Iteration: 68 | Classification loss: 0.12411 | Regression loss: 0.13804 | Running loss: 0.22018\n",
      "Epoch: 2 | Iteration: 69 | Classification loss: 0.08970 | Regression loss: 0.10300 | Running loss: 0.21979\n",
      "Epoch: 2 | Iteration: 70 | Classification loss: 0.09815 | Regression loss: 0.10336 | Running loss: 0.21953\n",
      "Epoch: 2 | Iteration: 71 | Classification loss: 0.10240 | Regression loss: 0.10052 | Running loss: 0.21930\n",
      "Epoch: 2 | Iteration: 72 | Classification loss: 0.11741 | Regression loss: 0.14679 | Running loss: 0.21991\n",
      "Epoch: 2 | Iteration: 73 | Classification loss: 0.12661 | Regression loss: 0.10549 | Running loss: 0.22008\n",
      "Epoch: 2 | Iteration: 74 | Classification loss: 0.11162 | Regression loss: 0.09812 | Running loss: 0.21994\n",
      "Epoch: 2 | Iteration: 75 | Classification loss: 0.07721 | Regression loss: 0.10057 | Running loss: 0.21939\n",
      "Epoch: 2 | Iteration: 76 | Classification loss: 0.08550 | Regression loss: 0.08501 | Running loss: 0.21875\n",
      "Epoch: 2 | Iteration: 77 | Classification loss: 0.10711 | Regression loss: 0.11623 | Running loss: 0.21881\n",
      "Epoch: 2 | Iteration: 78 | Classification loss: 0.13091 | Regression loss: 0.12149 | Running loss: 0.21923\n",
      "Epoch: 2 | Iteration: 79 | Classification loss: 0.10048 | Regression loss: 0.10991 | Running loss: 0.21912\n",
      "Epoch: 2 | Iteration: 80 | Classification loss: 0.11054 | Regression loss: 0.12413 | Running loss: 0.21932\n",
      "Epoch: 2 | Iteration: 81 | Classification loss: 0.09983 | Regression loss: 0.10516 | Running loss: 0.21914\n",
      "Epoch: 2 | Iteration: 82 | Classification loss: 0.10120 | Regression loss: 0.10658 | Running loss: 0.21900\n",
      "Epoch: 2 | Iteration: 83 | Classification loss: 0.08096 | Regression loss: 0.09414 | Running loss: 0.21848\n",
      "Epoch: 2 | Iteration: 84 | Classification loss: 0.08334 | Regression loss: 0.08303 | Running loss: 0.21787\n",
      "Epoch: 2 | Iteration: 85 | Classification loss: 0.06454 | Regression loss: 0.06174 | Running loss: 0.21680\n",
      "Epoch: 2 | Iteration: 86 | Classification loss: 0.10090 | Regression loss: 0.09755 | Running loss: 0.21659\n",
      "Epoch: 2 | Iteration: 87 | Classification loss: 0.12851 | Regression loss: 0.14723 | Running loss: 0.21726\n",
      "Epoch: 2 | Iteration: 88 | Classification loss: 0.08731 | Regression loss: 0.10790 | Running loss: 0.21702\n",
      "Epoch: 2 | Iteration: 89 | Classification loss: 0.11883 | Regression loss: 0.12103 | Running loss: 0.21727\n",
      "Epoch: 2 | Iteration: 90 | Classification loss: 0.06936 | Regression loss: 0.07905 | Running loss: 0.21651\n",
      "Epoch: 2 | Iteration: 91 | Classification loss: 0.12534 | Regression loss: 0.14584 | Running loss: 0.21711\n",
      "Epoch: 2 | Iteration: 92 | Classification loss: 0.08369 | Regression loss: 0.06875 | Running loss: 0.21641\n",
      "Epoch: 2 | Iteration: 93 | Classification loss: 0.15005 | Regression loss: 0.10423 | Running loss: 0.21682\n",
      "Epoch: 2 | Iteration: 94 | Classification loss: 0.07030 | Regression loss: 0.07734 | Running loss: 0.21609\n",
      "Epoch: 2 | Iteration: 95 | Classification loss: 0.08628 | Regression loss: 0.09503 | Running loss: 0.21573\n",
      "Epoch: 2 | Iteration: 96 | Classification loss: 0.07394 | Regression loss: 0.08636 | Running loss: 0.21515\n",
      "Epoch: 2 | Iteration: 97 | Classification loss: 0.07225 | Regression loss: 0.08650 | Running loss: 0.21458\n",
      "Epoch: 2 | Iteration: 98 | Classification loss: 0.11269 | Regression loss: 0.11180 | Running loss: 0.21468\n",
      "Epoch: 2 | Iteration: 99 | Classification loss: 0.09176 | Regression loss: 0.10063 | Running loss: 0.21446\n",
      "Epoch: 2 | Iteration: 100 | Classification loss: 0.09664 | Regression loss: 0.12643 | Running loss: 0.21454\n",
      "Epoch: 2 | Iteration: 101 | Classification loss: 0.11088 | Regression loss: 0.13158 | Running loss: 0.21481\n",
      "Epoch: 2 | Iteration: 102 | Classification loss: 0.07816 | Regression loss: 0.07866 | Running loss: 0.21425\n",
      "Epoch: 2 | Iteration: 103 | Classification loss: 0.07097 | Regression loss: 0.08165 | Running loss: 0.21366\n",
      "Epoch: 2 | Iteration: 104 | Classification loss: 0.10246 | Regression loss: 0.09302 | Running loss: 0.21349\n",
      "Epoch: 2 | Iteration: 105 | Classification loss: 0.12746 | Regression loss: 0.14141 | Running loss: 0.21401\n",
      "Epoch: 2 | Iteration: 106 | Classification loss: 0.09186 | Regression loss: 0.10838 | Running loss: 0.21388\n",
      "Epoch: 2 | Iteration: 107 | Classification loss: 0.11683 | Regression loss: 0.12578 | Running loss: 0.21415\n",
      "Epoch: 2 | Iteration: 108 | Classification loss: 0.13562 | Regression loss: 0.09882 | Running loss: 0.21433\n",
      "Epoch: 2 | Iteration: 109 | Classification loss: 0.08914 | Regression loss: 0.11468 | Running loss: 0.21424\n",
      "Epoch: 2 | Iteration: 110 | Classification loss: 0.10736 | Regression loss: 0.13854 | Running loss: 0.21452\n",
      "Epoch: 2 | Iteration: 111 | Classification loss: 0.10817 | Regression loss: 0.08132 | Running loss: 0.21430\n",
      "Epoch: 2 | Iteration: 112 | Classification loss: 0.13280 | Regression loss: 0.14958 | Running loss: 0.21490\n",
      "Epoch: 2 | Iteration: 113 | Classification loss: 0.08873 | Regression loss: 0.09120 | Running loss: 0.21459\n",
      "Epoch: 2 | Iteration: 114 | Classification loss: 0.11014 | Regression loss: 0.12370 | Running loss: 0.21476\n",
      "Epoch: 2 | Iteration: 115 | Classification loss: 0.08139 | Regression loss: 0.08491 | Running loss: 0.21434\n",
      "Epoch: 2 | Iteration: 116 | Classification loss: 0.08457 | Regression loss: 0.08062 | Running loss: 0.21392\n",
      "Epoch: 2 | Iteration: 117 | Classification loss: 0.11059 | Regression loss: 0.12731 | Running loss: 0.21413\n",
      "Epoch: 2 | Iteration: 118 | Classification loss: 0.11356 | Regression loss: 0.10797 | Running loss: 0.21419\n",
      "Epoch: 2 | Iteration: 119 | Classification loss: 0.10479 | Regression loss: 0.10084 | Running loss: 0.21412\n",
      "Epoch: 2 | Iteration: 120 | Classification loss: 0.10541 | Regression loss: 0.12725 | Running loss: 0.21427\n",
      "Epoch: 2 | Iteration: 121 | Classification loss: 0.08215 | Regression loss: 0.07795 | Running loss: 0.21383\n",
      "Epoch: 2 | Iteration: 122 | Classification loss: 0.08394 | Regression loss: 0.09164 | Running loss: 0.21352\n",
      "Epoch: 2 | Iteration: 123 | Classification loss: 0.11690 | Regression loss: 0.12193 | Running loss: 0.21372\n",
      "Epoch: 2 | Iteration: 124 | Classification loss: 0.08598 | Regression loss: 0.09681 | Running loss: 0.21347\n",
      "Epoch: 2 | Iteration: 125 | Classification loss: 0.07001 | Regression loss: 0.07548 | Running loss: 0.21293\n",
      "Epoch: 2 | Iteration: 126 | Classification loss: 0.12437 | Regression loss: 0.13587 | Running loss: 0.21331\n",
      "Epoch: 2 | Iteration: 127 | Classification loss: 0.11875 | Regression loss: 0.13022 | Running loss: 0.21358\n",
      "Epoch: 2 | Iteration: 128 | Classification loss: 0.11643 | Regression loss: 0.13254 | Running loss: 0.21386\n",
      "Epoch: 2 | Iteration: 129 | Classification loss: 0.12732 | Regression loss: 0.13566 | Running loss: 0.21424\n",
      "Epoch: 2 | Iteration: 130 | Classification loss: 0.09064 | Regression loss: 0.09681 | Running loss: 0.21403\n",
      "Epoch: 2 | Iteration: 131 | Classification loss: 0.11363 | Regression loss: 0.11157 | Running loss: 0.21412\n",
      "Epoch: 2 | Iteration: 132 | Classification loss: 0.11032 | Regression loss: 0.13158 | Running loss: 0.21433\n",
      "Epoch: 2 | Iteration: 133 | Classification loss: 0.08492 | Regression loss: 0.10181 | Running loss: 0.21412\n",
      "Epoch: 2 | Iteration: 134 | Classification loss: 0.09119 | Regression loss: 0.10263 | Running loss: 0.21397\n",
      "Epoch: 2 | Iteration: 135 | Classification loss: 0.09732 | Regression loss: 0.11401 | Running loss: 0.21395\n",
      "Epoch: 2 | Iteration: 136 | Classification loss: 0.11631 | Regression loss: 0.14297 | Running loss: 0.21428\n",
      "Epoch: 2 | Iteration: 137 | Classification loss: 0.09275 | Regression loss: 0.10308 | Running loss: 0.21415\n",
      "Epoch: 2 | Iteration: 138 | Classification loss: 0.09221 | Regression loss: 0.11439 | Running loss: 0.21409\n",
      "Epoch: 2 | Iteration: 139 | Classification loss: 0.10729 | Regression loss: 0.13290 | Running loss: 0.21428\n",
      "Epoch: 2 | Iteration: 140 | Classification loss: 0.07609 | Regression loss: 0.07220 | Running loss: 0.21381\n",
      "Epoch: 2 | Iteration: 141 | Classification loss: 0.09182 | Regression loss: 0.10825 | Running loss: 0.21371\n",
      "Epoch: 2 | Iteration: 142 | Classification loss: 0.07470 | Regression loss: 0.08173 | Running loss: 0.21331\n",
      "Epoch: 2 | Iteration: 143 | Classification loss: 0.10370 | Regression loss: 0.10942 | Running loss: 0.21331\n",
      "Epoch: 2 | Iteration: 144 | Classification loss: 0.09705 | Regression loss: 0.11134 | Running loss: 0.21328\n",
      "Epoch: 2 | Iteration: 145 | Classification loss: 0.08507 | Regression loss: 0.10142 | Running loss: 0.21309\n",
      "Epoch: 2 | Iteration: 146 | Classification loss: 0.08814 | Regression loss: 0.10304 | Running loss: 0.21295\n",
      "Epoch: 2 | Iteration: 147 | Classification loss: 0.08632 | Regression loss: 0.10662 | Running loss: 0.21281\n",
      "Epoch: 2 | Iteration: 148 | Classification loss: 0.10101 | Regression loss: 0.11076 | Running loss: 0.21280\n",
      "Epoch: 2 | Iteration: 149 | Classification loss: 0.11183 | Regression loss: 0.12959 | Running loss: 0.21299\n",
      "Epoch: 2 | Iteration: 150 | Classification loss: 0.08772 | Regression loss: 0.09856 | Running loss: 0.21282\n",
      "Epoch: 2 | Iteration: 151 | Classification loss: 0.08859 | Regression loss: 0.08524 | Running loss: 0.21256\n",
      "Epoch: 2 | Iteration: 152 | Classification loss: 0.10300 | Regression loss: 0.08522 | Running loss: 0.21240\n",
      "Epoch: 2 | Iteration: 153 | Classification loss: 0.11689 | Regression loss: 0.11861 | Running loss: 0.21255\n",
      "Epoch: 2 | Iteration: 154 | Classification loss: 0.13359 | Regression loss: 0.14375 | Running loss: 0.21297\n",
      "Epoch: 2 | Iteration: 155 | Classification loss: 0.15993 | Regression loss: 0.14555 | Running loss: 0.21356\n",
      "Epoch: 2 | Iteration: 156 | Classification loss: 0.11420 | Regression loss: 0.12894 | Running loss: 0.21375\n",
      "Epoch: 2 | Iteration: 157 | Classification loss: 0.12706 | Regression loss: 0.13636 | Running loss: 0.21407\n",
      "Epoch: 2 | Iteration: 158 | Classification loss: 0.09056 | Regression loss: 0.09449 | Running loss: 0.21388\n",
      "Epoch: 2 | Iteration: 159 | Classification loss: 0.12195 | Regression loss: 0.13147 | Running loss: 0.21413\n",
      "Epoch: 2 | Iteration: 160 | Classification loss: 0.11219 | Regression loss: 0.12554 | Running loss: 0.21428\n",
      "Epoch: 2 | Iteration: 161 | Classification loss: 0.11274 | Regression loss: 0.12808 | Running loss: 0.21444\n",
      "Epoch: 2 | Iteration: 162 | Classification loss: 0.12813 | Regression loss: 0.14038 | Running loss: 0.21477\n",
      "Epoch: 2 | Iteration: 163 | Classification loss: 0.11654 | Regression loss: 0.11815 | Running loss: 0.21489\n",
      "Epoch: 2 | Iteration: 164 | Classification loss: 0.09809 | Regression loss: 0.11315 | Running loss: 0.21487\n",
      "Epoch: 2 | Iteration: 165 | Classification loss: 0.10325 | Regression loss: 0.12539 | Running loss: 0.21495\n",
      "Epoch: 2 | Iteration: 166 | Classification loss: 0.02576 | Regression loss: 0.00000 | Running loss: 0.21382\n",
      "\n",
      " Total Time - 1520\n",
      "\n",
      "get detections on train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d740cbf0cd5462a9fe1b2b08cef1d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get detections on valid dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ebbdfd3824d4a68859af915210bb5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "mAP on training dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.5414,Precision:0.2438,Recall:0.8575\n",
      "AP@0.4:0.4638,Precision:0.2199,Recall:0.7734\n",
      "AP@0.6:0.2266,Precision:0.1502,Recall:0.5282\n",
      "AP@0.5:0.3546,Precision:0.1920,Recall:0.6753\n",
      "AP@0.7:0.0711,Precision:0.0784,Recall:0.2757\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.0070,Precision:0.0461,Recall:0.1004\n",
      "AP@0.4:0.0024,Precision:0.0269,Recall:0.0587\n",
      "AP@0.6:0.0003,Precision:0.0084,Recall:0.0183\n",
      "AP@0.5:0.0008,Precision:0.0150,Recall:0.0326\n",
      "AP@0.7:0.0000,Precision:0.0030,Recall:0.0065\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.0048,Precision:0.0539,Recall:0.0587\n",
      "AP@0.4:0.0017,Precision:0.0347,Recall:0.0378\n",
      "AP@0.6:0.0002,Precision:0.0120,Recall:0.0130\n",
      "AP@0.5:0.0007,Precision:0.0204,Recall:0.0222\n",
      "AP@0.7:0.0000,Precision:0.0036,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.0040,Precision:0.0703,Recall:0.0456\n",
      "AP@0.4:0.0013,Precision:0.0422,Recall:0.0274\n",
      "AP@0.6:0.0002,Precision:0.0161,Recall:0.0104\n",
      "AP@0.5:0.0005,Precision:0.0261,Recall:0.0169\n",
      "AP@0.7:0.0000,Precision:0.0060,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.0026,Precision:0.0671,Recall:0.0261\n",
      "AP@0.4:0.0008,Precision:0.0403,Recall:0.0156\n",
      "AP@0.6:0.0001,Precision:0.0101,Recall:0.0039\n",
      "AP@0.5:0.0003,Precision:0.0235,Recall:0.0091\n",
      "AP@0.7:0.0000,Precision:0.0034,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.0019,Precision:0.0707,Recall:0.0183\n",
      "AP@0.4:0.0003,Precision:0.0354,Recall:0.0091\n",
      "AP@0.6:0.0001,Precision:0.0101,Recall:0.0026\n",
      "AP@0.5:0.0002,Precision:0.0253,Recall:0.0065\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0015,Precision:0.0730,Recall:0.0130\n",
      "AP@0.4:0.0002,Precision:0.0292,Recall:0.0052\n",
      "AP@0.6:0.0001,Precision:0.0146,Recall:0.0026\n",
      "AP@0.5:0.0001,Precision:0.0219,Recall:0.0039\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0013,Precision:0.0808,Recall:0.0104\n",
      "AP@0.4:0.0001,Precision:0.0303,Recall:0.0039\n",
      "AP@0.6:0.0001,Precision:0.0202,Recall:0.0026\n",
      "AP@0.5:0.0001,Precision:0.0202,Recall:0.0026\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0008,Precision:0.0645,Recall:0.0052\n",
      "AP@0.4:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.6:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.5:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0007,Precision:0.0789,Recall:0.0039\n",
      "AP@0.4:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.6:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.5:0.0000,Precision:0.0000,Recall:0.0000\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "====================================================================================================\n",
      "mAP on validating dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4077,Precision:0.1597,Recall:0.8401\n",
      "AP@0.4:0.3545,Precision:0.1468,Recall:0.7722\n",
      "AP@0.6:0.1614,Precision:0.0956,Recall:0.5031\n",
      "AP@0.5:0.2710,Precision:0.1263,Recall:0.6646\n",
      "AP@0.7:0.0543,Precision:0.0518,Recall:0.2727\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.3634,Precision:0.3064,Recall:0.6531\n",
      "AP@0.4:0.3167,Precision:0.2806,Recall:0.5982\n",
      "AP@0.6:0.1457,Precision:0.1828,Recall:0.3898\n",
      "AP@0.5:0.2430,Precision:0.2422,Recall:0.5162\n",
      "AP@0.7:0.0501,Precision:0.1025,Recall:0.2184\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.2854,Precision:0.4534,Recall:0.4472\n",
      "AP@0.4:0.2531,Precision:0.4211,Recall:0.4154\n",
      "AP@0.6:0.1187,Precision:0.2738,Recall:0.2701\n",
      "AP@0.5:0.1958,Precision:0.3655,Recall:0.3605\n",
      "AP@0.7:0.0418,Precision:0.1562,Recall:0.1541\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.2219,Precision:0.5602,Recall:0.3208\n",
      "AP@0.4:0.2005,Precision:0.5292,Recall:0.3030\n",
      "AP@0.6:0.0973,Precision:0.3504,Recall:0.2006\n",
      "AP@0.5:0.1562,Precision:0.4599,Recall:0.2633\n",
      "AP@0.7:0.0354,Precision:0.2062,Recall:0.1181\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.1675,Precision:0.6467,Recall:0.2315\n",
      "AP@0.4:0.1525,Precision:0.6131,Recall:0.2194\n",
      "AP@0.6:0.0773,Precision:0.4175,Recall:0.1494\n",
      "AP@0.5:0.1198,Precision:0.5328,Recall:0.1907\n",
      "AP@0.7:0.0289,Precision:0.2511,Recall:0.0899\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.1176,Precision:0.6842,Recall:0.1562\n",
      "AP@0.4:0.1079,Precision:0.6499,Recall:0.1484\n",
      "AP@0.6:0.0564,Precision:0.4439,Recall:0.1014\n",
      "AP@0.5:0.0861,Precision:0.5652,Recall:0.1290\n",
      "AP@0.7:0.0214,Precision:0.2700,Recall:0.0617\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0821,Precision:0.7199,Recall:0.1061\n",
      "AP@0.4:0.0762,Precision:0.6879,Recall:0.1014\n",
      "AP@0.6:0.0415,Precision:0.4716,Recall:0.0695\n",
      "AP@0.5:0.0626,Precision:0.6064,Recall:0.0893\n",
      "AP@0.7:0.0158,Precision:0.2872,Recall:0.0423\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0569,Precision:0.7405,Recall:0.0716\n",
      "AP@0.4:0.0539,Precision:0.7189,Recall:0.0695\n",
      "AP@0.6:0.0327,Precision:0.5351,Recall:0.0517\n",
      "AP@0.5:0.0465,Precision:0.6595,Recall:0.0637\n",
      "AP@0.7:0.0128,Precision:0.3351,Recall:0.0324\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0366,Precision:0.7083,Recall:0.0444\n",
      "AP@0.4:0.0347,Precision:0.6917,Recall:0.0434\n",
      "AP@0.6:0.0216,Precision:0.5083,Recall:0.0319\n",
      "AP@0.5:0.0298,Precision:0.6250,Recall:0.0392\n",
      "AP@0.7:0.0078,Precision:0.3083,Recall:0.0193\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0263,Precision:0.7250,Recall:0.0303\n",
      "AP@0.4:0.0251,Precision:0.7125,Recall:0.0298\n",
      "AP@0.6:0.0174,Precision:0.5750,Recall:0.0240\n",
      "AP@0.5:0.0228,Precision:0.6750,Recall:0.0282\n",
      "AP@0.7:0.0062,Precision:0.3375,Recall:0.0141\n",
      "Epoch - 3 Started\n",
      "Epoch: 3 | Iteration: 0 | Classification loss: 0.10326 | Regression loss: 0.12386 | Running loss: 0.22712\n",
      "Epoch: 3 | Iteration: 1 | Classification loss: 0.07541 | Regression loss: 0.08746 | Running loss: 0.19499\n",
      "Epoch: 3 | Iteration: 2 | Classification loss: 0.07211 | Regression loss: 0.09559 | Running loss: 0.18589\n",
      "Epoch: 3 | Iteration: 3 | Classification loss: 0.06871 | Regression loss: 0.07819 | Running loss: 0.17614\n",
      "Epoch: 3 | Iteration: 4 | Classification loss: 0.10399 | Regression loss: 0.10620 | Running loss: 0.18295\n",
      "Epoch: 3 | Iteration: 5 | Classification loss: 0.11020 | Regression loss: 0.13327 | Running loss: 0.19304\n",
      "Epoch: 3 | Iteration: 6 | Classification loss: 0.11562 | Regression loss: 0.13557 | Running loss: 0.20135\n",
      "Epoch: 3 | Iteration: 7 | Classification loss: 0.10616 | Regression loss: 0.11335 | Running loss: 0.20362\n",
      "Epoch: 3 | Iteration: 8 | Classification loss: 0.08128 | Regression loss: 0.09912 | Running loss: 0.20104\n",
      "Epoch: 3 | Iteration: 9 | Classification loss: 0.08884 | Regression loss: 0.08971 | Running loss: 0.19879\n",
      "Epoch: 3 | Iteration: 10 | Classification loss: 0.07612 | Regression loss: 0.10703 | Running loss: 0.19737\n",
      "Epoch: 3 | Iteration: 11 | Classification loss: 0.10710 | Regression loss: 0.11493 | Running loss: 0.19942\n",
      "Epoch: 3 | Iteration: 12 | Classification loss: 0.08872 | Regression loss: 0.08730 | Running loss: 0.19762\n",
      "Epoch: 3 | Iteration: 13 | Classification loss: 0.08767 | Regression loss: 0.09356 | Running loss: 0.19645\n",
      "Epoch: 3 | Iteration: 14 | Classification loss: 0.08077 | Regression loss: 0.09132 | Running loss: 0.19483\n",
      "Epoch: 3 | Iteration: 15 | Classification loss: 0.11061 | Regression loss: 0.12298 | Running loss: 0.19725\n",
      "Epoch: 3 | Iteration: 16 | Classification loss: 0.11304 | Regression loss: 0.11045 | Running loss: 0.19879\n",
      "Epoch: 3 | Iteration: 17 | Classification loss: 0.06039 | Regression loss: 0.08262 | Running loss: 0.19570\n",
      "Epoch: 3 | Iteration: 18 | Classification loss: 0.06405 | Regression loss: 0.07128 | Running loss: 0.19252\n",
      "Epoch: 3 | Iteration: 19 | Classification loss: 0.08939 | Regression loss: 0.10806 | Running loss: 0.19277\n",
      "Epoch: 3 | Iteration: 20 | Classification loss: 0.09490 | Regression loss: 0.10607 | Running loss: 0.19316\n",
      "Epoch: 3 | Iteration: 21 | Classification loss: 0.08697 | Regression loss: 0.09731 | Running loss: 0.19275\n",
      "Epoch: 3 | Iteration: 22 | Classification loss: 0.09647 | Regression loss: 0.11029 | Running loss: 0.19336\n",
      "Epoch: 3 | Iteration: 23 | Classification loss: 0.11417 | Regression loss: 0.14959 | Running loss: 0.19629\n",
      "Epoch: 3 | Iteration: 24 | Classification loss: 0.07930 | Regression loss: 0.10762 | Running loss: 0.19592\n",
      "Epoch: 3 | Iteration: 25 | Classification loss: 0.10082 | Regression loss: 0.10023 | Running loss: 0.19612\n",
      "Epoch: 3 | Iteration: 26 | Classification loss: 0.10823 | Regression loss: 0.14950 | Running loss: 0.19840\n",
      "Epoch: 3 | Iteration: 27 | Classification loss: 0.08294 | Regression loss: 0.09605 | Running loss: 0.19771\n",
      "Epoch: 3 | Iteration: 28 | Classification loss: 0.07119 | Regression loss: 0.07693 | Running loss: 0.19600\n",
      "Epoch: 3 | Iteration: 29 | Classification loss: 0.13845 | Regression loss: 0.14419 | Running loss: 0.19888\n",
      "Epoch: 3 | Iteration: 30 | Classification loss: 0.11642 | Regression loss: 0.10872 | Running loss: 0.19973\n",
      "Epoch: 3 | Iteration: 31 | Classification loss: 0.09311 | Regression loss: 0.10927 | Running loss: 0.19981\n",
      "Epoch: 3 | Iteration: 32 | Classification loss: 0.09339 | Regression loss: 0.10482 | Running loss: 0.19976\n",
      "Epoch: 3 | Iteration: 33 | Classification loss: 0.10150 | Regression loss: 0.10467 | Running loss: 0.19995\n",
      "Epoch: 3 | Iteration: 34 | Classification loss: 0.12746 | Regression loss: 0.12202 | Running loss: 0.20137\n",
      "Epoch: 3 | Iteration: 35 | Classification loss: 0.08536 | Regression loss: 0.08320 | Running loss: 0.20046\n",
      "Epoch: 3 | Iteration: 36 | Classification loss: 0.09982 | Regression loss: 0.12060 | Running loss: 0.20100\n",
      "Epoch: 3 | Iteration: 37 | Classification loss: 0.10379 | Regression loss: 0.11875 | Running loss: 0.20156\n",
      "Epoch: 3 | Iteration: 38 | Classification loss: 0.06937 | Regression loss: 0.07054 | Running loss: 0.19998\n",
      "Epoch: 3 | Iteration: 39 | Classification loss: 0.07298 | Regression loss: 0.08121 | Running loss: 0.19884\n",
      "Epoch: 3 | Iteration: 40 | Classification loss: 0.09327 | Regression loss: 0.10844 | Running loss: 0.19891\n",
      "Epoch: 3 | Iteration: 41 | Classification loss: 0.08740 | Regression loss: 0.09591 | Running loss: 0.19854\n",
      "Epoch: 3 | Iteration: 42 | Classification loss: 0.07341 | Regression loss: 0.09593 | Running loss: 0.19786\n",
      "Epoch: 3 | Iteration: 43 | Classification loss: 0.10350 | Regression loss: 0.10518 | Running loss: 0.19810\n",
      "Epoch: 3 | Iteration: 44 | Classification loss: 0.08806 | Regression loss: 0.10832 | Running loss: 0.19807\n",
      "Epoch: 3 | Iteration: 45 | Classification loss: 0.09315 | Regression loss: 0.10226 | Running loss: 0.19801\n",
      "Epoch: 3 | Iteration: 46 | Classification loss: 0.08634 | Regression loss: 0.08144 | Running loss: 0.19736\n",
      "Epoch: 3 | Iteration: 47 | Classification loss: 0.11974 | Regression loss: 0.12289 | Running loss: 0.19831\n",
      "Epoch: 3 | Iteration: 48 | Classification loss: 0.11480 | Regression loss: 0.14050 | Running loss: 0.19947\n",
      "Epoch: 3 | Iteration: 49 | Classification loss: 0.05758 | Regression loss: 0.07696 | Running loss: 0.19817\n",
      "Epoch: 3 | Iteration: 50 | Classification loss: 0.08888 | Regression loss: 0.10867 | Running loss: 0.19816\n",
      "Epoch: 3 | Iteration: 51 | Classification loss: 0.10368 | Regression loss: 0.11495 | Running loss: 0.19855\n",
      "Epoch: 3 | Iteration: 52 | Classification loss: 0.07811 | Regression loss: 0.07603 | Running loss: 0.19772\n",
      "Epoch: 3 | Iteration: 53 | Classification loss: 0.08032 | Regression loss: 0.09745 | Running loss: 0.19735\n",
      "Epoch: 3 | Iteration: 54 | Classification loss: 0.08715 | Regression loss: 0.09727 | Running loss: 0.19711\n",
      "Epoch: 3 | Iteration: 55 | Classification loss: 0.11323 | Regression loss: 0.12647 | Running loss: 0.19787\n",
      "Epoch: 3 | Iteration: 56 | Classification loss: 0.06659 | Regression loss: 0.08274 | Running loss: 0.19702\n",
      "Epoch: 3 | Iteration: 57 | Classification loss: 0.08213 | Regression loss: 0.07000 | Running loss: 0.19625\n",
      "Epoch: 3 | Iteration: 58 | Classification loss: 0.09362 | Regression loss: 0.09298 | Running loss: 0.19608\n",
      "Epoch: 3 | Iteration: 59 | Classification loss: 0.12835 | Regression loss: 0.13426 | Running loss: 0.19719\n",
      "Epoch: 3 | Iteration: 60 | Classification loss: 0.09463 | Regression loss: 0.09645 | Running loss: 0.19709\n",
      "Epoch: 3 | Iteration: 61 | Classification loss: 0.09536 | Regression loss: 0.10517 | Running loss: 0.19715\n",
      "Epoch: 3 | Iteration: 62 | Classification loss: 0.10343 | Regression loss: 0.10935 | Running loss: 0.19739\n",
      "Epoch: 3 | Iteration: 63 | Classification loss: 0.08445 | Regression loss: 0.10335 | Running loss: 0.19725\n",
      "Epoch: 3 | Iteration: 64 | Classification loss: 0.09967 | Regression loss: 0.11776 | Running loss: 0.19756\n",
      "Epoch: 3 | Iteration: 65 | Classification loss: 0.08107 | Regression loss: 0.07191 | Running loss: 0.19688\n",
      "Epoch: 3 | Iteration: 66 | Classification loss: 0.08586 | Regression loss: 0.08416 | Running loss: 0.19648\n",
      "Epoch: 3 | Iteration: 67 | Classification loss: 0.08279 | Regression loss: 0.09402 | Running loss: 0.19619\n",
      "Epoch: 3 | Iteration: 68 | Classification loss: 0.08691 | Regression loss: 0.10043 | Running loss: 0.19606\n",
      "Epoch: 3 | Iteration: 69 | Classification loss: 0.07641 | Regression loss: 0.09967 | Running loss: 0.19578\n",
      "Epoch: 3 | Iteration: 70 | Classification loss: 0.11383 | Regression loss: 0.09507 | Running loss: 0.19596\n",
      "Epoch: 3 | Iteration: 71 | Classification loss: 0.06770 | Regression loss: 0.07667 | Running loss: 0.19524\n",
      "Epoch: 3 | Iteration: 72 | Classification loss: 0.07391 | Regression loss: 0.09525 | Running loss: 0.19489\n",
      "Epoch: 3 | Iteration: 73 | Classification loss: 0.10458 | Regression loss: 0.11615 | Running loss: 0.19524\n",
      "Epoch: 3 | Iteration: 74 | Classification loss: 0.07478 | Regression loss: 0.09033 | Running loss: 0.19483\n",
      "Epoch: 3 | Iteration: 75 | Classification loss: 0.10887 | Regression loss: 0.11900 | Running loss: 0.19527\n",
      "Epoch: 3 | Iteration: 76 | Classification loss: 0.08000 | Regression loss: 0.08950 | Running loss: 0.19493\n",
      "Epoch: 3 | Iteration: 77 | Classification loss: 0.09460 | Regression loss: 0.12005 | Running loss: 0.19519\n",
      "Epoch: 3 | Iteration: 78 | Classification loss: 0.09937 | Regression loss: 0.10352 | Running loss: 0.19529\n",
      "Epoch: 3 | Iteration: 79 | Classification loss: 0.07210 | Regression loss: 0.07621 | Running loss: 0.19470\n",
      "Epoch: 3 | Iteration: 80 | Classification loss: 0.10904 | Regression loss: 0.12800 | Running loss: 0.19522\n",
      "Epoch: 3 | Iteration: 81 | Classification loss: 0.09565 | Regression loss: 0.12023 | Running loss: 0.19547\n",
      "Epoch: 3 | Iteration: 82 | Classification loss: 0.08521 | Regression loss: 0.07174 | Running loss: 0.19501\n",
      "Epoch: 3 | Iteration: 83 | Classification loss: 0.07831 | Regression loss: 0.08772 | Running loss: 0.19466\n",
      "Epoch: 3 | Iteration: 84 | Classification loss: 0.08222 | Regression loss: 0.09221 | Running loss: 0.19443\n",
      "Epoch: 3 | Iteration: 85 | Classification loss: 0.06628 | Regression loss: 0.06382 | Running loss: 0.19368\n",
      "Epoch: 3 | Iteration: 86 | Classification loss: 0.10565 | Regression loss: 0.12976 | Running loss: 0.19416\n",
      "Epoch: 3 | Iteration: 87 | Classification loss: 0.08894 | Regression loss: 0.10522 | Running loss: 0.19416\n",
      "Epoch: 3 | Iteration: 88 | Classification loss: 0.08475 | Regression loss: 0.08989 | Running loss: 0.19394\n",
      "Epoch: 3 | Iteration: 89 | Classification loss: 0.13077 | Regression loss: 0.13247 | Running loss: 0.19471\n",
      "Epoch: 3 | Iteration: 90 | Classification loss: 0.10860 | Regression loss: 0.13856 | Running loss: 0.19528\n",
      "Epoch: 3 | Iteration: 91 | Classification loss: 0.09027 | Regression loss: 0.09665 | Running loss: 0.19519\n",
      "Epoch: 3 | Iteration: 92 | Classification loss: 0.05476 | Regression loss: 0.07053 | Running loss: 0.19444\n",
      "Epoch: 3 | Iteration: 93 | Classification loss: 0.09320 | Regression loss: 0.10537 | Running loss: 0.19449\n",
      "Epoch: 3 | Iteration: 94 | Classification loss: 0.09291 | Regression loss: 0.09073 | Running loss: 0.19437\n",
      "Epoch: 3 | Iteration: 95 | Classification loss: 0.07694 | Regression loss: 0.08429 | Running loss: 0.19403\n",
      "Epoch: 3 | Iteration: 96 | Classification loss: 0.09634 | Regression loss: 0.11189 | Running loss: 0.19417\n",
      "Epoch: 3 | Iteration: 97 | Classification loss: 0.12099 | Regression loss: 0.12740 | Running loss: 0.19473\n",
      "Epoch: 3 | Iteration: 98 | Classification loss: 0.13396 | Regression loss: 0.14203 | Running loss: 0.19555\n",
      "Epoch: 3 | Iteration: 99 | Classification loss: 0.11377 | Regression loss: 0.10964 | Running loss: 0.19583\n",
      "Epoch: 3 | Iteration: 100 | Classification loss: 0.09560 | Regression loss: 0.10833 | Running loss: 0.19591\n",
      "Epoch: 3 | Iteration: 101 | Classification loss: 0.07007 | Regression loss: 0.08432 | Running loss: 0.19550\n",
      "Epoch: 3 | Iteration: 102 | Classification loss: 0.08049 | Regression loss: 0.09354 | Running loss: 0.19529\n",
      "Epoch: 3 | Iteration: 103 | Classification loss: 0.09467 | Regression loss: 0.11358 | Running loss: 0.19541\n",
      "Epoch: 3 | Iteration: 104 | Classification loss: 0.06886 | Regression loss: 0.06695 | Running loss: 0.19485\n",
      "Epoch: 3 | Iteration: 105 | Classification loss: 0.10321 | Regression loss: 0.12273 | Running loss: 0.19514\n",
      "Epoch: 3 | Iteration: 106 | Classification loss: 0.08799 | Regression loss: 0.09774 | Running loss: 0.19505\n",
      "Epoch: 3 | Iteration: 107 | Classification loss: 0.07908 | Regression loss: 0.08745 | Running loss: 0.19479\n",
      "Epoch: 3 | Iteration: 108 | Classification loss: 0.06239 | Regression loss: 0.08186 | Running loss: 0.19432\n",
      "Epoch: 3 | Iteration: 109 | Classification loss: 0.06599 | Regression loss: 0.08455 | Running loss: 0.19393\n",
      "Epoch: 3 | Iteration: 110 | Classification loss: 0.09889 | Regression loss: 0.11376 | Running loss: 0.19410\n",
      "Epoch: 3 | Iteration: 111 | Classification loss: 0.16161 | Regression loss: 0.09159 | Running loss: 0.19462\n",
      "Epoch: 3 | Iteration: 112 | Classification loss: 0.08981 | Regression loss: 0.09324 | Running loss: 0.19452\n",
      "Epoch: 3 | Iteration: 113 | Classification loss: 0.06880 | Regression loss: 0.06767 | Running loss: 0.19401\n",
      "Epoch: 3 | Iteration: 114 | Classification loss: 0.12636 | Regression loss: 0.14076 | Running loss: 0.19465\n",
      "Epoch: 3 | Iteration: 115 | Classification loss: 0.12050 | Regression loss: 0.12116 | Running loss: 0.19505\n",
      "Epoch: 3 | Iteration: 116 | Classification loss: 0.08537 | Regression loss: 0.08289 | Running loss: 0.19482\n",
      "Epoch: 3 | Iteration: 117 | Classification loss: 0.07838 | Regression loss: 0.09614 | Running loss: 0.19465\n",
      "Epoch: 3 | Iteration: 118 | Classification loss: 0.13465 | Regression loss: 0.14737 | Running loss: 0.19539\n",
      "Epoch: 3 | Iteration: 119 | Classification loss: 0.07644 | Regression loss: 0.08621 | Running loss: 0.19511\n",
      "Epoch: 3 | Iteration: 120 | Classification loss: 0.08913 | Regression loss: 0.09895 | Running loss: 0.19505\n",
      "Epoch: 3 | Iteration: 121 | Classification loss: 0.07195 | Regression loss: 0.07726 | Running loss: 0.19468\n",
      "Epoch: 3 | Iteration: 122 | Classification loss: 0.14481 | Regression loss: 0.11394 | Running loss: 0.19520\n",
      "Epoch: 3 | Iteration: 123 | Classification loss: 0.11037 | Regression loss: 0.12976 | Running loss: 0.19556\n",
      "Epoch: 3 | Iteration: 124 | Classification loss: 0.09326 | Regression loss: 0.09854 | Running loss: 0.19553\n",
      "Epoch: 3 | Iteration: 125 | Classification loss: 0.08428 | Regression loss: 0.09172 | Running loss: 0.19538\n",
      "Epoch: 3 | Iteration: 126 | Classification loss: 0.08532 | Regression loss: 0.07858 | Running loss: 0.19513\n",
      "Epoch: 3 | Iteration: 127 | Classification loss: 0.06160 | Regression loss: 0.06664 | Running loss: 0.19461\n",
      "Epoch: 3 | Iteration: 128 | Classification loss: 0.09783 | Regression loss: 0.11926 | Running loss: 0.19478\n",
      "Epoch: 3 | Iteration: 129 | Classification loss: 0.09431 | Regression loss: 0.10396 | Running loss: 0.19481\n",
      "Epoch: 3 | Iteration: 130 | Classification loss: 0.09028 | Regression loss: 0.11742 | Running loss: 0.19491\n",
      "Epoch: 3 | Iteration: 131 | Classification loss: 0.09349 | Regression loss: 0.13286 | Running loss: 0.19514\n",
      "Epoch: 3 | Iteration: 132 | Classification loss: 0.10339 | Regression loss: 0.11959 | Running loss: 0.19535\n",
      "Epoch: 3 | Iteration: 133 | Classification loss: 0.09553 | Regression loss: 0.09884 | Running loss: 0.19535\n",
      "Epoch: 3 | Iteration: 134 | Classification loss: 0.06298 | Regression loss: 0.08482 | Running loss: 0.19499\n",
      "Epoch: 3 | Iteration: 135 | Classification loss: 0.10220 | Regression loss: 0.12160 | Running loss: 0.19521\n",
      "Epoch: 3 | Iteration: 136 | Classification loss: 0.08061 | Regression loss: 0.09856 | Running loss: 0.19509\n",
      "Epoch: 3 | Iteration: 137 | Classification loss: 0.07296 | Regression loss: 0.10342 | Running loss: 0.19495\n",
      "Epoch: 3 | Iteration: 138 | Classification loss: 0.08756 | Regression loss: 0.08450 | Running loss: 0.19479\n",
      "Epoch: 3 | Iteration: 139 | Classification loss: 0.07696 | Regression loss: 0.09571 | Running loss: 0.19463\n",
      "Epoch: 3 | Iteration: 140 | Classification loss: 0.11301 | Regression loss: 0.11071 | Running loss: 0.19484\n",
      "Epoch: 3 | Iteration: 141 | Classification loss: 0.11710 | Regression loss: 0.15181 | Running loss: 0.19536\n",
      "Epoch: 3 | Iteration: 142 | Classification loss: 0.11468 | Regression loss: 0.12908 | Running loss: 0.19570\n",
      "Epoch: 3 | Iteration: 143 | Classification loss: 0.11597 | Regression loss: 0.12792 | Running loss: 0.19603\n",
      "Epoch: 3 | Iteration: 144 | Classification loss: 0.13805 | Regression loss: 0.10016 | Running loss: 0.19632\n",
      "Epoch: 3 | Iteration: 145 | Classification loss: 0.10732 | Regression loss: 0.10270 | Running loss: 0.19642\n",
      "Epoch: 3 | Iteration: 146 | Classification loss: 0.12794 | Regression loss: 0.10182 | Running loss: 0.19664\n",
      "Epoch: 3 | Iteration: 147 | Classification loss: 0.08608 | Regression loss: 0.12484 | Running loss: 0.19674\n",
      "Epoch: 3 | Iteration: 148 | Classification loss: 0.06968 | Regression loss: 0.08533 | Running loss: 0.19646\n",
      "Epoch: 3 | Iteration: 149 | Classification loss: 0.08906 | Regression loss: 0.10476 | Running loss: 0.19644\n",
      "Epoch: 3 | Iteration: 150 | Classification loss: 0.08277 | Regression loss: 0.08315 | Running loss: 0.19624\n",
      "Epoch: 3 | Iteration: 151 | Classification loss: 0.09133 | Regression loss: 0.09298 | Running loss: 0.19616\n",
      "Epoch: 3 | Iteration: 152 | Classification loss: 0.08798 | Regression loss: 0.09828 | Running loss: 0.19610\n",
      "Epoch: 3 | Iteration: 153 | Classification loss: 0.06177 | Regression loss: 0.06023 | Running loss: 0.19562\n",
      "Epoch: 3 | Iteration: 154 | Classification loss: 0.09157 | Regression loss: 0.11192 | Running loss: 0.19567\n",
      "Epoch: 3 | Iteration: 155 | Classification loss: 0.09629 | Regression loss: 0.12374 | Running loss: 0.19582\n",
      "Epoch: 3 | Iteration: 156 | Classification loss: 0.08690 | Regression loss: 0.08780 | Running loss: 0.19569\n",
      "Epoch: 3 | Iteration: 157 | Classification loss: 0.09440 | Regression loss: 0.13423 | Running loss: 0.19590\n",
      "Epoch: 3 | Iteration: 158 | Classification loss: 0.23835 | Regression loss: 0.11602 | Running loss: 0.19689\n",
      "Epoch: 3 | Iteration: 159 | Classification loss: 0.10989 | Regression loss: 0.11336 | Running loss: 0.19706\n",
      "Epoch: 3 | Iteration: 160 | Classification loss: 0.09997 | Regression loss: 0.10104 | Running loss: 0.19708\n",
      "Epoch: 3 | Iteration: 161 | Classification loss: 0.04290 | Regression loss: 0.06102 | Running loss: 0.19651\n",
      "Epoch: 3 | Iteration: 162 | Classification loss: 0.09949 | Regression loss: 0.10841 | Running loss: 0.19658\n",
      "Epoch: 3 | Iteration: 163 | Classification loss: 0.12391 | Regression loss: 0.13561 | Running loss: 0.19696\n",
      "Epoch: 3 | Iteration: 164 | Classification loss: 0.08759 | Regression loss: 0.10170 | Running loss: 0.19691\n",
      "Epoch: 3 | Iteration: 165 | Classification loss: 0.09074 | Regression loss: 0.10889 | Running loss: 0.19693\n",
      "Epoch: 3 | Iteration: 166 | Classification loss: 0.98824 | Regression loss: 0.96413 | Running loss: 0.20744\n",
      "\n",
      " Total Time - 1513\n",
      "\n",
      "get detections on train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f7a113a67241bdb2439c2d178f0003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get detections on valid dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4012d9c5dbb4c178a0a73fc96614f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "mAP on training dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.6014,Precision:0.3182,Recall:0.8474\n",
      "AP@0.4:0.5170,Precision:0.2876,Recall:0.7660\n",
      "AP@0.6:0.2355,Precision:0.2008,Recall:0.5347\n",
      "AP@0.5:0.4085,Precision:0.2511,Recall:0.6688\n",
      "AP@0.7:0.0719,Precision:0.1101,Recall:0.2932\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.0066,Precision:0.0488,Recall:0.0939\n",
      "AP@0.4:0.0030,Precision:0.0312,Recall:0.0600\n",
      "AP@0.6:0.0003,Precision:0.0095,Recall:0.0183\n",
      "AP@0.5:0.0010,Precision:0.0156,Recall:0.0300\n",
      "AP@0.7:0.0001,Precision:0.0034,Recall:0.0065\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.0051,Precision:0.0559,Recall:0.0652\n",
      "AP@0.4:0.0024,Precision:0.0358,Recall:0.0417\n",
      "AP@0.6:0.0002,Precision:0.0101,Recall:0.0117\n",
      "AP@0.5:0.0009,Precision:0.0190,Recall:0.0222\n",
      "AP@0.7:0.0001,Precision:0.0034,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.0040,Precision:0.0627,Recall:0.0456\n",
      "AP@0.4:0.0019,Precision:0.0412,Recall:0.0300\n",
      "AP@0.6:0.0002,Precision:0.0125,Recall:0.0091\n",
      "AP@0.5:0.0007,Precision:0.0215,Recall:0.0156\n",
      "AP@0.7:0.0001,Precision:0.0054,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.0034,Precision:0.0730,Recall:0.0378\n",
      "AP@0.4:0.0017,Precision:0.0479,Recall:0.0248\n",
      "AP@0.6:0.0002,Precision:0.0151,Recall:0.0078\n",
      "AP@0.5:0.0006,Precision:0.0227,Recall:0.0117\n",
      "AP@0.7:0.0001,Precision:0.0076,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.0025,Precision:0.0720,Recall:0.0248\n",
      "AP@0.4:0.0013,Precision:0.0492,Recall:0.0169\n",
      "AP@0.6:0.0002,Precision:0.0152,Recall:0.0052\n",
      "AP@0.5:0.0006,Precision:0.0265,Recall:0.0091\n",
      "AP@0.7:0.0000,Precision:0.0076,Recall:0.0026\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0024,Precision:0.0942,Recall:0.0235\n",
      "AP@0.4:0.0013,Precision:0.0628,Recall:0.0156\n",
      "AP@0.6:0.0002,Precision:0.0209,Recall:0.0052\n",
      "AP@0.5:0.0006,Precision:0.0366,Recall:0.0091\n",
      "AP@0.7:0.0000,Precision:0.0105,Recall:0.0026\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0014,Precision:0.0833,Recall:0.0143\n",
      "AP@0.4:0.0011,Precision:0.0758,Recall:0.0130\n",
      "AP@0.6:0.0001,Precision:0.0227,Recall:0.0039\n",
      "AP@0.5:0.0005,Precision:0.0455,Recall:0.0078\n",
      "AP@0.7:0.0000,Precision:0.0152,Recall:0.0026\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0009,Precision:0.0753,Recall:0.0091\n",
      "AP@0.4:0.0006,Precision:0.0645,Recall:0.0078\n",
      "AP@0.6:0.0001,Precision:0.0215,Recall:0.0026\n",
      "AP@0.5:0.0004,Precision:0.0430,Recall:0.0052\n",
      "AP@0.7:0.0000,Precision:0.0108,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0007,Precision:0.0685,Recall:0.0065\n",
      "AP@0.4:0.0004,Precision:0.0548,Recall:0.0052\n",
      "AP@0.6:0.0001,Precision:0.0137,Recall:0.0013\n",
      "AP@0.5:0.0003,Precision:0.0411,Recall:0.0039\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "====================================================================================================\n",
      "mAP on validating dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4225,Precision:0.2086,Recall:0.8036\n",
      "AP@0.4:0.3556,Precision:0.1911,Recall:0.7362\n",
      "AP@0.6:0.1353,Precision:0.1200,Recall:0.4624\n",
      "AP@0.5:0.2611,Precision:0.1628,Recall:0.6270\n",
      "AP@0.7:0.0331,Precision:0.0604,Recall:0.2325\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.3661,Precision:0.3567,Recall:0.6008\n",
      "AP@0.4:0.3080,Precision:0.3263,Recall:0.5496\n",
      "AP@0.6:0.1136,Precision:0.1942,Recall:0.3271\n",
      "AP@0.5:0.2249,Precision:0.2742,Recall:0.4619\n",
      "AP@0.7:0.0278,Precision:0.0989,Recall:0.1667\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.2932,Precision:0.4717,Recall:0.4227\n",
      "AP@0.4:0.2474,Precision:0.4315,Recall:0.3866\n",
      "AP@0.6:0.0927,Precision:0.2601,Recall:0.2330\n",
      "AP@0.5:0.1825,Precision:0.3650,Recall:0.3271\n",
      "AP@0.7:0.0222,Precision:0.1312,Recall:0.1176\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.2294,Precision:0.5750,Recall:0.3004\n",
      "AP@0.4:0.1939,Precision:0.5270,Recall:0.2753\n",
      "AP@0.6:0.0721,Precision:0.3080,Recall:0.1609\n",
      "AP@0.5:0.1434,Precision:0.4430,Recall:0.2315\n",
      "AP@0.7:0.0168,Precision:0.1540,Recall:0.0805\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.1799,Precision:0.6547,Recall:0.2200\n",
      "AP@0.4:0.1520,Precision:0.5988,Recall:0.2011\n",
      "AP@0.6:0.0584,Precision:0.3577,Recall:0.1202\n",
      "AP@0.5:0.1144,Precision:0.5070,Recall:0.1703\n",
      "AP@0.7:0.0133,Precision:0.1757,Recall:0.0590\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.1418,Precision:0.7389,Recall:0.1656\n",
      "AP@0.4:0.1207,Precision:0.6807,Recall:0.1526\n",
      "AP@0.6:0.0483,Precision:0.4196,Recall:0.0940\n",
      "AP@0.5:0.0928,Precision:0.5851,Recall:0.1311\n",
      "AP@0.7:0.0109,Precision:0.2098,Recall:0.0470\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.1066,Precision:0.7972,Recall:0.1191\n",
      "AP@0.4:0.0907,Precision:0.7343,Recall:0.1097\n",
      "AP@0.6:0.0368,Precision:0.4545,Recall:0.0679\n",
      "AP@0.5:0.0709,Precision:0.6364,Recall:0.0951\n",
      "AP@0.7:0.0074,Precision:0.2028,Recall:0.0303\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0854,Precision:0.8318,Recall:0.0930\n",
      "AP@0.4:0.0732,Precision:0.7710,Recall:0.0862\n",
      "AP@0.6:0.0300,Precision:0.4766,Recall:0.0533\n",
      "AP@0.5:0.0580,Precision:0.6729,Recall:0.0752\n",
      "AP@0.7:0.0062,Precision:0.2243,Recall:0.0251\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0678,Precision:0.8734,Recall:0.0721\n",
      "AP@0.4:0.0573,Precision:0.7975,Recall:0.0658\n",
      "AP@0.6:0.0237,Precision:0.4873,Recall:0.0402\n",
      "AP@0.5:0.0466,Precision:0.7089,Recall:0.0585\n",
      "AP@0.7:0.0044,Precision:0.2089,Recall:0.0172\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0517,Precision:0.8879,Recall:0.0538\n",
      "AP@0.4:0.0439,Precision:0.8103,Recall:0.0491\n",
      "AP@0.6:0.0189,Precision:0.5086,Recall:0.0308\n",
      "AP@0.5:0.0362,Precision:0.7328,Recall:0.0444\n",
      "AP@0.7:0.0033,Precision:0.2155,Recall:0.0131\n",
      "Epoch - 4 Started\n",
      "Epoch: 4 | Iteration: 0 | Classification loss: 0.09715 | Regression loss: 0.08467 | Running loss: 0.18181\n",
      "Epoch: 4 | Iteration: 1 | Classification loss: 0.08881 | Regression loss: 0.12363 | Running loss: 0.19713\n",
      "Epoch: 4 | Iteration: 2 | Classification loss: 0.07352 | Regression loss: 0.07837 | Running loss: 0.18205\n",
      "Epoch: 4 | Iteration: 3 | Classification loss: 0.09518 | Regression loss: 0.10607 | Running loss: 0.18685\n",
      "Epoch: 4 | Iteration: 4 | Classification loss: 0.07692 | Regression loss: 0.09948 | Running loss: 0.18476\n",
      "Epoch: 4 | Iteration: 5 | Classification loss: 0.06903 | Regression loss: 0.08429 | Running loss: 0.17952\n",
      "Epoch: 4 | Iteration: 6 | Classification loss: 0.07912 | Regression loss: 0.09838 | Running loss: 0.17923\n",
      "Epoch: 4 | Iteration: 7 | Classification loss: 0.07332 | Regression loss: 0.07806 | Running loss: 0.17575\n",
      "Epoch: 4 | Iteration: 8 | Classification loss: 0.08021 | Regression loss: 0.10246 | Running loss: 0.17652\n",
      "Epoch: 4 | Iteration: 9 | Classification loss: 0.06385 | Regression loss: 0.07158 | Running loss: 0.17241\n",
      "Epoch: 4 | Iteration: 10 | Classification loss: 0.10610 | Regression loss: 0.11207 | Running loss: 0.17657\n",
      "Epoch: 4 | Iteration: 11 | Classification loss: 0.07266 | Regression loss: 0.06740 | Running loss: 0.17353\n",
      "Epoch: 4 | Iteration: 12 | Classification loss: 0.06855 | Regression loss: 0.08944 | Running loss: 0.17233\n",
      "Epoch: 4 | Iteration: 13 | Classification loss: 0.06587 | Regression loss: 0.08033 | Running loss: 0.17047\n",
      "Epoch: 4 | Iteration: 14 | Classification loss: 0.07282 | Regression loss: 0.09533 | Running loss: 0.17031\n",
      "Epoch: 4 | Iteration: 15 | Classification loss: 0.06238 | Regression loss: 0.06221 | Running loss: 0.16745\n",
      "Epoch: 4 | Iteration: 16 | Classification loss: 0.05912 | Regression loss: 0.07432 | Running loss: 0.16545\n",
      "Epoch: 4 | Iteration: 17 | Classification loss: 0.05437 | Regression loss: 0.07020 | Running loss: 0.16318\n",
      "Epoch: 4 | Iteration: 18 | Classification loss: 0.10501 | Regression loss: 0.12007 | Running loss: 0.16644\n",
      "Epoch: 4 | Iteration: 19 | Classification loss: 0.08190 | Regression loss: 0.10051 | Running loss: 0.16724\n",
      "Epoch: 4 | Iteration: 20 | Classification loss: 0.09313 | Regression loss: 0.11664 | Running loss: 0.16926\n",
      "Epoch: 4 | Iteration: 21 | Classification loss: 0.15413 | Regression loss: 0.07824 | Running loss: 0.17213\n",
      "Epoch: 4 | Iteration: 22 | Classification loss: 0.09149 | Regression loss: 0.10290 | Running loss: 0.17310\n",
      "Epoch: 4 | Iteration: 23 | Classification loss: 0.09819 | Regression loss: 0.11682 | Running loss: 0.17485\n",
      "Epoch: 4 | Iteration: 24 | Classification loss: 0.08292 | Regression loss: 0.10264 | Running loss: 0.17528\n",
      "Epoch: 4 | Iteration: 25 | Classification loss: 0.10454 | Regression loss: 0.11602 | Running loss: 0.17702\n",
      "Epoch: 4 | Iteration: 26 | Classification loss: 0.06900 | Regression loss: 0.07703 | Running loss: 0.17587\n",
      "Epoch: 4 | Iteration: 27 | Classification loss: 0.05313 | Regression loss: 0.07006 | Running loss: 0.17399\n",
      "Epoch: 4 | Iteration: 28 | Classification loss: 0.07531 | Regression loss: 0.10129 | Running loss: 0.17408\n",
      "Epoch: 4 | Iteration: 29 | Classification loss: 0.05478 | Regression loss: 0.07854 | Running loss: 0.17272\n",
      "Epoch: 4 | Iteration: 30 | Classification loss: 0.07328 | Regression loss: 0.09924 | Running loss: 0.17271\n",
      "Epoch: 4 | Iteration: 31 | Classification loss: 0.06469 | Regression loss: 0.09415 | Running loss: 0.17228\n",
      "Epoch: 4 | Iteration: 32 | Classification loss: 0.09444 | Regression loss: 0.12792 | Running loss: 0.17380\n",
      "Epoch: 4 | Iteration: 33 | Classification loss: 0.08670 | Regression loss: 0.09846 | Running loss: 0.17413\n",
      "Epoch: 4 | Iteration: 34 | Classification loss: 0.07176 | Regression loss: 0.08986 | Running loss: 0.17377\n",
      "Epoch: 4 | Iteration: 35 | Classification loss: 0.06594 | Regression loss: 0.09299 | Running loss: 0.17336\n",
      "Epoch: 4 | Iteration: 36 | Classification loss: 0.08977 | Regression loss: 0.11609 | Running loss: 0.17424\n",
      "Epoch: 4 | Iteration: 37 | Classification loss: 0.09306 | Regression loss: 0.12065 | Running loss: 0.17528\n",
      "Epoch: 4 | Iteration: 38 | Classification loss: 0.08010 | Regression loss: 0.09175 | Running loss: 0.17519\n",
      "Epoch: 4 | Iteration: 39 | Classification loss: 0.05775 | Regression loss: 0.09011 | Running loss: 0.17451\n",
      "Epoch: 4 | Iteration: 40 | Classification loss: 0.05423 | Regression loss: 0.07008 | Running loss: 0.17328\n",
      "Epoch: 4 | Iteration: 41 | Classification loss: 0.07373 | Regression loss: 0.10109 | Running loss: 0.17332\n",
      "Epoch: 4 | Iteration: 42 | Classification loss: 0.07686 | Regression loss: 0.08997 | Running loss: 0.17317\n",
      "Epoch: 4 | Iteration: 43 | Classification loss: 0.04370 | Regression loss: 0.07334 | Running loss: 0.17189\n",
      "Epoch: 4 | Iteration: 44 | Classification loss: 0.12183 | Regression loss: 0.13324 | Running loss: 0.17374\n",
      "Epoch: 4 | Iteration: 45 | Classification loss: 0.09578 | Regression loss: 0.12093 | Running loss: 0.17468\n",
      "Epoch: 4 | Iteration: 46 | Classification loss: 0.07797 | Regression loss: 0.09708 | Running loss: 0.17468\n",
      "Epoch: 4 | Iteration: 47 | Classification loss: 0.09779 | Regression loss: 0.12337 | Running loss: 0.17565\n",
      "Epoch: 4 | Iteration: 48 | Classification loss: 0.10731 | Regression loss: 0.13301 | Running loss: 0.17697\n",
      "Epoch: 4 | Iteration: 49 | Classification loss: 0.10156 | Regression loss: 0.10981 | Running loss: 0.17766\n",
      "Epoch: 4 | Iteration: 50 | Classification loss: 0.14856 | Regression loss: 0.06658 | Running loss: 0.17839\n",
      "Epoch: 4 | Iteration: 51 | Classification loss: 0.10922 | Regression loss: 0.08743 | Running loss: 0.17875\n",
      "Epoch: 4 | Iteration: 52 | Classification loss: 0.08218 | Regression loss: 0.10823 | Running loss: 0.17897\n",
      "Epoch: 4 | Iteration: 53 | Classification loss: 0.08968 | Regression loss: 0.10672 | Running loss: 0.17929\n",
      "Epoch: 4 | Iteration: 54 | Classification loss: 0.07403 | Regression loss: 0.10509 | Running loss: 0.17929\n",
      "Epoch: 4 | Iteration: 55 | Classification loss: 0.06998 | Regression loss: 0.09730 | Running loss: 0.17907\n",
      "Epoch: 4 | Iteration: 56 | Classification loss: 0.06717 | Regression loss: 0.10182 | Running loss: 0.17889\n",
      "Epoch: 4 | Iteration: 57 | Classification loss: 0.07253 | Regression loss: 0.06539 | Running loss: 0.17819\n",
      "Epoch: 4 | Iteration: 58 | Classification loss: 0.11324 | Regression loss: 0.10730 | Running loss: 0.17891\n",
      "Epoch: 4 | Iteration: 59 | Classification loss: 0.05848 | Regression loss: 0.06946 | Running loss: 0.17806\n",
      "Epoch: 4 | Iteration: 60 | Classification loss: 0.11134 | Regression loss: 0.12733 | Running loss: 0.17905\n",
      "Epoch: 4 | Iteration: 61 | Classification loss: 0.08185 | Regression loss: 0.08968 | Running loss: 0.17893\n",
      "Epoch: 4 | Iteration: 62 | Classification loss: 0.05906 | Regression loss: 0.07808 | Running loss: 0.17827\n",
      "Epoch: 4 | Iteration: 63 | Classification loss: 0.10156 | Regression loss: 0.12208 | Running loss: 0.17897\n",
      "Epoch: 4 | Iteration: 64 | Classification loss: 0.04847 | Regression loss: 0.06619 | Running loss: 0.17798\n",
      "Epoch: 4 | Iteration: 65 | Classification loss: 0.08433 | Regression loss: 0.10736 | Running loss: 0.17819\n",
      "Epoch: 4 | Iteration: 66 | Classification loss: 0.09994 | Regression loss: 0.11533 | Running loss: 0.17875\n",
      "Epoch: 4 | Iteration: 67 | Classification loss: 0.07344 | Regression loss: 0.11297 | Running loss: 0.17886\n",
      "Epoch: 4 | Iteration: 68 | Classification loss: 0.06240 | Regression loss: 0.07220 | Running loss: 0.17822\n",
      "Epoch: 4 | Iteration: 69 | Classification loss: 0.05570 | Regression loss: 0.06544 | Running loss: 0.17740\n",
      "Epoch: 4 | Iteration: 70 | Classification loss: 0.08422 | Regression loss: 0.11592 | Running loss: 0.17772\n",
      "Epoch: 4 | Iteration: 71 | Classification loss: 0.06452 | Regression loss: 0.08220 | Running loss: 0.17729\n",
      "Epoch: 4 | Iteration: 72 | Classification loss: 0.07811 | Regression loss: 0.09226 | Running loss: 0.17720\n",
      "Epoch: 4 | Iteration: 73 | Classification loss: 0.07404 | Regression loss: 0.11551 | Running loss: 0.17736\n",
      "Epoch: 4 | Iteration: 74 | Classification loss: 0.07520 | Regression loss: 0.08849 | Running loss: 0.17718\n",
      "Epoch: 4 | Iteration: 75 | Classification loss: 0.08819 | Regression loss: 0.08655 | Running loss: 0.17715\n",
      "Epoch: 4 | Iteration: 76 | Classification loss: 0.05758 | Regression loss: 0.07445 | Running loss: 0.17656\n",
      "Epoch: 4 | Iteration: 77 | Classification loss: 0.04831 | Regression loss: 0.05674 | Running loss: 0.17565\n",
      "Epoch: 4 | Iteration: 78 | Classification loss: 0.04197 | Regression loss: 0.04816 | Running loss: 0.17456\n",
      "Epoch: 4 | Iteration: 79 | Classification loss: 0.09409 | Regression loss: 0.11573 | Running loss: 0.17500\n",
      "Epoch: 4 | Iteration: 80 | Classification loss: 0.07703 | Regression loss: 0.09197 | Running loss: 0.17493\n",
      "Epoch: 4 | Iteration: 81 | Classification loss: 0.09983 | Regression loss: 0.09897 | Running loss: 0.17522\n",
      "Epoch: 4 | Iteration: 82 | Classification loss: 0.10287 | Regression loss: 0.12650 | Running loss: 0.17587\n",
      "Epoch: 4 | Iteration: 83 | Classification loss: 0.08524 | Regression loss: 0.10856 | Running loss: 0.17609\n",
      "Epoch: 4 | Iteration: 84 | Classification loss: 0.10341 | Regression loss: 0.10555 | Running loss: 0.17647\n",
      "Epoch: 4 | Iteration: 85 | Classification loss: 0.08424 | Regression loss: 0.09256 | Running loss: 0.17648\n",
      "Epoch: 4 | Iteration: 86 | Classification loss: 0.09921 | Regression loss: 0.10858 | Running loss: 0.17684\n",
      "Epoch: 4 | Iteration: 87 | Classification loss: 0.07955 | Regression loss: 0.07521 | Running loss: 0.17659\n",
      "Epoch: 4 | Iteration: 88 | Classification loss: 0.07574 | Regression loss: 0.10741 | Running loss: 0.17666\n",
      "Epoch: 4 | Iteration: 89 | Classification loss: 0.08911 | Regression loss: 0.11333 | Running loss: 0.17695\n",
      "Epoch: 4 | Iteration: 90 | Classification loss: 0.06755 | Regression loss: 0.08668 | Running loss: 0.17670\n",
      "Epoch: 4 | Iteration: 91 | Classification loss: 0.11201 | Regression loss: 0.12658 | Running loss: 0.17737\n",
      "Epoch: 4 | Iteration: 92 | Classification loss: 0.09034 | Regression loss: 0.10781 | Running loss: 0.17759\n",
      "Epoch: 4 | Iteration: 93 | Classification loss: 0.10320 | Regression loss: 0.12080 | Running loss: 0.17809\n",
      "Epoch: 4 | Iteration: 94 | Classification loss: 0.06311 | Regression loss: 0.09362 | Running loss: 0.17786\n",
      "Epoch: 4 | Iteration: 95 | Classification loss: 0.07058 | Regression loss: 0.11424 | Running loss: 0.17793\n",
      "Epoch: 4 | Iteration: 96 | Classification loss: 0.08055 | Regression loss: 0.08573 | Running loss: 0.17781\n",
      "Epoch: 4 | Iteration: 97 | Classification loss: 0.10211 | Regression loss: 0.13527 | Running loss: 0.17842\n",
      "Epoch: 4 | Iteration: 98 | Classification loss: 0.06930 | Regression loss: 0.08872 | Running loss: 0.17822\n",
      "Epoch: 4 | Iteration: 99 | Classification loss: 0.06019 | Regression loss: 0.07118 | Running loss: 0.17775\n",
      "Epoch: 4 | Iteration: 100 | Classification loss: 0.08441 | Regression loss: 0.10799 | Running loss: 0.17789\n",
      "Epoch: 4 | Iteration: 101 | Classification loss: 0.07860 | Regression loss: 0.10576 | Running loss: 0.17796\n",
      "Epoch: 4 | Iteration: 102 | Classification loss: 0.07992 | Regression loss: 0.09338 | Running loss: 0.17791\n",
      "Epoch: 4 | Iteration: 103 | Classification loss: 0.05564 | Regression loss: 0.07727 | Running loss: 0.17748\n",
      "Epoch: 4 | Iteration: 104 | Classification loss: 0.07463 | Regression loss: 0.08109 | Running loss: 0.17727\n",
      "Epoch: 4 | Iteration: 105 | Classification loss: 0.07310 | Regression loss: 0.09248 | Running loss: 0.17716\n",
      "Epoch: 4 | Iteration: 106 | Classification loss: 0.08183 | Regression loss: 0.10644 | Running loss: 0.17726\n",
      "Epoch: 4 | Iteration: 107 | Classification loss: 0.04191 | Regression loss: 0.05144 | Running loss: 0.17649\n",
      "Epoch: 4 | Iteration: 108 | Classification loss: 0.06165 | Regression loss: 0.08663 | Running loss: 0.17623\n",
      "Epoch: 4 | Iteration: 109 | Classification loss: 0.09442 | Regression loss: 0.11247 | Running loss: 0.17651\n",
      "Epoch: 4 | Iteration: 110 | Classification loss: 0.04454 | Regression loss: 0.05828 | Running loss: 0.17584\n",
      "Epoch: 4 | Iteration: 111 | Classification loss: 0.09352 | Regression loss: 0.11383 | Running loss: 0.17613\n",
      "Epoch: 4 | Iteration: 112 | Classification loss: 0.05860 | Regression loss: 0.07680 | Running loss: 0.17576\n",
      "Epoch: 4 | Iteration: 113 | Classification loss: 0.07917 | Regression loss: 0.10715 | Running loss: 0.17586\n",
      "Epoch: 4 | Iteration: 114 | Classification loss: 0.08319 | Regression loss: 0.10711 | Running loss: 0.17598\n",
      "Epoch: 4 | Iteration: 115 | Classification loss: 0.07772 | Regression loss: 0.07983 | Running loss: 0.17582\n",
      "Epoch: 4 | Iteration: 116 | Classification loss: 0.08932 | Regression loss: 0.10487 | Running loss: 0.17598\n",
      "Epoch: 4 | Iteration: 117 | Classification loss: 0.07362 | Regression loss: 0.08920 | Running loss: 0.17587\n",
      "Epoch: 4 | Iteration: 118 | Classification loss: 0.07176 | Regression loss: 0.08431 | Running loss: 0.17570\n",
      "Epoch: 4 | Iteration: 119 | Classification loss: 0.09070 | Regression loss: 0.10787 | Running loss: 0.17589\n",
      "Epoch: 4 | Iteration: 120 | Classification loss: 0.07883 | Regression loss: 0.09712 | Running loss: 0.17589\n",
      "Epoch: 4 | Iteration: 121 | Classification loss: 0.08250 | Regression loss: 0.08858 | Running loss: 0.17585\n",
      "Epoch: 4 | Iteration: 122 | Classification loss: 0.07753 | Regression loss: 0.08570 | Running loss: 0.17575\n",
      "Epoch: 4 | Iteration: 123 | Classification loss: 0.06561 | Regression loss: 0.09258 | Running loss: 0.17561\n",
      "Epoch: 4 | Iteration: 124 | Classification loss: 0.08312 | Regression loss: 0.06559 | Running loss: 0.17540\n",
      "Epoch: 4 | Iteration: 125 | Classification loss: 0.05977 | Regression loss: 0.08021 | Running loss: 0.17511\n",
      "Epoch: 4 | Iteration: 126 | Classification loss: 0.07076 | Regression loss: 0.07551 | Running loss: 0.17489\n",
      "Epoch: 4 | Iteration: 127 | Classification loss: 0.07116 | Regression loss: 0.08987 | Running loss: 0.17478\n",
      "Epoch: 4 | Iteration: 128 | Classification loss: 0.07053 | Regression loss: 0.10219 | Running loss: 0.17476\n",
      "Epoch: 4 | Iteration: 129 | Classification loss: 0.06557 | Regression loss: 0.08766 | Running loss: 0.17460\n",
      "Epoch: 4 | Iteration: 130 | Classification loss: 0.06256 | Regression loss: 0.07799 | Running loss: 0.17434\n",
      "Epoch: 4 | Iteration: 131 | Classification loss: 0.07826 | Regression loss: 0.09904 | Running loss: 0.17436\n",
      "Epoch: 4 | Iteration: 132 | Classification loss: 0.07284 | Regression loss: 0.07412 | Running loss: 0.17415\n",
      "Epoch: 4 | Iteration: 133 | Classification loss: 0.07234 | Regression loss: 0.06854 | Running loss: 0.17391\n",
      "Epoch: 4 | Iteration: 134 | Classification loss: 0.07361 | Regression loss: 0.10153 | Running loss: 0.17391\n",
      "Epoch: 4 | Iteration: 135 | Classification loss: 0.06754 | Regression loss: 0.09567 | Running loss: 0.17384\n",
      "Epoch: 4 | Iteration: 136 | Classification loss: 0.05407 | Regression loss: 0.06636 | Running loss: 0.17345\n",
      "Epoch: 4 | Iteration: 137 | Classification loss: 0.06779 | Regression loss: 0.08407 | Running loss: 0.17329\n",
      "Epoch: 4 | Iteration: 138 | Classification loss: 0.07775 | Regression loss: 0.09833 | Running loss: 0.17331\n",
      "Epoch: 4 | Iteration: 139 | Classification loss: 0.07763 | Regression loss: 0.08985 | Running loss: 0.17327\n",
      "Epoch: 4 | Iteration: 140 | Classification loss: 0.09656 | Regression loss: 0.09727 | Running loss: 0.17341\n",
      "Epoch: 4 | Iteration: 141 | Classification loss: 0.07904 | Regression loss: 0.09893 | Running loss: 0.17345\n",
      "Epoch: 4 | Iteration: 142 | Classification loss: 0.07429 | Regression loss: 0.08817 | Running loss: 0.17337\n",
      "Epoch: 4 | Iteration: 143 | Classification loss: 0.08660 | Regression loss: 0.11239 | Running loss: 0.17355\n",
      "Epoch: 4 | Iteration: 144 | Classification loss: 0.10137 | Regression loss: 0.10391 | Running loss: 0.17377\n",
      "Epoch: 4 | Iteration: 145 | Classification loss: 0.08799 | Regression loss: 0.10811 | Running loss: 0.17392\n",
      "Epoch: 4 | Iteration: 146 | Classification loss: 0.07620 | Regression loss: 0.07280 | Running loss: 0.17375\n",
      "Epoch: 4 | Iteration: 147 | Classification loss: 0.07967 | Regression loss: 0.08651 | Running loss: 0.17370\n",
      "Epoch: 4 | Iteration: 148 | Classification loss: 0.09651 | Regression loss: 0.10676 | Running loss: 0.17390\n",
      "Epoch: 4 | Iteration: 149 | Classification loss: 0.06573 | Regression loss: 0.07820 | Running loss: 0.17370\n",
      "Epoch: 4 | Iteration: 150 | Classification loss: 0.08859 | Regression loss: 0.09659 | Running loss: 0.17377\n",
      "Epoch: 4 | Iteration: 151 | Classification loss: 0.08800 | Regression loss: 0.10244 | Running loss: 0.17388\n",
      "Epoch: 4 | Iteration: 152 | Classification loss: 0.08572 | Regression loss: 0.11323 | Running loss: 0.17405\n",
      "Epoch: 4 | Iteration: 153 | Classification loss: 0.08945 | Regression loss: 0.06700 | Running loss: 0.17393\n",
      "Epoch: 4 | Iteration: 154 | Classification loss: 0.09232 | Regression loss: 0.09960 | Running loss: 0.17405\n",
      "Epoch: 4 | Iteration: 155 | Classification loss: 0.06321 | Regression loss: 0.07974 | Running loss: 0.17385\n",
      "Epoch: 4 | Iteration: 156 | Classification loss: 0.05853 | Regression loss: 0.06730 | Running loss: 0.17354\n",
      "Epoch: 4 | Iteration: 157 | Classification loss: 0.06228 | Regression loss: 0.06717 | Running loss: 0.17326\n",
      "Epoch: 4 | Iteration: 158 | Classification loss: 0.09925 | Regression loss: 0.10498 | Running loss: 0.17346\n",
      "Epoch: 4 | Iteration: 159 | Classification loss: 0.07513 | Regression loss: 0.08849 | Running loss: 0.17340\n",
      "Epoch: 4 | Iteration: 160 | Classification loss: 0.08502 | Regression loss: 0.09319 | Running loss: 0.17343\n",
      "Epoch: 4 | Iteration: 161 | Classification loss: 0.07385 | Regression loss: 0.11123 | Running loss: 0.17350\n",
      "Epoch: 4 | Iteration: 162 | Classification loss: 0.05559 | Regression loss: 0.08711 | Running loss: 0.17331\n",
      "Epoch: 4 | Iteration: 163 | Classification loss: 0.07562 | Regression loss: 0.08286 | Running loss: 0.17322\n",
      "Epoch: 4 | Iteration: 164 | Classification loss: 0.07447 | Regression loss: 0.09159 | Running loss: 0.17318\n",
      "Epoch: 4 | Iteration: 165 | Classification loss: 0.07937 | Regression loss: 0.10421 | Running loss: 0.17324\n",
      "Epoch: 4 | Iteration: 166 | Classification loss: 0.00569 | Regression loss: 0.00000 | Running loss: 0.17224\n",
      "\n",
      " Total Time - 1464\n",
      "\n",
      "get detections on train dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c587ce5dbcda487d926cbef2ab793da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get detections on valid dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbc345acdd1c41bbb9915b30d64bce28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5435 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "mAP on training dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.7197,Precision:0.3163,Recall:0.8529\n",
      "AP@0.4:0.6531,Precision:0.2943,Recall:0.7937\n",
      "AP@0.6:0.3843,Precision:0.2244,Recall:0.6050\n",
      "AP@0.5:0.5463,Precision:0.2652,Recall:0.7151\n",
      "AP@0.7:0.1687,Precision:0.1448,Recall:0.3904\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.0100,Precision:0.0488,Recall:0.0978\n",
      "AP@0.4:0.0020,Precision:0.0260,Recall:0.0522\n",
      "AP@0.6:0.0001,Precision:0.0052,Recall:0.0104\n",
      "AP@0.5:0.0004,Precision:0.0124,Recall:0.0248\n",
      "AP@0.7:0.0000,Precision:0.0020,Recall:0.0039\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.0082,Precision:0.0547,Recall:0.0665\n",
      "AP@0.4:0.0013,Precision:0.0258,Recall:0.0313\n",
      "AP@0.6:0.0001,Precision:0.0054,Recall:0.0065\n",
      "AP@0.5:0.0003,Precision:0.0118,Recall:0.0143\n",
      "AP@0.7:0.0000,Precision:0.0011,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.0075,Precision:0.0663,Recall:0.0535\n",
      "AP@0.4:0.0012,Precision:0.0307,Recall:0.0248\n",
      "AP@0.6:0.0000,Precision:0.0049,Recall:0.0039\n",
      "AP@0.5:0.0002,Precision:0.0129,Recall:0.0104\n",
      "AP@0.7:0.0000,Precision:0.0016,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.0070,Precision:0.0755,Recall:0.0469\n",
      "AP@0.4:0.0011,Precision:0.0377,Recall:0.0235\n",
      "AP@0.6:0.0000,Precision:0.0063,Recall:0.0039\n",
      "AP@0.5:0.0002,Precision:0.0168,Recall:0.0104\n",
      "AP@0.7:0.0000,Precision:0.0021,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.0065,Precision:0.0833,Recall:0.0417\n",
      "AP@0.4:0.0010,Precision:0.0417,Recall:0.0209\n",
      "AP@0.6:0.0000,Precision:0.0052,Recall:0.0026\n",
      "AP@0.5:0.0002,Precision:0.0156,Recall:0.0078\n",
      "AP@0.7:0.0000,Precision:0.0026,Recall:0.0013\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.0055,Precision:0.0780,Recall:0.0300\n",
      "AP@0.4:0.0007,Precision:0.0373,Recall:0.0143\n",
      "AP@0.6:0.0000,Precision:0.0034,Recall:0.0013\n",
      "AP@0.5:0.0001,Precision:0.0136,Recall:0.0052\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.0054,Precision:0.0952,Recall:0.0287\n",
      "AP@0.4:0.0006,Precision:0.0433,Recall:0.0130\n",
      "AP@0.6:0.0000,Precision:0.0043,Recall:0.0013\n",
      "AP@0.5:0.0001,Precision:0.0173,Recall:0.0052\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0043,Precision:0.0867,Recall:0.0196\n",
      "AP@0.4:0.0003,Precision:0.0347,Recall:0.0078\n",
      "AP@0.6:0.0000,Precision:0.0058,Recall:0.0013\n",
      "AP@0.5:0.0001,Precision:0.0116,Recall:0.0026\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0041,Precision:0.0985,Recall:0.0169\n",
      "AP@0.4:0.0002,Precision:0.0303,Recall:0.0052\n",
      "AP@0.6:0.0000,Precision:0.0076,Recall:0.0013\n",
      "AP@0.5:0.0001,Precision:0.0152,Recall:0.0026\n",
      "AP@0.7:0.0000,Precision:0.0000,Recall:0.0000\n",
      "\n",
      "====================================================================================================\n",
      "mAP on validating dataset\n",
      "====================================================================================================\n",
      "\n",
      "predicting with confidence value: 0.05\n",
      "AP@0.3:0.4618,Precision:0.2110,Recall:0.7978\n",
      "AP@0.4:0.3798,Precision:0.1889,Recall:0.7142\n",
      "AP@0.6:0.1258,Precision:0.1118,Recall:0.4227\n",
      "AP@0.5:0.2540,Precision:0.1572,Recall:0.5946\n",
      "AP@0.7:0.0350,Precision:0.0601,Recall:0.2273\n",
      "\n",
      "predicting with confidence value: 0.1\n",
      "AP@0.3:0.4069,Precision:0.3641,Recall:0.6071\n",
      "AP@0.4:0.3357,Precision:0.3250,Recall:0.5418\n",
      "AP@0.6:0.1096,Precision:0.1877,Recall:0.3130\n",
      "AP@0.5:0.2220,Precision:0.2664,Recall:0.4441\n",
      "AP@0.7:0.0304,Precision:0.1009,Recall:0.1682\n",
      "\n",
      "predicting with confidence value: 0.15\n",
      "AP@0.3:0.3427,Precision:0.5131,Recall:0.4598\n",
      "AP@0.4:0.2853,Precision:0.4606,Recall:0.4127\n",
      "AP@0.6:0.0912,Precision:0.2554,Recall:0.2288\n",
      "AP@0.5:0.1875,Precision:0.3738,Recall:0.3349\n",
      "AP@0.7:0.0250,Precision:0.1353,Recall:0.1212\n",
      "\n",
      "predicting with confidence value: 0.2\n",
      "AP@0.3:0.2914,Precision:0.6139,Recall:0.3689\n",
      "AP@0.4:0.2451,Precision:0.5548,Recall:0.3333\n",
      "AP@0.6:0.0783,Precision:0.3035,Recall:0.1823\n",
      "AP@0.5:0.1601,Precision:0.4461,Recall:0.2680\n",
      "AP@0.7:0.0207,Precision:0.1522,Recall:0.0914\n",
      "\n",
      "predicting with confidence value: 0.25\n",
      "AP@0.3:0.2395,Precision:0.6909,Recall:0.2884\n",
      "AP@0.4:0.2030,Precision:0.6258,Recall:0.2612\n",
      "AP@0.6:0.0651,Precision:0.3392,Recall:0.1416\n",
      "AP@0.5:0.1315,Precision:0.4956,Recall:0.2069\n",
      "AP@0.7:0.0174,Precision:0.1715,Recall:0.0716\n",
      "\n",
      "predicting with confidence value: 0.3\n",
      "AP@0.3:0.1946,Precision:0.7587,Recall:0.2268\n",
      "AP@0.4:0.1669,Precision:0.6923,Recall:0.2069\n",
      "AP@0.6:0.0554,Precision:0.3846,Recall:0.1149\n",
      "AP@0.5:0.1096,Precision:0.5524,Recall:0.1651\n",
      "AP@0.7:0.0150,Precision:0.1958,Recall:0.0585\n",
      "\n",
      "predicting with confidence value: 0.35\n",
      "AP@0.3:0.1578,Precision:0.8234,Recall:0.1803\n",
      "AP@0.4:0.1366,Precision:0.7542,Recall:0.1651\n",
      "AP@0.6:0.0464,Precision:0.4224,Recall:0.0925\n",
      "AP@0.5:0.0911,Precision:0.6086,Recall:0.1332\n",
      "AP@0.7:0.0129,Precision:0.2220,Recall:0.0486\n",
      "\n",
      "predicting with confidence value: 0.4\n",
      "AP@0.3:0.1175,Precision:0.8372,Recall:0.1317\n",
      "AP@0.4:0.1048,Precision:0.7841,Recall:0.1233\n",
      "AP@0.6:0.0379,Precision:0.4651,Recall:0.0731\n",
      "AP@0.5:0.0713,Precision:0.6445,Recall:0.1014\n",
      "AP@0.7:0.0104,Precision:0.2392,Recall:0.0376\n",
      "\n",
      "predicting with confidence value: 0.45\n",
      "AP@0.3:0.0851,Precision:0.8565,Recall:0.0935\n",
      "AP@0.4:0.0764,Precision:0.8038,Recall:0.0878\n",
      "AP@0.6:0.0274,Precision:0.4689,Recall:0.0512\n",
      "AP@0.5:0.0519,Precision:0.6555,Recall:0.0716\n",
      "AP@0.7:0.0074,Precision:0.2344,Recall:0.0256\n",
      "\n",
      "predicting with confidence value: 0.5\n",
      "AP@0.3:0.0543,Precision:0.8740,Recall:0.0580\n",
      "AP@0.4:0.0494,Precision:0.8268,Recall:0.0549\n",
      "AP@0.6:0.0176,Precision:0.4567,Recall:0.0303\n",
      "AP@0.5:0.0327,Precision:0.6457,Recall:0.0428\n",
      "AP@0.7:0.0050,Precision:0.2362,Recall:0.0157\n",
      "Epoch - 5 Started\n",
      "Epoch: 5 | Iteration: 0 | Classification loss: 0.06885 | Regression loss: 0.09633 | Running loss: 0.16518\n",
      "Epoch: 5 | Iteration: 1 | Classification loss: 0.02666 | Regression loss: 0.04268 | Running loss: 0.11726\n",
      "Epoch: 5 | Iteration: 2 | Classification loss: 0.05697 | Regression loss: 0.06397 | Running loss: 0.11849\n",
      "Epoch: 5 | Iteration: 3 | Classification loss: 0.05858 | Regression loss: 0.09615 | Running loss: 0.12755\n",
      "Epoch: 5 | Iteration: 4 | Classification loss: 0.07550 | Regression loss: 0.11758 | Running loss: 0.14066\n",
      "Epoch: 5 | Iteration: 5 | Classification loss: 0.08813 | Regression loss: 0.09094 | Running loss: 0.14706\n",
      "Epoch: 5 | Iteration: 6 | Classification loss: 0.06793 | Regression loss: 0.08074 | Running loss: 0.14729\n",
      "Epoch: 5 | Iteration: 7 | Classification loss: 0.04622 | Regression loss: 0.05684 | Running loss: 0.14176\n",
      "Epoch: 5 | Iteration: 8 | Classification loss: 0.06014 | Regression loss: 0.08588 | Running loss: 0.14223\n",
      "Epoch: 5 | Iteration: 9 | Classification loss: 0.03718 | Regression loss: 0.05585 | Running loss: 0.13731\n",
      "Epoch: 5 | Iteration: 10 | Classification loss: 0.06467 | Regression loss: 0.07098 | Running loss: 0.13716\n",
      "Epoch: 5 | Iteration: 11 | Classification loss: 0.08115 | Regression loss: 0.08629 | Running loss: 0.13969\n",
      "Epoch: 5 | Iteration: 12 | Classification loss: 0.06055 | Regression loss: 0.08436 | Running loss: 0.14009\n",
      "Epoch: 5 | Iteration: 13 | Classification loss: 0.04816 | Regression loss: 0.05915 | Running loss: 0.13775\n",
      "Epoch: 5 | Iteration: 14 | Classification loss: 0.05251 | Regression loss: 0.07977 | Running loss: 0.13738\n",
      "Epoch: 5 | Iteration: 15 | Classification loss: 0.07558 | Regression loss: 0.11505 | Running loss: 0.14071\n",
      "Epoch: 5 | Iteration: 16 | Classification loss: 0.06130 | Regression loss: 0.08713 | Running loss: 0.14116\n",
      "Epoch: 5 | Iteration: 17 | Classification loss: 0.05724 | Regression loss: 0.08712 | Running loss: 0.14134\n",
      "Epoch: 5 | Iteration: 18 | Classification loss: 0.07094 | Regression loss: 0.11202 | Running loss: 0.14353\n",
      "Epoch: 5 | Iteration: 19 | Classification loss: 0.03774 | Regression loss: 0.05186 | Running loss: 0.14084\n",
      "Epoch: 5 | Iteration: 20 | Classification loss: 0.05801 | Regression loss: 0.09267 | Running loss: 0.14130\n",
      "Epoch: 5 | Iteration: 21 | Classification loss: 0.05889 | Regression loss: 0.08481 | Running loss: 0.14141\n",
      "Epoch: 5 | Iteration: 22 | Classification loss: 0.05315 | Regression loss: 0.05646 | Running loss: 0.14003\n",
      "Epoch: 5 | Iteration: 23 | Classification loss: 0.05102 | Regression loss: 0.06925 | Running loss: 0.13921\n",
      "Epoch: 5 | Iteration: 24 | Classification loss: 0.05574 | Regression loss: 0.07432 | Running loss: 0.13884\n",
      "Epoch: 5 | Iteration: 25 | Classification loss: 0.05680 | Regression loss: 0.09557 | Running loss: 0.13936\n",
      "Epoch: 5 | Iteration: 26 | Classification loss: 0.04921 | Regression loss: 0.07814 | Running loss: 0.13892\n",
      "Epoch: 5 | Iteration: 27 | Classification loss: 0.08684 | Regression loss: 0.09608 | Running loss: 0.14049\n",
      "Epoch: 5 | Iteration: 28 | Classification loss: 0.05099 | Regression loss: 0.05243 | Running loss: 0.13921\n",
      "Epoch: 5 | Iteration: 29 | Classification loss: 0.04304 | Regression loss: 0.07978 | Running loss: 0.13866\n",
      "Epoch: 5 | Iteration: 30 | Classification loss: 0.09554 | Regression loss: 0.10880 | Running loss: 0.14078\n",
      "Epoch: 5 | Iteration: 31 | Classification loss: 0.04135 | Regression loss: 0.05267 | Running loss: 0.13932\n",
      "Epoch: 5 | Iteration: 32 | Classification loss: 0.06258 | Regression loss: 0.08269 | Running loss: 0.13950\n",
      "Epoch: 5 | Iteration: 33 | Classification loss: 0.07795 | Regression loss: 0.10054 | Running loss: 0.14065\n",
      "Epoch: 5 | Iteration: 34 | Classification loss: 0.06388 | Regression loss: 0.08791 | Running loss: 0.14097\n",
      "Epoch: 5 | Iteration: 35 | Classification loss: 0.07091 | Regression loss: 0.10638 | Running loss: 0.14197\n",
      "Epoch: 5 | Iteration: 36 | Classification loss: 0.07047 | Regression loss: 0.08058 | Running loss: 0.14222\n",
      "Epoch: 5 | Iteration: 37 | Classification loss: 0.09322 | Regression loss: 0.06477 | Running loss: 0.14263\n",
      "Epoch: 5 | Iteration: 38 | Classification loss: 0.08730 | Regression loss: 0.10761 | Running loss: 0.14398\n",
      "Epoch: 5 | Iteration: 39 | Classification loss: 0.08067 | Regression loss: 0.09226 | Running loss: 0.14470\n",
      "Epoch: 5 | Iteration: 40 | Classification loss: 0.04809 | Regression loss: 0.07324 | Running loss: 0.14413\n",
      "Epoch: 5 | Iteration: 41 | Classification loss: 0.06344 | Regression loss: 0.07898 | Running loss: 0.14409\n",
      "Epoch: 5 | Iteration: 42 | Classification loss: 0.05780 | Regression loss: 0.07876 | Running loss: 0.14391\n",
      "Epoch: 5 | Iteration: 43 | Classification loss: 0.06624 | Regression loss: 0.07367 | Running loss: 0.14382\n",
      "Epoch: 5 | Iteration: 44 | Classification loss: 0.05665 | Regression loss: 0.08021 | Running loss: 0.14367\n",
      "Epoch: 5 | Iteration: 45 | Classification loss: 0.06895 | Regression loss: 0.06384 | Running loss: 0.14343\n",
      "Epoch: 5 | Iteration: 46 | Classification loss: 0.06646 | Regression loss: 0.09801 | Running loss: 0.14388\n",
      "Epoch: 5 | Iteration: 47 | Classification loss: 0.07732 | Regression loss: 0.10712 | Running loss: 0.14472\n",
      "Epoch: 5 | Iteration: 48 | Classification loss: 0.06148 | Regression loss: 0.08530 | Running loss: 0.14477\n",
      "Epoch: 5 | Iteration: 49 | Classification loss: 0.06529 | Regression loss: 0.10812 | Running loss: 0.14534\n",
      "Epoch: 5 | Iteration: 50 | Classification loss: 0.06765 | Regression loss: 0.09841 | Running loss: 0.14574\n",
      "Epoch: 5 | Iteration: 51 | Classification loss: 0.09640 | Regression loss: 0.11462 | Running loss: 0.14700\n",
      "Epoch: 5 | Iteration: 52 | Classification loss: 0.06401 | Regression loss: 0.08500 | Running loss: 0.14704\n",
      "Epoch: 5 | Iteration: 53 | Classification loss: 0.04217 | Regression loss: 0.06590 | Running loss: 0.14632\n",
      "Epoch: 5 | Iteration: 54 | Classification loss: 0.04425 | Regression loss: 0.06113 | Running loss: 0.14557\n",
      "Epoch: 5 | Iteration: 55 | Classification loss: 0.13345 | Regression loss: 0.11250 | Running loss: 0.14736\n",
      "Epoch: 5 | Iteration: 56 | Classification loss: 0.05868 | Regression loss: 0.07645 | Running loss: 0.14715\n",
      "Epoch: 5 | Iteration: 57 | Classification loss: 0.05501 | Regression loss: 0.07549 | Running loss: 0.14686\n",
      "Epoch: 5 | Iteration: 58 | Classification loss: 0.05034 | Regression loss: 0.08627 | Running loss: 0.14669\n",
      "Epoch: 5 | Iteration: 59 | Classification loss: 0.04736 | Regression loss: 0.07474 | Running loss: 0.14628\n",
      "Epoch: 5 | Iteration: 60 | Classification loss: 0.06646 | Regression loss: 0.09353 | Running loss: 0.14650\n",
      "Epoch: 5 | Iteration: 61 | Classification loss: 0.06842 | Regression loss: 0.10637 | Running loss: 0.14696\n",
      "Epoch: 5 | Iteration: 62 | Classification loss: 0.06753 | Regression loss: 0.10657 | Running loss: 0.14739\n",
      "Epoch: 5 | Iteration: 63 | Classification loss: 0.07451 | Regression loss: 0.10950 | Running loss: 0.14796\n",
      "Epoch: 5 | Iteration: 64 | Classification loss: 0.07387 | Regression loss: 0.09816 | Running loss: 0.14833\n",
      "Epoch: 5 | Iteration: 65 | Classification loss: 0.07915 | Regression loss: 0.10080 | Running loss: 0.14881\n",
      "Epoch: 5 | Iteration: 66 | Classification loss: 0.05703 | Regression loss: 0.06389 | Running loss: 0.14840\n",
      "Epoch: 5 | Iteration: 67 | Classification loss: 0.06079 | Regression loss: 0.08427 | Running loss: 0.14835\n",
      "Epoch: 5 | Iteration: 68 | Classification loss: 0.06335 | Regression loss: 0.10160 | Running loss: 0.14859\n",
      "Epoch: 5 | Iteration: 69 | Classification loss: 0.06134 | Regression loss: 0.07792 | Running loss: 0.14845\n",
      "Epoch: 5 | Iteration: 70 | Classification loss: 0.04387 | Regression loss: 0.06677 | Running loss: 0.14792\n",
      "Epoch: 5 | Iteration: 71 | Classification loss: 0.06148 | Regression loss: 0.09011 | Running loss: 0.14797\n",
      "Epoch: 5 | Iteration: 72 | Classification loss: 0.05592 | Regression loss: 0.07468 | Running loss: 0.14773\n",
      "Epoch: 5 | Iteration: 73 | Classification loss: 0.06502 | Regression loss: 0.10367 | Running loss: 0.14802\n",
      "Epoch: 5 | Iteration: 74 | Classification loss: 0.03377 | Regression loss: 0.05448 | Running loss: 0.14722\n",
      "Epoch: 5 | Iteration: 75 | Classification loss: 0.04574 | Regression loss: 0.08187 | Running loss: 0.14696\n",
      "Epoch: 5 | Iteration: 76 | Classification loss: 0.05897 | Regression loss: 0.07171 | Running loss: 0.14675\n",
      "Epoch: 5 | Iteration: 77 | Classification loss: 0.03728 | Regression loss: 0.06458 | Running loss: 0.14618\n",
      "Epoch: 5 | Iteration: 78 | Classification loss: 0.04133 | Regression loss: 0.08229 | Running loss: 0.14589\n",
      "Epoch: 5 | Iteration: 79 | Classification loss: 0.07725 | Regression loss: 0.09563 | Running loss: 0.14623\n",
      "Epoch: 5 | Iteration: 80 | Classification loss: 0.03058 | Regression loss: 0.06031 | Running loss: 0.14554\n",
      "Epoch: 5 | Iteration: 81 | Classification loss: 0.05180 | Regression loss: 0.08034 | Running loss: 0.14538\n",
      "Epoch: 5 | Iteration: 82 | Classification loss: 0.09278 | Regression loss: 0.12726 | Running loss: 0.14628\n",
      "Epoch: 5 | Iteration: 83 | Classification loss: 0.06798 | Regression loss: 0.07471 | Running loss: 0.14624\n",
      "Epoch: 5 | Iteration: 84 | Classification loss: 0.06486 | Regression loss: 0.09466 | Running loss: 0.14639\n",
      "Epoch: 5 | Iteration: 85 | Classification loss: 0.04700 | Regression loss: 0.07612 | Running loss: 0.14612\n",
      "Epoch: 5 | Iteration: 86 | Classification loss: 0.06185 | Regression loss: 0.09136 | Running loss: 0.14621\n",
      "Epoch: 5 | Iteration: 87 | Classification loss: 0.07292 | Regression loss: 0.10282 | Running loss: 0.14654\n",
      "Epoch: 5 | Iteration: 88 | Classification loss: 0.04737 | Regression loss: 0.07720 | Running loss: 0.14629\n",
      "Epoch: 5 | Iteration: 89 | Classification loss: 0.07103 | Regression loss: 0.09080 | Running loss: 0.14647\n",
      "Epoch: 5 | Iteration: 90 | Classification loss: 0.06728 | Regression loss: 0.09060 | Running loss: 0.14659\n",
      "Epoch: 5 | Iteration: 91 | Classification loss: 0.05959 | Regression loss: 0.09685 | Running loss: 0.14670\n",
      "Epoch: 5 | Iteration: 92 | Classification loss: 0.08077 | Regression loss: 0.06562 | Running loss: 0.14670\n",
      "Epoch: 5 | Iteration: 93 | Classification loss: 0.06615 | Regression loss: 0.08621 | Running loss: 0.14676\n",
      "Epoch: 5 | Iteration: 94 | Classification loss: 0.08268 | Regression loss: 0.06370 | Running loss: 0.14675\n",
      "Epoch: 5 | Iteration: 95 | Classification loss: 0.05994 | Regression loss: 0.07750 | Running loss: 0.14665\n",
      "Epoch: 5 | Iteration: 96 | Classification loss: 0.04456 | Regression loss: 0.07169 | Running loss: 0.14634\n",
      "Epoch: 5 | Iteration: 97 | Classification loss: 0.05809 | Regression loss: 0.08431 | Running loss: 0.14630\n",
      "Epoch: 5 | Iteration: 98 | Classification loss: 0.07293 | Regression loss: 0.09237 | Running loss: 0.14649\n",
      "Epoch: 5 | Iteration: 99 | Classification loss: 0.05385 | Regression loss: 0.06633 | Running loss: 0.14623\n",
      "Epoch: 5 | Iteration: 100 | Classification loss: 0.05200 | Regression loss: 0.07203 | Running loss: 0.14601\n",
      "Epoch: 5 | Iteration: 101 | Classification loss: 0.05246 | Regression loss: 0.07044 | Running loss: 0.14578\n",
      "Epoch: 5 | Iteration: 102 | Classification loss: 0.07004 | Regression loss: 0.08981 | Running loss: 0.14592\n",
      "Epoch: 5 | Iteration: 103 | Classification loss: 0.05775 | Regression loss: 0.09058 | Running loss: 0.14594\n",
      "Epoch: 5 | Iteration: 104 | Classification loss: 0.11653 | Regression loss: 0.10846 | Running loss: 0.14670\n",
      "Epoch: 5 | Iteration: 105 | Classification loss: 0.05258 | Regression loss: 0.07694 | Running loss: 0.14653\n",
      "Epoch: 5 | Iteration: 106 | Classification loss: 0.06433 | Regression loss: 0.06145 | Running loss: 0.14634\n",
      "Epoch: 5 | Iteration: 107 | Classification loss: 0.05969 | Regression loss: 0.09474 | Running loss: 0.14642\n",
      "Epoch: 5 | Iteration: 108 | Classification loss: 0.06322 | Regression loss: 0.09008 | Running loss: 0.14648\n",
      "Epoch: 5 | Iteration: 109 | Classification loss: 0.05749 | Regression loss: 0.07941 | Running loss: 0.14639\n",
      "Epoch: 5 | Iteration: 110 | Classification loss: 0.04961 | Regression loss: 0.06576 | Running loss: 0.14611\n",
      "Epoch: 5 | Iteration: 111 | Classification loss: 0.05435 | Regression loss: 0.07564 | Running loss: 0.14597\n",
      "Epoch: 5 | Iteration: 112 | Classification loss: 0.06931 | Regression loss: 0.09773 | Running loss: 0.14615\n",
      "Epoch: 5 | Iteration: 113 | Classification loss: 0.06834 | Regression loss: 0.09812 | Running loss: 0.14633\n",
      "Epoch: 5 | Iteration: 114 | Classification loss: 0.06874 | Regression loss: 0.09211 | Running loss: 0.14646\n",
      "Epoch: 5 | Iteration: 115 | Classification loss: 0.05795 | Regression loss: 0.07933 | Running loss: 0.14638\n",
      "Epoch: 5 | Iteration: 116 | Classification loss: 0.04806 | Regression loss: 0.09490 | Running loss: 0.14635\n",
      "Epoch: 5 | Iteration: 117 | Classification loss: 0.06609 | Regression loss: 0.08454 | Running loss: 0.14639\n",
      "Epoch: 5 | Iteration: 118 | Classification loss: 0.05291 | Regression loss: 0.08810 | Running loss: 0.14634\n",
      "Epoch: 5 | Iteration: 119 | Classification loss: 0.06034 | Regression loss: 0.08250 | Running loss: 0.14631\n",
      "Epoch: 5 | Iteration: 120 | Classification loss: 0.05738 | Regression loss: 0.07427 | Running loss: 0.14619\n",
      "Epoch: 5 | Iteration: 121 | Classification loss: 0.06230 | Regression loss: 0.09435 | Running loss: 0.14628\n",
      "Epoch: 5 | Iteration: 122 | Classification loss: 0.08659 | Regression loss: 0.10428 | Running loss: 0.14664\n",
      "Epoch: 5 | Iteration: 123 | Classification loss: 0.05043 | Regression loss: 0.06545 | Running loss: 0.14639\n",
      "Epoch: 5 | Iteration: 124 | Classification loss: 0.03679 | Regression loss: 0.06448 | Running loss: 0.14603\n",
      "Epoch: 5 | Iteration: 125 | Classification loss: 0.04888 | Regression loss: 0.07264 | Running loss: 0.14584\n"
     ]
    }
   ],
   "source": [
    "### Training Loop\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(retinanet, epoch, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518451c-6a5c-4f91-982e-75930a2bf338",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d05d68-217b-43ae-8f3e-df61fa5af814",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Show some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb47e0-c7a8-4641-adad-38341535b0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.patches import Rectangle\n",
    "# retinanet = torch.load('./retinanet_resnet34.pt')val_detection_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049641b1-3e14-45f0-88f0-2b3c5598c9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Sample Results\n",
    "# # retinanet = model.resnet50(num_classes = 2, pretrained = False)\n",
    "\n",
    "# retinanet.eval()\n",
    "# with torch.no_grad():\n",
    "# # unnormalize = UnNormalizer()\n",
    "\n",
    "#     fig, ax = plt.subplots(2, 8, figsize=(32, 8))\n",
    "\n",
    "#     for iter_num, data in enumerate(valid_dataloader):\n",
    "\n",
    "#         # print(data['annot'].size())\n",
    "\n",
    "#         tmp = data['img'].to(device)\n",
    "\n",
    "#         # Getting Predictions\n",
    "#         scores, classification, transformed_anchors = retinanet(tmp.float())\n",
    "#         # print(scores)\n",
    "\n",
    "#         idxs = np.where(scores.cpu()>0.05)\n",
    "#         # print(scores)\n",
    "#         # print(classification)\n",
    "#         # print(transformed_anchors)\n",
    "#         # print(idxs)\n",
    "#         # img = np.array(255 * unnormalize(data['img'][0, :, :, :])).copy()\n",
    "\n",
    "#         img = np.array(data['img'][0, :, :, :]).copy()\n",
    "#         # img[img<0] = 0\n",
    "#         # img[img>255] = 255\n",
    "#         img = img.squeeze(0)\n",
    "#         # print(img.shape)\n",
    "\n",
    "#         ax[0][iter_num].imshow(img, cmap='gray')\n",
    "#         ax[1][iter_num].imshow(img, cmap='gray')\n",
    "\n",
    "#         for j in range(idxs[0].shape[0]):\n",
    "#             ## predict\n",
    "#             bbox = transformed_anchors[idxs[0][j], :]\n",
    "#             x1 = int(bbox[0])\n",
    "#             y1 = int(bbox[1])\n",
    "#             x2 = int(bbox[2])\n",
    "#             y2 = int(bbox[3])\n",
    "#             rect = Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1,edgecolor='r',facecolor='none')\n",
    "#             ax[0][iter_num].add_patch(rect)\n",
    "            \n",
    "#         for j in range(data['annot'].size(1)):\n",
    "#             ## ground truth\n",
    "#             bbox = data['annot'][0][j]\n",
    "#             x1 = int(bbox[0])\n",
    "#             y1 = int(bbox[1])\n",
    "#             x2 = int(bbox[2])\n",
    "#             y2 = int(bbox[3])\n",
    "#             rect = Rectangle((x1,y1),x2-x1,y2-y1,linewidth=1,edgecolor='r',facecolor='none')\n",
    "#             ax[1][iter_num].add_patch(rect)\n",
    "\n",
    "#         if iter_num == 7:\n",
    "#             break\n",
    "\n",
    "\n",
    "\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6622325-87ac-4360-a29f-8518b6dc220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_threshold = 0.1\n",
    "\n",
    "# predict = [[None, None] for j in range(len(valid_dataset))]\n",
    "\n",
    "# retinanet = torch.load('./retinanet_gwd.pt')\n",
    "# retinanet.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "\n",
    "#     for index in tqdm(range(len(valid_dataset))):\n",
    "#         data = valid_dataset[index]\n",
    "#         img = data['img']\n",
    "#         annot = data['annot']\n",
    "#         scale = data['scale']\n",
    "\n",
    "#         # run network\n",
    "#         if torch.cuda.is_available():\n",
    "#             scores, labels, boxes = retinanet(img.cuda().permute(2, 0, 1).float().unsqueeze(dim=0))\n",
    "#         else:\n",
    "#             scores, labels, boxes = retinanet(data['img'].permute(2, 0, 1).float().unsqueeze(dim=0))\n",
    "            \n",
    "#         scores = scores.cpu().numpy()\n",
    "#         labels = labels.cpu().numpy()\n",
    "#         boxes  = boxes.cpu().numpy()\n",
    "        \n",
    "#         # print(scores, \"\\n\", labels, \"\\n\", boxes, \"\\n\")\n",
    "\n",
    "#         # correct boxes for image scale\n",
    "#         # boxes /= scale\n",
    "\n",
    "#         # select indices which have a score above the threshold\n",
    "#         indices = np.where(scores > score_threshold)[0]\n",
    "#         if indices.shape[0] > 0:\n",
    "#             # select those scores\n",
    "#             scores = scores[indices]\n",
    "\n",
    "#             # find the order with which to sort the scores\n",
    "#             scores_sort = np.argsort(-scores)[:4]\n",
    "\n",
    "#             # select detections\n",
    "#             image_boxes      = boxes[indices[scores_sort], :]\n",
    "#             image_scores     = scores[scores_sort]\n",
    "#             image_labels     = labels[indices[scores_sort]]\n",
    "#             image_detections = np.concatenate([image_boxes, np.expand_dims(image_scores, axis=1), np.expand_dims(image_labels, axis=1)], axis=1)\n",
    "\n",
    "#             # copy detections to predict\n",
    "#             for label in range(2):\n",
    "#                 predict[index][label] = image_detections[image_detections[:, -1] == label, :-1]\n",
    "#         else:\n",
    "#             # copy detections to predict\n",
    "#             for label in range(2):\n",
    "#                 predict[index][label] = np.zeros((0, 5))\n",
    "\n",
    "#         # print('{}/{}'.format(index + 1, len(dataset)), end='\\r')\n",
    "#         # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474cb8c-71f5-4fe7-9fd3-dfc5881a5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = [[None, None] for _ in range(2000)]\n",
    "# for index in tqdm(range(2000)):\n",
    "#     data = train_dataset[index]\n",
    "#     annot = data['annot'].numpy()\n",
    "#     if annot.shape[0] != 0:\n",
    "#         for label in range(2):\n",
    "#             ground_truth[index][label] = annot[annot[:, -1] == label, :-1]\n",
    "#     else:\n",
    "#         for label in range(2):\n",
    "#             ground_truth[index][label] = np.zeros((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d6261-5850-4331-aee0-f5260940a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(ground_truth, \"./ground_truth_annot_train.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c00230-fcbb-455f-a155-f505eea4c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground_truth = [[None, None] for _ in range(len(valid_dataset))]\n",
    "# for index in tqdm(range(len(valid_dataset))):\n",
    "#     data =valid_dataset[index]\n",
    "#     annot = data['annot'].numpy()\n",
    "#     if annot.shape[0] != 0:\n",
    "#         for label in range(2):\n",
    "#             ground_truth[index][label] = annot[annot[:, -1] == label, :-1]\n",
    "#     else:\n",
    "#         for label in range(2):\n",
    "#             ground_truth[index][label] = np.zeros((0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd60d0f-b76b-407b-a005-c2298883dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(ground_truth, \"./ground_truth_annot_valid.data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abb312f-879d-454a-9401-21adafee178e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
